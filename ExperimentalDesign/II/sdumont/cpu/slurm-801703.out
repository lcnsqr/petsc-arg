Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type cg -pc_type bjacobi -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 15:27:34 2020            |
| OS:             Linux                               |
| HostName:       sdumont6181                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.85334, Active time=2.8821                                        |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.3993      0.000008    0.3993      0.000008    13.85    13.85    |
| Ke                            50792      1.7576      0.000035    1.7576      0.000035    60.98    60.98    |
| elem init                     50792      0.7252      0.000014    0.7252      0.000014    25.16    25.16    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.8821                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 98.665109
Tempo total: 98.665017
Tempo total: 98.665122
Tempo total: 98.665111
Tempo total: 98.665061
Tempo total: 98.665132
Tempo total: 98.665068
Tempo total: 98.665020
Tempo total: 98.665021
Tempo total: 98.665024
Tempo total: 98.665083
Tempo total: 98.665061
Tempo total: 98.665053
Tempo total: 98.665119
Tempo total: 98.665119
Tempo total: 98.664930
Tempo total: 98.664929
Tempo total: 98.665106
Tempo total: 98.665020
Tempo total: 98.665121
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6181 with 20 processors, by luciano.siqueira Thu Dec 10 15:28:45 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           9.891e+01     1.000   9.891e+01
Objects:              3.300e+01     1.000   3.300e+01
Flop:                 4.587e+10     1.106   4.359e+10  8.719e+11
Flop/sec:             4.637e+08     1.106   4.407e+08  8.815e+09
MPI Messages:         4.552e+03     2.706   3.035e+03  6.071e+04
MPI Message Lengths:  2.654e+08     1.571   7.091e+04  4.305e+09
MPI Reductions:       1.249e+03     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 9.8914e+01 100.0%  8.7189e+11 100.0%  6.071e+04 100.0%  7.091e+04      100.0%  1.242e+03  99.4%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 4.4503e-0189.7 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  0  0  1  0  1   0  0  1  0  1     0
BuildTwoSidedF         5 1.0 4.4385e-01105.9 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  0  0  1  5  0   0  0  1  5  0     0
MatMult              402 1.0 3.2840e+01 1.0 2.15e+10 1.1 5.9e+04 4.6e+04 0.0e+00 33 47 97 63  0  33 47 97 63  0 12483
MatSolve             403 1.0 3.2043e+01 1.1 2.11e+10 1.1 0.0e+00 0.0e+00 0.0e+00 31 46  0  0  0  31 46  0  0  0 12435
MatLUFactorNum         1 1.0 2.4486e+00 1.1 1.27e+09 1.1 0.0e+00 0.0e+00 0.0e+00  2  3  0  0  0   2  3  0  0  0  9882
MatILUFactorSym        1 1.0 1.5302e-01 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatAssemblyBegin       2 1.0 5.1945e-01 3.4 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  0  0  0  5  0   0  0  0  5  0     0
MatAssemblyEnd         2 1.0 3.4324e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  0  0  0  0  0   0  0  0  0  0    13
MatGetRowIJ            1 1.0 3.6570e-06 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatGetOrdering         1 1.0 4.2868e-03 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatZeroEntries         3 1.0 1.2209e-01 1.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecTDot              802 1.0 2.0098e+00 4.1 6.81e+08 1.1 0.0e+00 0.0e+00 8.0e+02  1  1  0  0 64   1  1  0  0 65  6481
VecNorm              403 1.0 3.6710e+0016.6 3.42e+08 1.1 0.0e+00 0.0e+00 4.0e+02  2  1  0  0 32   2  1  0  0 32  1783
VecCopy                2 1.0 1.5612e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet               408 1.0 1.3362e-01 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY              802 1.0 7.1138e-01 1.2 6.81e+08 1.1 0.0e+00 0.0e+00 0.0e+00  1  1  0  0  0   1  1  0  0  0 18310
VecAYPX              401 1.0 4.3198e-01 1.1 3.40e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 15058
VecAssemblyBegin       3 1.0 9.6675e-03 1.0 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAssemblyEnd         3 1.0 5.6268e-04 4.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecScatterBegin      403 1.0 2.5439e-01 2.0 0.00e+00 0.0 5.9e+04 4.6e+04 0.0e+00  0  0 97 63  0   0  0 97 63  0     0
VecScatterEnd        403 1.0 3.1735e+0058.6 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
SFSetGraph             2 1.0 5.1647e-04 1.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.1779e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  1  0  0   0  0  1  0  0     0
SFBcastOpBegin       403 1.0 2.5345e-01 2.1 0.00e+00 0.0 5.9e+04 4.6e+04 0.0e+00  0  0 97 63  0   0  0 97 63  0     0
SFBcastOpEnd         403 1.0 3.1726e+0059.5 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
SFPack               403 1.0 2.4494e-01 2.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack             403 1.0 3.1600e-04 1.8 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               2 1.0 1.5968e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSolve               1 1.0 6.9437e+01 1.0 4.59e+10 1.1 5.9e+04 4.6e+04 1.2e+03 70100 97 63 96  70100 97 63 97 12553
PCSetUp                2 1.0 2.6125e+00 1.1 1.27e+09 1.1 0.0e+00 0.0e+00 0.0e+00  3  3  0  0  0   3  3  0  0  0  9262
PCSetUpOnBlocks        1 1.0 2.6046e+00 1.1 1.27e+09 1.1 0.0e+00 0.0e+00 0.0e+00  3  3  0  0  0   3  3  0  0  0  9290
PCApply              403 1.0 3.2175e+01 1.1 2.11e+10 1.1 0.0e+00 0.0e+00 0.0e+00 31 46  0  0  0  31 46  0  0  0 12384
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     4              4    666933972     0.
           Index Set     7              7      5403804     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    12             12     24405960     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     2              2         3088     0.
      Preconditioner     2              2         1944     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 3.01e-08
Average time for MPI_Barrier(): 4.9906e-06
Average time for zero size MPI_Send(): 3.3205e-06
#PETSc Option Table entries:
-d 3
-ksp_type cg
-log_view
-mat_type aij
-n 100
-pc_type bjacobi
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type cg -pc_type jacobi -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 15:29:15 2020            |
| OS:             Linux                               |
| HostName:       sdumont6181                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.85837, Active time=2.89782                                       |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.4039      0.000008    0.4039      0.000008    13.94    13.94    |
| Ke                            50792      1.7686      0.000035    1.7686      0.000035    61.03    61.03    |
| elem init                     50792      0.7254      0.000014    0.7254      0.000014    25.03    25.03    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.8978                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 40.457378
Tempo total: 40.478936
Tempo total: 40.448823
Tempo total: 40.479486
Tempo total: 40.433088
Tempo total: 40.448214
Tempo total: 40.457048
Tempo total: 40.434589
Tempo total: 40.426633
Tempo total: 40.431865
Tempo total: 40.430670
Tempo total: 40.412573
Tempo total: 40.445545
Tempo total: 40.447065
Tempo total: 40.431654
Tempo total: 40.423670
Tempo total: 40.424291
Tempo total: 40.439794
Tempo total: 40.458902
Tempo total: 40.506538
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6181 with 20 processors, by luciano.siqueira Thu Dec 10 15:29:29 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           4.083e+01     1.000   4.083e+01
Objects:              2.600e+01     1.000   2.600e+01
Flop:                 8.024e+09     1.100   7.659e+09  1.532e+11
Flop/sec:             1.965e+08     1.100   1.876e+08  3.752e+09
MPI Messages:         1.626e+03     2.630   1.094e+03  2.187e+04
MPI Message Lengths:  1.458e+08     1.348   1.154e+05  2.524e+09
MPI Reductions:       4.530e+02     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 4.0829e+01 100.0%  1.5319e+11 100.0%  2.187e+04 100.0%  1.154e+05      100.0%  4.460e+02  98.5%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 4.3723e-0189.0 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  1  0  2  0  2   1  0  2  0  2     0
BuildTwoSidedF         5 1.0 4.3671e-01106.5 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  0  0  2  8  1   0  0  2  8  1     0
MatMult              136 1.0 1.1103e+01 1.1 7.27e+09 1.1 2.0e+04 4.6e+04 0.0e+00 27 91 91 36  0  27 91 91 36  0 12490
MatAssemblyBegin       2 1.0 5.4101e-01 3.7 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  1  0  1  8  0   1  0  1  8  0     0
MatAssemblyEnd         2 1.0 3.4312e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  1  0  1  0  1   1  0  1  0  1    13
MatZeroEntries         3 1.0 1.2092e-01 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecTDot              270 1.0 7.1661e-01 4.2 2.29e+08 1.1 0.0e+00 0.0e+00 2.7e+02  1  3  0  0 60   1  3  0  0 61  6119
VecNorm              137 1.0 1.2861e-01 1.6 1.16e+08 1.1 0.0e+00 0.0e+00 1.4e+02  0  1  0  0 30   0  1  0  0 31 17300
VecCopy                2 1.0 1.5459e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet                 5 1.0 1.7873e-03 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY              270 1.0 2.4063e-01 1.1 2.29e+08 1.1 0.0e+00 0.0e+00 0.0e+00  1  3  0  0  0   1  3  0  0  0 18224
VecAYPX              135 1.0 1.4680e-01 1.1 1.14e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 14881
VecAssemblyBegin       3 1.0 9.7277e-03 1.0 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  1  0  1   0  0  1  0  1     0
VecAssemblyEnd         3 1.0 5.7895e-04 4.6 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecPointwiseMult     137 1.0 1.7502e-01 1.1 5.82e+07 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0  6357
VecScatterBegin      137 1.0 8.6880e-02 2.0 0.00e+00 0.0 2.0e+04 4.6e+04 0.0e+00  0  0 91 36  0   0  0 91 36  0     0
VecScatterEnd        137 1.0 1.0558e+0052.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
SFSetGraph             2 1.0 5.1607e-04 1.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.1700e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  3  0  0   0  0  3  0  0     0
SFBcastOpBegin       137 1.0 8.6609e-02 2.0 0.00e+00 0.0 2.0e+04 4.6e+04 0.0e+00  0  0 91 36  0   0  0 91 36  0     0
SFBcastOpEnd         137 1.0 1.0555e+0053.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
SFPack               137 1.0 8.2485e-02 2.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack             137 1.0 1.1651e-04 2.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               1 1.0 1.5832e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSolve               1 1.0 1.1985e+01 1.0 8.01e+09 1.1 2.0e+04 4.6e+04 4.1e+02 29100 91 36 90  29100 91 36 92 12764
PCSetUp                1 1.0 5.7400e-07 3.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
PCApply              137 1.0 2.4713e-01 1.1 5.82e+07 1.1 0.0e+00 0.0e+00 2.0e+00  1  1  0  0  0   1  1  0  0  0  4502
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     3              3    344047400     0.
           Index Set     4              4       304416     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    11             11     27802304     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     1              1         1672     0.
      Preconditioner     1              1          968     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 2.76e-08
Average time for MPI_Barrier(): 5.196e-06
Average time for zero size MPI_Send(): 3.2861e-06
#PETSc Option Table entries:
-d 3
-ksp_type cg
-log_view
-mat_type aij
-n 100
-pc_type jacobi
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type cg -pc_type sor -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 15:29:59 2020            |
| OS:             Linux                               |
| HostName:       sdumont6181                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.82852, Active time=2.87637                                       |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.3968      0.000008    0.3968      0.000008    13.80    13.80    |
| Ke                            50792      1.7606      0.000035    1.7606      0.000035    61.21    61.21    |
| elem init                     50792      0.7190      0.000014    0.7190      0.000014    25.00    25.00    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.8764                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 123.011881
Tempo total: 123.026373
Tempo total: 122.969406
Tempo total: 122.966153
Tempo total: 122.973553
Tempo total: 122.954395
Tempo total: 122.942424
Tempo total: 122.951019
Tempo total: 122.956906
Tempo total: 122.973164
Tempo total: 122.973762
Tempo total: 122.943717
Tempo total: 122.937444
Tempo total: 122.949234
Tempo total: 122.955157
Tempo total: 122.950867
Tempo total: 122.961763
Tempo total: 122.943117
Tempo total: 122.961421
Tempo total: 123.036081
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6181 with 20 processors, by luciano.siqueira Thu Dec 10 15:31:35 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           1.233e+02     1.000   1.233e+02
Objects:              2.500e+01     1.000   2.500e+01
Flop:                 5.110e+10     1.106   4.857e+10  9.715e+11
Flop/sec:             4.143e+08     1.106   3.938e+08  7.876e+09
MPI Messages:         5.178e+03     2.711   3.452e+03  6.903e+04
MPI Message Lengths:  2.910e+08     1.600   6.789e+04  4.686e+09
MPI Reductions:       1.420e+03     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 1.2334e+02 100.0%  9.7148e+11 100.0%  6.903e+04 100.0%  6.789e+04      100.0%  1.413e+03  99.5%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 4.3363e-01116.5 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  0  0  1  0  0   0  0  1  0  0     0
BuildTwoSidedF         5 1.0 4.3218e-01133.7 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  0  0  1  4  0   0  0  1  4  0     0
MatMult              459 1.0 3.7381e+01 1.1 2.45e+10 1.1 6.7e+04 4.6e+04 0.0e+00 30 48 97 66  0  30 48 97 66  0 12521
MatSOR               460 1.0 5.4662e+01 1.1 2.42e+10 1.1 0.0e+00 0.0e+00 0.0e+00 42 47  0  0  0  42 47  0  0  0  8389
MatAssemblyBegin       2 1.0 5.3333e-01 3.2 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  0  0  0  4  0   0  0  0  4  0     0
MatAssemblyEnd         2 1.0 3.2096e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  0  0  0  0  0   0  0  0  0  0    13
MatZeroEntries         3 1.0 1.2050e-01 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecTDot              916 1.0 2.3853e+00 4.1 7.78e+08 1.1 0.0e+00 0.0e+00 9.2e+02  1  2  0  0 65   1  2  0  0 65  6237
VecNorm              460 1.0 5.9408e+0022.5 3.91e+08 1.1 0.0e+00 0.0e+00 4.6e+02  2  1  0  0 32   2  1  0  0 33  1258
VecCopy                2 1.0 1.5071e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet                 5 1.0 1.7569e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY              916 1.0 8.2393e-01 1.2 7.78e+08 1.1 0.0e+00 0.0e+00 0.0e+00  1  2  0  0  0   1  2  0  0  0 18056
VecAYPX              458 1.0 5.0057e-01 1.1 3.89e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 14844
VecAssemblyBegin       3 1.0 8.5493e-03 1.0 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAssemblyEnd         3 1.0 5.5572e-04 4.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecScatterBegin      460 1.0 2.9119e-01 2.1 0.00e+00 0.0 6.7e+04 4.6e+04 0.0e+00  0  0 97 66  0   0  0 97 66  0     0
VecScatterEnd        460 1.0 3.4644e+0057.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
SFSetGraph             2 1.0 5.1918e-04 1.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.1523e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  1  0  0   0  0  1  0  0     0
SFBcastOpBegin       460 1.0 2.9027e-01 2.1 0.00e+00 0.0 6.7e+04 4.6e+04 0.0e+00  0  0 97 66  0   0  0 97 66  0     0
SFBcastOpEnd         460 1.0 3.4635e+0059.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
SFPack               460 1.0 2.7939e-01 2.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack             460 1.0 3.5346e-04 2.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               1 1.0 1.5766e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSolve               1 1.0 9.4169e+01 1.0 5.11e+10 1.1 6.7e+04 4.6e+04 1.4e+03 76100 97 66 97  76100 97 66 97 10314
PCSetUp                1 1.0 2.8800e-07 1.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
PCApply              460 1.0 5.4663e+01 1.1 2.42e+10 1.1 0.0e+00 0.0e+00 0.0e+00 42 47  0  0  0  42 47  0  0  0  8389
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     3              3    354240752     0.
           Index Set     4              4       304416     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    10             10     24402824     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     1              1         1672     0.
      Preconditioner     1              1          968     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 2.77e-08
Average time for MPI_Barrier(): 4.5804e-06
Average time for zero size MPI_Send(): 3.2873e-06
#PETSc Option Table entries:
-d 3
-ksp_type cg
-log_view
-mat_type aij
-n 100
-pc_type sor
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type cg -pc_type mg -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 15:32:06 2020            |
| OS:             Linux                               |
| HostName:       sdumont6181                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.82831, Active time=2.87171                                       |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.3987      0.000008    0.3987      0.000008    13.88    13.88    |
| Ke                            50792      1.7513      0.000034    1.7513      0.000034    60.98    60.98    |
| elem init                     50792      0.7217      0.000014    0.7217      0.000014    25.13    25.13    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.8717                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 134.264917
Tempo total: 134.223087
Tempo total: 134.236237
Tempo total: 134.233685
Tempo total: 134.235007
Tempo total: 134.213561
Tempo total: 134.174270
Tempo total: 134.191119
Tempo total: 134.175722
Tempo total: 134.177042
Tempo total: 134.197906
Tempo total: 134.176240
Tempo total: 134.188798
Tempo total: 134.186419
Tempo total: 134.184477
Tempo total: 134.171381
Tempo total: 134.166480
Tempo total: 134.184729
Tempo total: 134.165185
Tempo total: 134.285868
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6181 with 20 processors, by luciano.siqueira Thu Dec 10 15:33:52 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           1.346e+02     1.000   1.346e+02
Objects:              5.000e+01     1.000   5.000e+01
Flop:                 5.658e+10     1.106   5.378e+10  1.076e+12
Flop/sec:             4.204e+08     1.106   3.996e+08  7.992e+09
MPI Messages:         5.750e+03     2.715   3.831e+03  7.662e+04
MPI Message Lengths:  3.144e+08     1.622   6.570e+04  5.034e+09
MPI Reductions:       8.160e+02     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 1.3458e+02 100.0%  1.0755e+12 100.0%  7.662e+04 100.0%  6.570e+04      100.0%  8.090e+02  99.1%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 4.0132e-0139.1 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  0  0  1  0  1   0  0  1  0  1     0
BuildTwoSidedF         5 1.0 3.9944e-0162.6 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  0  0  0  4  1   0  0  0  4  1     0
MatMult              511 1.0 4.4754e+01 1.1 2.73e+10 1.1 7.5e+04 4.6e+04 0.0e+00 31 48 97 68  0  31 48 97 68  0 11643
MatSOR               513 1.0 6.1084e+01 1.1 2.70e+10 1.1 0.0e+00 0.0e+00 0.0e+00 43 48  0  0  0  43 48  0  0  0  8372
MatAssemblyBegin       2 1.0 4.7276e-01 3.4 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  0  0  0  4  0   0  0  0  4  0     0
MatAssemblyEnd         2 1.0 3.4281e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  0  0  0  0  1   0  0  0  0  1    13
MatZeroEntries         3 1.0 1.2201e-01 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecMDot               10 1.0 1.4951e-01 6.6 4.67e+07 1.1 0.0e+00 0.0e+00 1.0e+01  0  0  0  0  1   0  0  0  0  1  5975
VecTDot              498 1.0 1.3203e+00 4.3 4.23e+08 1.1 0.0e+00 0.0e+00 5.0e+02  1  1  0  0 61   1  1  0  0 62  6126
VecNorm              262 1.0 3.5517e+0016.9 2.23e+08 1.1 0.0e+00 0.0e+00 2.6e+02  1  0  0  0 32   1  0  0  0 32  1198
VecScale              11 1.0 3.4258e-03 1.3 4.67e+06 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 26075
VecCopy              505 1.0 3.5608e-01 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet               509 1.0 1.5628e-01 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY              499 1.0 4.4653e-01 1.2 4.24e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 18150
VecAYPX              751 1.0 8.2723e-01 1.1 5.31e+08 1.1 0.0e+00 0.0e+00 0.0e+00  1  1  0  0  0   1  1  0  0  0 12271
VecAXPBYCZ           251 1.0 3.3352e-01 1.1 5.33e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 30557
VecMAXPY              11 1.0 3.6083e-02 1.1 5.52e+07 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 29257
VecAssemblyBegin       3 1.0 9.6355e-03 1.0 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAssemblyEnd         3 1.0 6.0901e-04 4.7 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecScatterBegin      512 1.0 3.2400e-01 2.1 0.00e+00 0.0 7.5e+04 4.6e+04 0.0e+00  0  0 98 68  0   0  0 98 68  0     0
VecScatterEnd        512 1.0 7.5127e+0080.8 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  2  0  0  0  0   2  0  0  0  0     0
VecNormalize          11 1.0 4.0099e-02 3.9 1.40e+07 1.1 0.0e+00 0.0e+00 1.1e+01  0  0  0  0  1   0  0  0  0  1  6683
SFSetGraph             2 1.0 5.3417e-04 1.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.2130e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  1  0  0   0  0  1  0  0     0
SFBcastOpBegin       512 1.0 3.2293e-01 2.1 0.00e+00 0.0 7.5e+04 4.6e+04 0.0e+00  0  0 98 68  0   0  0 98 68  0     0
SFBcastOpEnd         512 1.0 7.5116e+0081.5 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  2  0  0  0  0   2  0  0  0  0     0
SFPack               512 1.0 3.1060e-01 2.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack             512 1.0 3.3277e-04 1.6 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               2 1.0 2.3189e+00 1.0 1.23e+09 1.1 1.5e+03 4.6e+04 2.3e+01  2  2  2  1  3   2  2  2  1  3 10093
KSPSolve               1 1.0 1.0518e+02 1.0 5.66e+10 1.1 7.5e+04 4.6e+04 7.7e+02 78100 97 68 95  78100 97 68 95 10224
KSPGMRESOrthog        10 1.0 1.7737e-01 3.4 9.34e+07 1.1 0.0e+00 0.0e+00 1.0e+01  0  0  0  0  1   0  0  0  0  1 10072
PCSetUp                1 1.0 2.3177e+00 1.0 1.23e+09 1.1 1.5e+03 4.6e+04 2.3e+01  2  2  2  1  3   2  2  2  1  3 10098
PCApply              262 1.0 8.2560e+01 1.0 4.13e+10 1.1 3.7e+04 4.6e+04 0.0e+00 60 73 48 33  0  60 73 48 33  0  9492
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     3              3    354240752     0.
           Index Set     4              4       304416     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    29             29     88992944     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     4              4        35216     0.
      Preconditioner     4              4         4256     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 2.88e-08
Average time for MPI_Barrier(): 4.802e-06
Average time for zero size MPI_Send(): 3.6675e-06
#PETSc Option Table entries:
-d 3
-ksp_type cg
-log_view
-mat_type aij
-n 100
-pc_type mg
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type gmres -pc_type bjacobi -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 15:34:23 2020            |
| OS:             Linux                               |
| HostName:       sdumont6181                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.84522, Active time=2.88541                                       |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.4023      0.000008    0.4023      0.000008    13.94    13.94    |
| Ke                            50792      1.7585      0.000035    1.7585      0.000035    60.94    60.94    |
| elem init                     50792      0.7246      0.000014    0.7246      0.000014    25.11    25.11    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.8854                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 165.842729
Tempo total: 165.862516
Tempo total: 165.857802
Tempo total: 165.863660
Tempo total: 165.830444
Tempo total: 165.829994
Tempo total: 165.847737
Tempo total: 165.828216
Tempo total: 165.806226
Tempo total: 165.812161
Tempo total: 165.837371
Tempo total: 165.825706
Tempo total: 165.805060
Tempo total: 165.804960
Tempo total: 165.801370
Tempo total: 165.806384
Tempo total: 165.803389
Tempo total: 165.813844
Tempo total: 165.839799
Tempo total: 165.845196
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6181 with 20 processors, by luciano.siqueira Thu Dec 10 15:36:41 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           1.662e+02     1.000   1.662e+02
Objects:              6.400e+01     1.000   6.400e+01
Flop:                 1.036e+11     1.104   9.855e+10  1.971e+12
Flop/sec:             6.232e+08     1.104   5.929e+08  1.186e+10
MPI Messages:         8.578e+03     2.726   5.707e+03  1.141e+05
MPI Message Lengths:  4.300e+08     1.703   5.918e+04  6.755e+09
MPI Reductions:       1.556e+03     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 1.6621e+02 100.0%  1.9710e+12 100.0%  1.141e+05 100.0%  5.918e+04      100.0%  1.549e+03  99.6%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 4.2076e-0196.6 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  0  0  0  0  0   0  0  0  0  0     0
BuildTwoSidedF         5 1.0 4.1790e-01109.3 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  0  0  0  3  0   0  0  0  3  0     0
MatMult              768 1.0 6.2691e+01 1.1 4.10e+10 1.1 1.1e+05 4.6e+04 0.0e+00 37 40 98 76  0  37 40 98 76  0 12492
MatSolve             769 1.0 6.1059e+01 1.1 4.02e+10 1.1 0.0e+00 0.0e+00 0.0e+00 35 39  0  0  0  35 39  0  0  0 12452
MatLUFactorNum         1 1.0 2.4454e+00 1.1 1.27e+09 1.1 0.0e+00 0.0e+00 0.0e+00  1  1  0  0  0   1  1  0  0  0  9895
MatILUFactorSym        1 1.0 1.5508e-01 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatAssemblyBegin       2 1.0 5.3297e-01 3.1 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  0  0  0  3  0   0  0  0  3  0     0
MatAssemblyEnd         2 1.0 3.2378e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  0  0  0  0  0   0  0  0  0  0    13
MatGetRowIJ            1 1.0 3.9700e-06 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatGetOrdering         1 1.0 4.2097e-03 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatZeroEntries         3 1.0 1.2181e-01 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecMDot              743 1.0 1.1365e+01 2.6 9.71e+09 1.1 0.0e+00 0.0e+00 7.4e+02  5  9  0  0 48   5  9  0  0 48 16343
VecNorm              769 1.0 1.1799e+00 2.6 6.53e+08 1.1 0.0e+00 0.0e+00 7.7e+02  0  1  0  0 49   0  1  0  0 50 10585
VecScale             768 1.0 1.9615e-01 1.1 3.26e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 31795
VecCopy               26 1.0 1.8146e-02 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet               799 1.0 3.7264e-01 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY               50 1.0 3.1028e-02 1.2 4.25e+07 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 26172
VecMAXPY             768 1.0 6.1606e+00 1.1 1.03e+10 1.1 0.0e+00 0.0e+00 0.0e+00  4 10  0  0  0   4 10  0  0  0 32107
VecAssemblyBegin       3 1.0 1.0166e-02 1.1 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAssemblyEnd         3 1.0 6.0506e-04 4.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecScatterBegin      769 1.0 3.5837e-01 2.6 0.00e+00 0.0 1.1e+05 4.6e+04 0.0e+00  0  0 98 76  0   0  0 98 76  0     0
VecScatterEnd        769 1.0 6.2580e+0055.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  2  0  0  0  0   2  0  0  0  0     0
VecNormalize         768 1.0 1.3627e+00 2.2 9.79e+08 1.1 0.0e+00 0.0e+00 7.7e+02  1  1  0  0 49   1  1  0  0 50 13730
SFSetGraph             2 1.0 4.9917e-04 1.8 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.1431e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  1  0  0   0  0  1  0  0     0
SFBcastOpBegin       769 1.0 3.5700e-01 2.6 0.00e+00 0.0 1.1e+05 4.6e+04 0.0e+00  0  0 98 76  0   0  0 98 76  0     0
SFBcastOpEnd         769 1.0 6.2564e+0056.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  2  0  0  0  0   2  0  0  0  0     0
SFPack               769 1.0 3.4317e-01 2.7 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack             769 1.0 5.2715e-04 1.6 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               2 1.0 2.6397e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSolve               1 1.0 1.3675e+02 1.0 1.04e+11 1.1 1.1e+05 4.6e+04 1.5e+03 82100 98 76 97  82100 98 76 98 14411
KSPGMRESOrthog       743 1.0 1.6707e+01 1.6 1.94e+10 1.1 0.0e+00 0.0e+00 7.4e+02  8 19  0  0 48   8 19  0  0 48 22235
PCSetUp                2 1.0 2.6128e+00 1.1 1.27e+09 1.1 0.0e+00 0.0e+00 0.0e+00  1  1  0  0  0   1  1  0  0  0  9261
PCSetUpOnBlocks        1 1.0 2.6048e+00 1.1 1.27e+09 1.1 0.0e+00 0.0e+00 0.0e+00  1  1  0  0  0   1  1  0  0  0  9289
PCApply              769 1.0 6.1426e+01 1.1 4.02e+10 1.1 0.0e+00 0.0e+00 0.0e+00 35 39  0  0  0  35 39  0  0  0 12378
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     4              4    666933972     0.
           Index Set     7              7      5403804     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    43             43    129789840     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     2              2        20072     0.
      Preconditioner     2              2         1944     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 2.87e-08
Average time for MPI_Barrier(): 4.9898e-06
Average time for zero size MPI_Send(): 3.30555e-06
#PETSc Option Table entries:
-d 3
-ksp_type gmres
-log_view
-mat_type aij
-n 100
-pc_type bjacobi
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type gmres -pc_type jacobi -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 15:37:11 2020            |
| OS:             Linux                               |
| HostName:       sdumont6181                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.88239, Active time=2.89962                                       |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.4033      0.000008    0.4033      0.000008    13.91    13.91    |
| Ke                            50792      1.7704      0.000035    1.7704      0.000035    61.06    61.06    |
| elem init                     50792      0.7260      0.000014    0.7260      0.000014    25.04    25.04    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.8996                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 191.669493
Tempo total: 191.675033
Tempo total: 191.687333
Tempo total: 191.642626
Tempo total: 191.625787
Tempo total: 191.649261
Tempo total: 191.650349
Tempo total: 191.642173
Tempo total: 191.645940
Tempo total: 191.638127
Tempo total: 191.630341
Tempo total: 191.640284
Tempo total: 191.636691
Tempo total: 191.627837
Tempo total: 191.628431
Tempo total: 191.623784
Tempo total: 191.640901
Tempo total: 191.629628
Tempo total: 191.634220
Tempo total: 191.674793
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6181 with 20 processors, by luciano.siqueira Thu Dec 10 15:39:56 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           1.920e+02     1.000   1.920e+02
Objects:              5.700e+01     1.000   5.700e+01
Flop:                 1.351e+11     1.098   1.290e+11  2.580e+12
Flop/sec:             7.034e+08     1.098   6.717e+08  1.343e+10
MPI Messages:         1.839e+04     2.739   1.222e+04  2.444e+05
MPI Message Lengths:  8.312e+08     1.821   5.208e+04  1.273e+10
MPI Reductions:       3.313e+03     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 1.9203e+02 100.0%  2.5797e+12 100.0%  2.444e+05 100.0%  5.208e+04      100.0%  3.306e+03  99.8%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 4.6019e-0191.0 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  0  0  0  0  0   0  0  0  0  0     0
BuildTwoSidedF         5 1.0 4.5864e-01102.9 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  0  0  0  2  0   0  0  0  2  0     0
MatMult             1660 1.0 1.3535e+02 1.0 8.87e+10 1.1 2.4e+05 4.6e+04 0.0e+00 69 66 99 87  0  69 66 99 87  0 12507
MatAssemblyBegin       2 1.0 5.3937e-01 3.9 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  0  0  0  2  0   0  0  0  2  0     0
MatAssemblyEnd         2 1.0 3.4127e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  0  0  0  0  0   0  0  0  0  0    13
MatZeroEntries         3 1.0 1.2201e-01 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecMDot             1606 1.0 1.5067e+01 1.5 2.11e+10 1.1 0.0e+00 0.0e+00 1.6e+03  7 16  0  0 48   7 16  0  0 49 26712
VecNorm             1661 1.0 2.2738e+00 2.2 1.41e+09 1.1 0.0e+00 0.0e+00 1.7e+03  1  1  0  0 50   1  1  0  0 50 11864
VecScale            1660 1.0 6.0817e-01 1.1 7.05e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 22165
VecCopy               55 1.0 3.8336e-02 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet                59 1.0 3.0659e-02 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY              108 1.0 6.5520e-02 1.2 9.17e+07 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 26771
VecMAXPY            1660 1.0 1.3865e+01 1.1 2.24e+10 1.1 0.0e+00 0.0e+00 0.0e+00  7 17  0  0  0   7 17  0  0  0 30909
VecAssemblyBegin       3 1.0 1.0482e-02 1.1 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAssemblyEnd         3 1.0 6.0958e-04 4.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecPointwiseMult    1661 1.0 2.1685e+00 1.2 7.05e+08 1.1 0.0e+00 0.0e+00 0.0e+00  1  1  0  0  0   1  1  0  0  0  6220
VecScatterBegin     1661 1.0 9.0098e-01 2.3 0.00e+00 0.0 2.4e+05 4.6e+04 0.0e+00  0  0 99 87  0   0  0 99 87  0     0
VecScatterEnd       1661 1.0 1.2792e+0150.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  3  0  0  0  0   3  0  0  0  0     0
VecNormalize        1660 1.0 2.8509e+00 1.8 2.12e+09 1.1 0.0e+00 0.0e+00 1.7e+03  1  2  0  0 50   1  2  0  0 50 14185
SFSetGraph             2 1.0 5.1700e-04 1.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.1866e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFBcastOpBegin      1661 1.0 8.9807e-01 2.4 0.00e+00 0.0 2.4e+05 4.6e+04 0.0e+00  0  0 99 87  0   0  0 99 87  0     0
SFBcastOpEnd        1661 1.0 1.2789e+0150.8 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  3  0  0  0  0   3  0  0  0  0     0
SFPack              1661 1.0 8.6829e-01 2.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack            1661 1.0 1.2570e-03 1.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               1 1.0 2.6471e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSolve               1 1.0 1.6337e+02 1.0 1.35e+11 1.1 2.4e+05 4.6e+04 3.3e+03 85100 99 87 99  85100 99 87 99 15789
KSPGMRESOrthog      1606 1.0 2.8007e+01 1.2 4.21e+10 1.1 0.0e+00 0.0e+00 1.6e+03 13 31  0  0 48  13 31  0  0 49 28741
PCSetUp                1 1.0 7.4800e-07 2.8 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
PCApply             1661 1.0 2.2426e+00 1.2 7.05e+08 1.1 0.0e+00 0.0e+00 2.0e+00  1  1  0  0  0   1  1  0  0  0  6015
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     3              3    344047400     0.
           Index Set     4              4       304416     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    42             42    133186184     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     1              1        18656     0.
      Preconditioner     1              1          968     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 2.78e-08
Average time for MPI_Barrier(): 5.0896e-06
Average time for zero size MPI_Send(): 3.22095e-06
#PETSc Option Table entries:
-d 3
-ksp_type gmres
-log_view
-mat_type aij
-n 100
-pc_type jacobi
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type gmres -pc_type sor -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 15:40:27 2020            |
| OS:             Linux                               |
| HostName:       sdumont6181                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.86955, Active time=2.89768                                       |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.4131      0.000008    0.4131      0.000008    14.26    14.26    |
| Ke                            50792      1.7597      0.000035    1.7597      0.000035    60.73    60.73    |
| elem init                     50792      0.7249      0.000014    0.7249      0.000014    25.02    25.02    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.8977                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 247.325503
Tempo total: 247.329665
Tempo total: 247.282260
Tempo total: 247.289867
Tempo total: 247.310808
Tempo total: 247.294364
Tempo total: 247.309369
Tempo total: 247.281054
Tempo total: 247.312339
Tempo total: 247.268376
Tempo total: 247.263797
Tempo total: 247.281930
Tempo total: 247.272921
Tempo total: 247.265741
Tempo total: 247.283256
Tempo total: 247.266606
Tempo total: 247.280703
Tempo total: 247.263490
Tempo total: 247.285355
Tempo total: 247.338327
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6181 with 20 processors, by luciano.siqueira Thu Dec 10 15:44:06 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           2.478e+02     1.000   2.478e+02
Objects:              5.600e+01     1.000   5.600e+01
Flop:                 1.363e+11     1.104   1.296e+11  2.593e+12
Flop/sec:             5.498e+08     1.104   5.231e+08  1.046e+10
MPI Messages:         1.134e+04     2.732   7.540e+03  1.508e+05
MPI Message Lengths:  5.429e+08     1.752   5.594e+04  8.435e+09
MPI Reductions:       2.050e+03     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 2.4783e+02 100.0%  2.5928e+12 100.0%  1.508e+05 100.0%  5.594e+04      100.0%  2.043e+03  99.7%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 4.4811e-0190.3 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  0  0  0  0  0   0  0  0  0  0     0
BuildTwoSidedF         5 1.0 4.4821e-01106.5 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  0  0  0  2  0   0  0  0  2  0     0
MatMult             1019 1.0 8.2829e+01 1.0 5.44e+10 1.1 1.5e+05 4.6e+04 0.0e+00 33 40 99 81  0  33 40 99 81  0 12545
MatSOR              1020 1.0 1.2190e+02 1.1 5.37e+10 1.1 0.0e+00 0.0e+00 0.0e+00 47 39  0  0  0  47 39  0  0  0  8341
MatAssemblyBegin       2 1.0 5.3951e-01 3.7 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  0  0  0  2  0   0  0  0  2  0     0
MatAssemblyEnd         2 1.0 3.4258e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  0  0  0  0  0   0  0  0  0  0    13
MatZeroEntries         3 1.0 1.2059e-01 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecMDot              986 1.0 1.8022e+01 3.2 1.29e+10 1.1 0.0e+00 0.0e+00 9.9e+02  5 10  0  0 48   5 10  0  0 48 13726
VecNorm             1020 1.0 1.5866e+00 2.6 8.66e+08 1.1 0.0e+00 0.0e+00 1.0e+03  0  1  0  0 50   0  1  0  0 50 10441
VecScale            1019 1.0 3.0300e-01 1.2 4.33e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 27310
VecCopy               34 1.0 2.3497e-02 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet                38 1.0 1.9161e-02 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY               66 1.0 3.9682e-02 1.2 5.61e+07 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 27012
VecMAXPY            1019 1.0 8.2277e+00 1.1 1.38e+10 1.1 0.0e+00 0.0e+00 0.0e+00  3 10  0  0  0   3 10  0  0  0 32012
VecAssemblyBegin       3 1.0 1.0813e-02 1.1 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAssemblyEnd         3 1.0 5.8033e-04 4.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecScatterBegin     1020 1.0 5.0532e-01 2.7 0.00e+00 0.0 1.5e+05 4.6e+04 0.0e+00  0  0 99 81  0   0  0 99 81  0     0
VecScatterEnd       1020 1.0 7.7454e+0053.7 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
VecNormalize        1019 1.0 1.8409e+00 2.1 1.30e+09 1.1 0.0e+00 0.0e+00 1.0e+03  1  1  0  0 50   1  1  0  0 50 13485
SFSetGraph             2 1.0 5.3227e-04 1.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.1656e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFBcastOpBegin      1020 1.0 5.0363e-01 2.7 0.00e+00 0.0 1.5e+05 4.6e+04 0.0e+00  0  0 99 81  0   0  0 99 81  0     0
SFBcastOpEnd        1020 1.0 7.7432e+0054.7 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
SFPack              1020 1.0 4.8462e-01 2.8 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack            1020 1.0 8.5462e-04 2.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               1 1.0 2.6370e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSolve               1 1.0 2.1810e+02 1.0 1.36e+11 1.1 1.5e+05 4.6e+04 2.0e+03 88100 99 81 98  88100 99 81 98 11887
KSPGMRESOrthog       986 1.0 2.5192e+01 1.9 2.59e+10 1.1 0.0e+00 0.0e+00 9.9e+02  8 19  0  0 48   8 19  0  0 48 19639
PCSetUp                1 1.0 3.9000e-07 2.5 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
PCApply             1020 1.0 1.2190e+02 1.1 5.37e+10 1.1 0.0e+00 0.0e+00 0.0e+00 47 39  0  0  0  47 39  0  0  0  8341
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     3              3    354240752     0.
           Index Set     4              4       304416     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    41             41    129786704     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     1              1        18656     0.
      Preconditioner     1              1          968     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 2.92e-08
Average time for MPI_Barrier(): 4.8796e-06
Average time for zero size MPI_Send(): 3.4077e-06
#PETSc Option Table entries:
-d 3
-ksp_type gmres
-log_view
-mat_type aij
-n 100
-pc_type sor
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type gmres -pc_type mg -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 15:44:37 2020            |
| OS:             Linux                               |
| HostName:       sdumont6181                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.84676, Active time=2.90288                                       |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.4346      0.000009    0.4346      0.000009    14.97    14.97    |
| Ke                            50792      1.7476      0.000034    1.7476      0.000034    60.20    60.20    |
| elem init                     50792      0.7206      0.000014    0.7206      0.000014    24.83    24.83    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.9029                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 187.467651
Tempo total: 187.488044
Tempo total: 187.443911
Tempo total: 187.455478
Tempo total: 187.470398
Tempo total: 187.461557
Tempo total: 187.441921
Tempo total: 187.469313
Tempo total: 187.469481
Tempo total: 187.463651
Tempo total: 187.433474
Tempo total: 187.434908
Tempo total: 187.455541
Tempo total: 187.438829
Tempo total: 187.451529
Tempo total: 187.437070
Tempo total: 187.452975
Tempo total: 187.427613
Tempo total: 187.447337
Tempo total: 187.459878
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6181 with 20 processors, by luciano.siqueira Thu Dec 10 15:47:17 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           1.878e+02     1.000   1.878e+02
Objects:              8.100e+01     1.000   8.100e+01
Flop:                 9.162e+10     1.105   8.713e+10  1.743e+12
Flop/sec:             4.878e+08     1.105   4.639e+08  9.278e+09
MPI Messages:         8.412e+03     2.726   5.598e+03  1.120e+05
MPI Message Lengths:  4.233e+08     1.699   5.944e+04  6.654e+09
MPI Reductions:       7.980e+02     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 1.8783e+02 100.0%  1.7426e+12 100.0%  1.120e+05 100.0%  5.944e+04      100.0%  7.910e+02  99.1%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 4.5709e-01112.1 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  0  0  0  0  1   0  0  0  0  1     0
BuildTwoSidedF         5 1.0 4.5700e-01134.0 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  0  0  0  3  1   0  0  0  3  1     0
MatMult              753 1.0 6.5655e+01 1.1 4.02e+10 1.1 1.1e+05 4.6e+04 0.0e+00 33 44 98 76  0  33 44 98 76  0 11695
MatSOR               755 1.0 9.0405e+01 1.1 3.98e+10 1.1 0.0e+00 0.0e+00 0.0e+00 46 43  0  0  0  46 43  0  0  0  8325
MatAssemblyBegin       2 1.0 5.3147e-01 3.7 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  0  0  0  3  0   0  0  0  3  0     0
MatAssemblyEnd         2 1.0 3.3775e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  0  0  0  0  1   0  0  0  0  1    13
MatZeroEntries         3 1.0 1.2229e-01 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecMDot              369 1.0 8.1054e+00 4.0 4.76e+09 1.1 0.0e+00 0.0e+00 3.7e+02  3  5  0  0 46   3  5  0  0 47 11231
VecNorm              383 1.0 6.3715e-01 2.5 3.25e+08 1.1 0.0e+00 0.0e+00 3.8e+02  0  0  0  0 48   0  0  0  0 48  9763
VecScale             382 1.0 1.0484e-01 1.4 1.62e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 29588
VecCopy              758 1.0 5.1387e-01 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet               763 1.0 2.3682e-01 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY               25 1.0 1.7003e-02 1.3 2.12e+07 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 23880
VecAYPX              744 1.0 8.3465e-01 1.1 4.74e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 10858
VecAXPBYCZ           372 1.0 5.0231e-01 1.1 7.90e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 30070
VecMAXPY             382 1.0 3.0356e+00 1.1 5.07e+09 1.1 0.0e+00 0.0e+00 0.0e+00  2  6  0  0  0   2  6  0  0  0 31962
VecAssemblyBegin       3 1.0 1.0422e-02 1.2 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAssemblyEnd         3 1.0 5.8766e-04 4.5 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecScatterBegin      754 1.0 4.2553e-01 2.4 0.00e+00 0.0 1.1e+05 4.6e+04 0.0e+00  0  0 98 76  0   0  0 98 76  0     0
VecScatterEnd        754 1.0 1.0683e+0146.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  2  0  0  0  0   2  0  0  0  0     0
VecNormalize         382 1.0 7.3422e-01 2.2 4.87e+08 1.1 0.0e+00 0.0e+00 3.8e+02  0  1  0  0 48   0  1  0  0 48 12675
SFSetGraph             2 1.0 5.1507e-04 1.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.1426e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  1  0  0   0  0  1  0  0     0
SFBcastOpBegin       754 1.0 4.2408e-01 2.4 0.00e+00 0.0 1.1e+05 4.6e+04 0.0e+00  0  0 98 76  0   0  0 98 76  0     0
SFBcastOpEnd         754 1.0 1.0681e+0146.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  2  0  0  0  0   2  0  0  0  0     0
SFPack               754 1.0 4.0732e-01 2.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack             754 1.0 5.2682e-04 1.7 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               2 1.0 2.3255e+00 1.0 1.23e+09 1.1 1.5e+03 4.6e+04 2.3e+01  1  1  1  1  3   1  1  1  1  3 10064
KSPSolve               1 1.0 1.5835e+02 1.0 9.16e+10 1.1 1.1e+05 4.6e+04 7.5e+02 84100 98 76 94  84100 98 76 95 11004
KSPGMRESOrthog       369 1.0 1.0734e+01 2.2 9.52e+09 1.1 0.0e+00 0.0e+00 3.7e+02  4 10  0  0 46   4 10  0  0 47 16962
PCSetUp                1 1.0 2.3233e+00 1.0 1.23e+09 1.1 1.5e+03 4.6e+04 2.3e+01  1  1  1  1  3   1  1  1  1  3 10074
PCApply              383 1.0 1.2234e+02 1.0 6.09e+10 1.1 5.4e+04 4.6e+04 0.0e+00 64 66 49 37  0  64 66 49 37  0  9450
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     3              3    354240752     0.
           Index Set     4              4       304416     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    60             60    194376824     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     4              4        52200     0.
      Preconditioner     4              4         4256     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 3.13e-08
Average time for MPI_Barrier(): 4.8088e-06
Average time for zero size MPI_Send(): 3.3808e-06
#PETSc Option Table entries:
-d 3
-ksp_type gmres
-log_view
-mat_type aij
-n 100
-pc_type mg
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type fcg -pc_type bjacobi -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 15:47:48 2020            |
| OS:             Linux                               |
| HostName:       sdumont6181                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.8234, Active time=2.87067                                        |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.3972      0.000008    0.3972      0.000008    13.84    13.84    |
| Ke                            50792      1.7556      0.000035    1.7556      0.000035    61.16    61.16    |
| elem init                     50792      0.7179      0.000014    0.7179      0.000014    25.01    25.01    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.8707                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 104.992981
Tempo total: 104.932700
Tempo total: 104.917436
Tempo total: 104.945661
Tempo total: 104.947020
Tempo total: 104.916560
Tempo total: 104.915301
Tempo total: 104.898074
Tempo total: 104.908755
Tempo total: 104.902103
Tempo total: 104.902160
Tempo total: 104.889630
Tempo total: 104.876460
Tempo total: 104.886301
Tempo total: 104.898014
Tempo total: 104.892621
Tempo total: 104.901272
Tempo total: 104.894736
Tempo total: 104.899248
Tempo total: 104.996973
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6181 with 20 processors, by luciano.siqueira Thu Dec 10 15:49:05 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           1.053e+02     1.000   1.053e+02
Objects:              9.400e+01     1.000   9.400e+01
Flop:                 5.619e+10     1.104   5.346e+10  1.069e+12
Flop/sec:             5.334e+08     1.104   5.076e+08  1.015e+10
MPI Messages:         4.562e+03     2.706   3.043e+03  6.086e+04
MPI Message Lengths:  2.659e+08     1.572   7.085e+04  4.311e+09
MPI Reductions:       1.653e+03     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 1.0533e+02 100.0%  1.0692e+12 100.0%  6.086e+04 100.0%  7.085e+04      100.0%  1.646e+03  99.6%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 4.9707e-0198.2 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  0  0  1  0  0   0  0  1  0  0     0
BuildTwoSidedF         5 1.0 4.9746e-01114.3 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  0  0  1  5  0   0  0  1  5  0     0
MatMult              403 1.0 3.3010e+01 1.1 2.15e+10 1.1 5.9e+04 4.6e+04 0.0e+00 31 38 97 63  0  31 38 97 63  0 12449
MatSolve             404 1.0 3.2135e+01 1.1 2.11e+10 1.1 0.0e+00 0.0e+00 0.0e+00 29 37  0  0  0  29 37  0  0  0 12430
MatLUFactorNum         1 1.0 2.4557e+00 1.1 1.27e+09 1.1 0.0e+00 0.0e+00 0.0e+00  2  2  0  0  0   2  2  0  0  0  9853
MatILUFactorSym        1 1.0 1.5313e-01 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatAssemblyBegin       2 1.0 5.7261e-01 2.7 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  0  0  0  5  0   0  0  0  5  0     0
MatAssemblyEnd         2 1.0 3.4301e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  0  0  0  0  0   0  0  0  0  0    13
MatGetRowIJ            1 1.0 3.9800e-06 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatGetOrdering         1 1.0 4.1431e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatZeroEntries         3 1.0 1.2194e-01 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecTDot              804 1.0 2.2399e+00 4.0 6.83e+08 1.1 0.0e+00 0.0e+00 8.0e+02  1  1  0  0 49   1  1  0  0 49  5830
VecMTDot             401 1.0 2.5676e+00 1.0 5.19e+09 1.1 0.0e+00 0.0e+00 4.0e+02  2  9  0  0 24   2  9  0  0 24 38655
VecNorm              404 1.0 3.6548e+0016.4 3.43e+08 1.1 0.0e+00 0.0e+00 4.0e+02  2  1  0  0 24   2  1  0  0 25  1795
VecScale             401 1.0 2.4256e-01 1.1 1.70e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 13425
VecCopy              403 1.0 2.7529e-01 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet               409 1.0 2.0588e-01 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY              804 1.0 7.2042e-01 1.1 6.83e+08 1.1 0.0e+00 0.0e+00 0.0e+00  1  1  0  0  0   1  1  0  0  0 18125
VecAYPX                1 1.0 1.1361e-03 1.1 4.25e+05 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0  7148
VecMAXPY             401 1.0 3.3271e+00 1.1 5.19e+09 1.1 0.0e+00 0.0e+00 0.0e+00  3  9  0  0  0   3  9  0  0  0 29831
VecAssemblyBegin       3 1.0 9.6567e-03 1.0 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAssemblyEnd         3 1.0 6.1755e-04 4.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecScatterBegin      404 1.0 2.5844e-01 2.1 0.00e+00 0.0 5.9e+04 4.6e+04 0.0e+00  0  0 97 63  0   0  0 97 63  0     0
VecScatterEnd        404 1.0 3.4084e+0066.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
SFSetGraph             2 1.0 5.1657e-04 2.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.1559e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  1  0  0   0  0  1  0  0     0
SFBcastOpBegin       404 1.0 2.5757e-01 2.1 0.00e+00 0.0 5.9e+04 4.6e+04 0.0e+00  0  0 97 63  0   0  0 97 63  0     0
SFBcastOpEnd         404 1.0 3.4075e+0067.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
SFPack               404 1.0 2.5043e-01 2.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack             404 1.0 2.4175e-04 1.6 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               2 1.0 1.5542e-02 1.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSolve               1 1.0 7.5812e+01 1.0 5.62e+10 1.1 5.9e+04 4.6e+04 1.6e+03 72100 97 63 97  72100 97 63 98 14101
PCSetUp                2 1.0 2.6200e+00 1.1 1.27e+09 1.1 0.0e+00 0.0e+00 0.0e+00  2  2  0  0  0   2  2  0  0  0  9235
PCSetUpOnBlocks        1 1.0 2.6130e+00 1.1 1.27e+09 1.1 0.0e+00 0.0e+00 0.0e+00  2  2  0  0  0   2  2  0  0  0  9260
PCApply              404 1.0 3.2345e+01 1.1 2.11e+10 1.1 0.0e+00 0.0e+00 0.0e+00 29 37  0  0  0  29 37  0  0  0 12349
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     4              4    666933972     0.
           Index Set     7              7      5403804     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    73             73    231774240     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     2              2         4264     0.
      Preconditioner     2              2         1944     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 2.74e-08
Average time for MPI_Barrier(): 5.0068e-06
Average time for zero size MPI_Send(): 3.41505e-06
#PETSc Option Table entries:
-d 3
-ksp_type fcg
-log_view
-mat_type aij
-n 100
-pc_type bjacobi
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type fcg -pc_type jacobi -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 15:49:36 2020            |
| OS:             Linux                               |
| HostName:       sdumont6181                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.89242, Active time=2.90431                                       |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.4077      0.000008    0.4077      0.000008    14.04    14.04    |
| Ke                            50792      1.7698      0.000035    1.7698      0.000035    60.94    60.94    |
| elem init                     50792      0.7268      0.000014    0.7268      0.000014    25.03    25.03    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.9043                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 43.137323
Tempo total: 43.128483
Tempo total: 43.159016
Tempo total: 43.150434
Tempo total: 43.144015
Tempo total: 43.137139
Tempo total: 43.119078
Tempo total: 43.127572
Tempo total: 43.129501
Tempo total: 43.124844
Tempo total: 43.137378
Tempo total: 43.118833
Tempo total: 43.130902
Tempo total: 43.116601
Tempo total: 43.124273
Tempo total: 43.104383
Tempo total: 43.089845
Tempo total: 43.117225
Tempo total: 43.098744
Tempo total: 43.156730
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6181 with 20 processors, by luciano.siqueira Thu Dec 10 15:49:51 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           4.353e+01     1.000   4.353e+01
Objects:              8.700e+01     1.000   8.700e+01
Flop:                 1.131e+10     1.098   1.080e+10  2.159e+11
Flop/sec:             2.597e+08     1.098   2.480e+08  4.960e+09
MPI Messages:         1.626e+03     2.630   1.094e+03  2.187e+04
MPI Message Lengths:  1.458e+08     1.348   1.154e+05  2.524e+09
MPI Reductions:       5.870e+02     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 4.3530e+01 100.0%  2.1593e+11 100.0%  2.187e+04 100.0%  1.154e+05      100.0%  5.800e+02  98.8%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 4.0671e-0182.4 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  1  0  2  0  1   1  0  2  0  1     0
BuildTwoSidedF         5 1.0 4.0404e-0196.0 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  1  0  2  8  1   1  0  2  8  1     0
MatMult              136 1.0 1.1096e+01 1.0 7.27e+09 1.1 2.0e+04 4.6e+04 0.0e+00 25 64 91 36  0  25 64 91 36  0 12499
MatAssemblyBegin       2 1.0 5.8522e-01 4.1 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  1  0  1  8  0   1  0  1  8  0     0
MatAssemblyEnd         2 1.0 3.4272e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  1  0  1  0  1   1  0  1  0  1    13
MatZeroEntries         3 1.0 1.2211e-01 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecTDot              270 1.0 7.0909e-01 4.0 2.29e+08 1.1 0.0e+00 0.0e+00 2.7e+02  1  2  0  0 46   1  2  0  0 47  6184
VecMTDot             134 1.0 8.8014e-01 1.0 1.67e+09 1.1 0.0e+00 0.0e+00 1.3e+02  2 15  0  0 23   2 15  0  0 23 36260
VecNorm              137 1.0 1.3591e-01 1.7 1.16e+08 1.1 0.0e+00 0.0e+00 1.4e+02  0  1  0  0 23   0  1  0  0 24 16371
VecScale             134 1.0 7.3183e-02 1.1 5.69e+07 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 14869
VecCopy              136 1.0 1.1025e-01 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet                 5 1.0 1.7660e-03 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY              270 1.0 2.4180e-01 1.2 2.29e+08 1.1 0.0e+00 0.0e+00 0.0e+00  1  2  0  0  0   1  2  0  0  0 18135
VecAYPX                1 1.0 1.1872e-03 1.2 4.25e+05 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0  6840
VecMAXPY             134 1.0 1.0563e+00 1.1 1.67e+09 1.1 0.0e+00 0.0e+00 0.0e+00  2 15  0  0  0   2 15  0  0  0 30212
VecAssemblyBegin       3 1.0 9.6344e-03 1.0 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  1  0  1   0  0  1  0  1     0
VecAssemblyEnd         3 1.0 6.2234e-04 4.6 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecPointwiseMult     137 1.0 1.8930e-01 1.1 5.82e+07 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0  5877
VecScatterBegin      137 1.0 8.3574e-02 2.1 0.00e+00 0.0 2.0e+04 4.6e+04 0.0e+00  0  0 91 36  0   0  0 91 36  0     0
VecScatterEnd        137 1.0 1.0509e+0058.6 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
SFSetGraph             2 1.0 5.1271e-04 1.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.1590e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  3  0  0   0  0  3  0  0     0
SFBcastOpBegin       137 1.0 8.3338e-02 2.1 0.00e+00 0.0 2.0e+04 4.6e+04 0.0e+00  0  0 91 36  0   0  0 91 36  0     0
SFBcastOpEnd         137 1.0 1.0507e+0059.5 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
SFPack               137 1.0 8.0471e-02 2.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack             137 1.0 8.6467e-05 1.6 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               1 1.0 1.5591e-02 1.5 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSolve               1 1.0 1.4006e+01 1.0 1.13e+10 1.1 2.0e+04 4.6e+04 5.4e+02 32100 91 36 93  32100 91 36 94 15401
PCSetUp                1 1.0 1.1140e-06 6.6 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
PCApply              137 1.0 2.6392e-01 1.1 5.82e+07 1.1 0.0e+00 0.0e+00 2.0e+00  1  1  0  0  0   1  1  0  0  0  4215
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     3              3    344047400     0.
           Index Set     4              4       304416     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    72             72    235170584     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     1              1         2848     0.
      Preconditioner     1              1          968     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 2.85e-08
Average time for MPI_Barrier(): 4.8588e-06
Average time for zero size MPI_Send(): 3.3074e-06
#PETSc Option Table entries:
-d 3
-ksp_type fcg
-log_view
-mat_type aij
-n 100
-pc_type jacobi
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type fcg -pc_type sor -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 15:50:22 2020            |
| OS:             Linux                               |
| HostName:       sdumont6181                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.89039, Active time=2.90676                                       |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.4011      0.000008    0.4011      0.000008    13.80    13.80    |
| Ke                            50792      1.7803      0.000035    1.7803      0.000035    61.25    61.25    |
| elem init                     50792      0.7254      0.000014    0.7254      0.000014    24.95    24.95    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.9068                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 131.069209
Tempo total: 131.026605
Tempo total: 131.001582
Tempo total: 131.041931
Tempo total: 131.026240
Tempo total: 131.005878
Tempo total: 131.016161
Tempo total: 131.014307
Tempo total: 131.020219
Tempo total: 131.019574
Tempo total: 131.012994
Tempo total: 130.997965
Tempo total: 131.015678
Tempo total: 131.000883
Tempo total: 130.983043
Tempo total: 130.999755
Tempo total: 131.006298
Tempo total: 131.026625
Tempo total: 131.062595
Tempo total: 131.001152
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6181 with 20 processors, by luciano.siqueira Thu Dec 10 15:52:05 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           1.314e+02     1.000   1.314e+02
Objects:              8.600e+01     1.000   8.600e+01
Flop:                 6.293e+10     1.104   5.988e+10  1.198e+12
Flop/sec:             4.789e+08     1.104   4.557e+08  9.113e+09
MPI Messages:         5.190e+03     2.711   3.459e+03  6.918e+04
MPI Message Lengths:  2.915e+08     1.600   6.784e+04  4.693e+09
MPI Reductions:       1.881e+03     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 1.3141e+02 100.0%  1.1976e+12 100.0%  6.918e+04 100.0%  6.784e+04      100.0%  1.874e+03  99.6%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 4.8441e-0199.5 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  0  0  1  0  0   0  0  1  0  0     0
BuildTwoSidedF         5 1.0 4.8338e-01116.7 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  0  0  1  4  0   0  0  1  4  0     0
MatMult              460 1.0 3.7589e+01 1.1 2.46e+10 1.1 6.7e+04 4.6e+04 0.0e+00 28 39 97 66  0  28 39 97 66  0 12479
MatSOR               461 1.0 5.5022e+01 1.1 2.43e+10 1.1 0.0e+00 0.0e+00 0.0e+00 40 38  0  0  0  40 38  0  0  0  8352
MatAssemblyBegin       2 1.0 5.5587e-01 4.1 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  0  0  0  4  0   0  0  0  4  0     0
MatAssemblyEnd         2 1.0 3.4272e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  0  0  0  0  0   0  0  0  0  0    13
MatZeroEntries         3 1.0 1.2142e-01 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecTDot              918 1.0 2.6141e+00 3.9 7.80e+08 1.1 0.0e+00 0.0e+00 9.2e+02  1  1  0  0 49   1  1  0  0 49  5703
VecMTDot             458 1.0 3.0212e+00 1.0 5.96e+09 1.1 0.0e+00 0.0e+00 4.6e+02  2 10  0  0 24   2 10  0  0 24 37689
VecNorm              461 1.0 6.4717e+0024.6 3.92e+08 1.1 0.0e+00 0.0e+00 4.6e+02  2  1  0  0 25   2  1  0  0 25  1157
VecScale             458 1.0 2.6754e-01 1.1 1.95e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 13902
VecCopy              460 1.0 3.3961e-01 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet                 5 1.0 1.7848e-03 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY              918 1.0 8.1293e-01 1.1 7.80e+08 1.1 0.0e+00 0.0e+00 0.0e+00  1  1  0  0  0   1  1  0  0  0 18340
VecAYPX                1 1.0 1.1990e-03 1.2 4.25e+05 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0  6773
VecMAXPY             458 1.0 3.7911e+00 1.1 5.96e+09 1.1 0.0e+00 0.0e+00 0.0e+00  3 10  0  0  0   3 10  0  0  0 30035
VecAssemblyBegin       3 1.0 9.6383e-03 1.0 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAssemblyEnd         3 1.0 5.5876e-04 4.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecScatterBegin      461 1.0 2.8748e-01 2.1 0.00e+00 0.0 6.7e+04 4.6e+04 0.0e+00  0  0 97 66  0   0  0 97 66  0     0
VecScatterEnd        461 1.0 3.5907e+0060.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
SFSetGraph             2 1.0 5.1431e-04 1.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.1513e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  1  0  0   0  0  1  0  0     0
SFBcastOpBegin       461 1.0 2.8663e-01 2.1 0.00e+00 0.0 6.7e+04 4.6e+04 0.0e+00  0  0 97 66  0   0  0 97 66  0     0
SFBcastOpEnd         461 1.0 3.5897e+0060.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
SFPack               461 1.0 2.7871e-01 2.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack             461 1.0 3.3242e-04 2.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               1 1.0 1.5066e-02 1.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSolve               1 1.0 1.0169e+02 1.0 6.29e+10 1.1 6.7e+04 4.6e+04 1.8e+03 77100 97 66 98  77100 97 66 98 11775
PCSetUp                1 1.0 5.6100e-07 3.6 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
PCApply              461 1.0 5.5023e+01 1.1 2.43e+10 1.1 0.0e+00 0.0e+00 0.0e+00 40 38  0  0  0  40 38  0  0  0  8352
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     3              3    354240752     0.
           Index Set     4              4       304416     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    71             71    231771104     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     1              1         2848     0.
      Preconditioner     1              1          968     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 2.76e-08
Average time for MPI_Barrier(): 4.6842e-06
Average time for zero size MPI_Send(): 3.34605e-06
#PETSc Option Table entries:
-d 3
-ksp_type fcg
-log_view
-mat_type aij
-n 100
-pc_type sor
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type fcg -pc_type mg -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 15:52:36 2020            |
| OS:             Linux                               |
| HostName:       sdumont6181                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.86234, Active time=2.89927                                       |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.3997      0.000008    0.3997      0.000008    13.79    13.79    |
| Ke                            50792      1.7668      0.000035    1.7668      0.000035    60.94    60.94    |
| elem init                     50792      0.7327      0.000014    0.7327      0.000014    25.27    25.27    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.8993                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 138.045069
Tempo total: 138.052240
Tempo total: 138.013786
Tempo total: 138.032756
Tempo total: 138.038086
Tempo total: 138.021903
Tempo total: 138.013120
Tempo total: 138.056496
Tempo total: 138.031026
Tempo total: 138.000836
Tempo total: 138.012144
Tempo total: 138.012859
Tempo total: 138.027011
Tempo total: 138.003891
Tempo total: 138.028286
Tempo total: 138.005357
Tempo total: 138.015773
Tempo total: 138.003523
Tempo total: 137.989822
Tempo total: 138.049501
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6181 with 20 processors, by luciano.siqueira Thu Dec 10 15:54:27 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           1.384e+02     1.000   1.384e+02
Objects:              1.110e+02     1.000   1.110e+02
Flop:                 6.285e+10     1.105   5.977e+10  1.195e+12
Flop/sec:             4.541e+08     1.105   4.318e+08  8.637e+09
MPI Messages:         5.750e+03     2.715   3.831e+03  7.662e+04
MPI Message Lengths:  3.144e+08     1.622   6.570e+04  5.034e+09
MPI Reductions:       1.064e+03     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 1.3842e+02 100.0%  1.1955e+12 100.0%  7.662e+04 100.0%  6.570e+04      100.0%  1.057e+03  99.3%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 4.4565e-01102.6 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  0  0  1  0  1   0  0  1  0  1     0
BuildTwoSidedF         5 1.0 4.4621e-01118.8 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  0  0  0  4  0   0  0  0  4  0     0
MatMult              511 1.0 4.4907e+01 1.1 2.73e+10 1.1 7.5e+04 4.6e+04 0.0e+00 30 44 97 68  0  30 44 97 68  0 11604
MatSOR               513 1.0 6.1174e+01 1.1 2.70e+10 1.1 0.0e+00 0.0e+00 0.0e+00 42 43  0  0  0  42 43  0  0  0  8360
MatAssemblyBegin       2 1.0 5.2744e-01 3.2 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  0  0  0  4  0   0  0  0  4  0     0
MatAssemblyEnd         2 1.0 3.4213e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  0  0  0  0  0   0  0  0  0  0    13
MatZeroEntries         3 1.0 1.2178e-01 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecMDot               10 1.0 1.3788e-01 6.4 4.67e+07 1.1 0.0e+00 0.0e+00 1.0e+01  0  0  0  0  1   0  0  0  0  1  6479
VecTDot              498 1.0 1.5888e+00 4.3 4.23e+08 1.1 0.0e+00 0.0e+00 5.0e+02  1  1  0  0 47   1  1  0  0 47  5091
VecMTDot             248 1.0 1.5531e+00 1.0 3.19e+09 1.1 0.0e+00 0.0e+00 2.5e+02  1  5  0  0 23   1  5  0  0 23 39277
VecNorm              262 1.0 4.1697e+0024.6 2.23e+08 1.1 0.0e+00 0.0e+00 2.6e+02  1  0  0  0 25   1  0  0  0 25  1021
VecScale             259 1.0 1.6386e-01 1.1 1.10e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 12836
VecCopy              753 1.0 5.2841e-01 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet               509 1.0 2.3689e-01 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY              499 1.0 4.4604e-01 1.1 4.24e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 18169
VecAYPX              503 1.0 5.6281e-01 1.1 3.20e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 10879
VecAXPBYCZ           251 1.0 3.6039e-01 1.2 5.33e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 28278
VecMAXPY             259 1.0 2.0998e+00 1.1 3.25e+09 1.1 0.0e+00 0.0e+00 0.0e+00  1  5  0  0  0   1  5  0  0  0 29554
VecAssemblyBegin       3 1.0 9.6482e-03 1.0 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAssemblyEnd         3 1.0 6.1307e-04 4.6 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecScatterBegin      512 1.0 3.1940e-01 2.0 0.00e+00 0.0 7.5e+04 4.6e+04 0.0e+00  0  0 98 68  0   0  0 98 68  0     0
VecScatterEnd        512 1.0 7.5893e+0086.5 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  2  0  0  0  0   2  0  0  0  0     0
VecNormalize          11 1.0 3.2805e-02 3.1 1.40e+07 1.1 0.0e+00 0.0e+00 1.1e+01  0  0  0  0  1   0  0  0  0  1  8169
SFSetGraph             2 1.0 5.1315e-04 1.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.6198e-02 1.7 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  1  0  0   0  0  1  0  0     0
SFBcastOpBegin       512 1.0 3.1826e-01 2.0 0.00e+00 0.0 7.5e+04 4.6e+04 0.0e+00  0  0 98 68  0   0  0 98 68  0     0
SFBcastOpEnd         512 1.0 7.5881e+0087.6 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  2  0  0  0  0   2  0  0  0  0     0
SFPack               512 1.0 3.0669e-01 2.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack             512 1.0 3.3343e-04 1.6 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               2 1.0 2.3309e+00 1.0 1.23e+09 1.1 1.5e+03 4.6e+04 2.3e+01  2  2  2  1  2   2  2  2  1  2 10041
KSPSolve               1 1.0 1.0926e+02 1.0 6.28e+10 1.1 7.5e+04 4.6e+04 1.0e+03 79100 97 68 96  79100 97 68 96 10940
KSPGMRESOrthog        10 1.0 1.6555e-01 3.2 9.34e+07 1.1 0.0e+00 0.0e+00 1.0e+01  0  0  0  0  1   0  0  0  0  1 10792
PCSetUp                1 1.0 2.3202e+00 1.0 1.23e+09 1.1 1.5e+03 4.6e+04 2.3e+01  2  2  2  1  2   2  2  2  1  2 10087
PCApply              262 1.0 8.2750e+01 1.1 4.13e+10 1.1 3.7e+04 4.6e+04 0.0e+00 58 66 48 33  0  58 66 48 33  0  9470
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     3              3    354240752     0.
           Index Set     4              4       304416     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    90             90    296361224     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     4              4        36392     0.
      Preconditioner     4              4         4256     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 2.77e-08
Average time for MPI_Barrier(): 4.6808e-06
Average time for zero size MPI_Send(): 3.3334e-06
#PETSc Option Table entries:
-d 3
-ksp_type fcg
-log_view
-mat_type aij
-n 100
-pc_type mg
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type tcqmr -pc_type bjacobi -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 15:54:57 2020            |
| OS:             Linux                               |
| HostName:       sdumont6181                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.84855, Active time=2.87983                                       |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.3995      0.000008    0.3995      0.000008    13.87    13.87    |
| Ke                            50792      1.7568      0.000035    1.7568      0.000035    61.01    61.01    |
| elem init                     50792      0.7235      0.000014    0.7235      0.000014    25.12    25.12    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.8798                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 330.936058
Tempo total: 330.945391
Tempo total: 330.957072
Tempo total: 330.887841
Tempo total: 330.899903
Tempo total: 330.862516
Tempo total: 330.874680
Tempo total: 330.881413
Tempo total: 330.894700
Tempo total: 330.888347
Tempo total: 330.893312
Tempo total: 330.856171
Tempo total: 330.884104
Tempo total: 330.863937
Tempo total: 330.883639
Tempo total: 330.865163
Tempo total: 330.855076
Tempo total: 330.866776
Tempo total: 330.870897
Tempo total: 330.908017
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6181 with 20 processors, by luciano.siqueira Thu Dec 10 16:00:00 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           3.313e+02     1.000   3.313e+02
Objects:              4.800e+01     1.000   4.800e+01
Flop:                 2.001e+11     1.106   1.901e+11  3.803e+12
Flop/sec:             6.039e+08     1.106   5.740e+08  1.148e+10
MPI Messages:         1.991e+04     2.740   1.323e+04  2.645e+05
MPI Message Lengths:  8.933e+08     1.831   5.160e+04  1.365e+10
MPI Reductions:       3.042e+03     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 3.3127e+02 100.0%  3.8030e+12 100.0%  2.645e+05 100.0%  5.160e+04      100.0%  3.035e+03  99.8%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 4.5184e-0189.3 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  0  0  0  0  0   0  0  0  0  0     0
BuildTwoSidedF         5 1.0 4.5046e-01105.1 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  0  0  0  2  0   0  0  0  2  0     0
MatMult             1798 1.0 1.4705e+02 1.1 9.61e+10 1.1 2.6e+05 4.6e+04 0.0e+00 44 48 99 88  0  44 48 99 88  0 12468
MatSolve            1800 1.0 1.4313e+02 1.1 9.41e+10 1.1 0.0e+00 0.0e+00 0.0e+00 41 47  0  0  0  41 47  0  0  0 12434
MatLUFactorNum         1 1.0 2.4544e+00 1.1 1.27e+09 1.1 0.0e+00 0.0e+00 0.0e+00  1  1  0  0  0   1  1  0  0  0  9859
MatILUFactorSym        1 1.0 1.5436e-01 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatAssemblyBegin       2 1.0 5.3840e-01 3.1 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  0  0  0  2  0   0  0  0  2  0     0
MatAssemblyEnd         2 1.0 3.4255e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  0  0  0  0  0   0  0  0  0  0    13
MatGetRowIJ            1 1.0 3.8970e-06 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatGetOrdering         1 1.0 4.1560e-03 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatZeroEntries         3 1.0 1.2169e-01 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecDot              1797 1.0 7.0551e+00 5.8 1.53e+09 1.1 0.0e+00 0.0e+00 1.8e+03  1  1  0  0 59   1  1  0  0 59  4137
VecNorm             1201 1.0 1.2439e+0119.7 1.02e+09 1.1 0.0e+00 0.0e+00 1.2e+03  2  1  0  0 39   2  1  0  0 40  1568
VecScale            2397 1.0 8.5227e-01 1.2 1.02e+09 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 22839
VecCopy             5396 1.0 4.1376e+00 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
VecSet              1810 1.0 8.4160e-01 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY             5389 1.0 3.5787e+00 1.2 4.58e+09 1.1 0.0e+00 0.0e+00 0.0e+00  1  2  0  0  0   1  2  0  0  0 24457
VecAYPX              599 1.0 6.8089e-01 1.1 5.09e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 14288
VecAssemblyBegin       3 1.0 1.0082e-02 1.1 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAssemblyEnd         3 1.0 5.8859e-04 6.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecScatterBegin     1799 1.0 1.2451e+00 2.1 0.00e+00 0.0 2.6e+05 4.6e+04 0.0e+00  0  0 99 88  0   0  0 99 88  0     0
VecScatterEnd       1799 1.0 1.4383e+0161.8 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  2  0  0  0  0   2  0  0  0  0     0
SFSetGraph             2 1.0 5.1361e-04 1.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.1459e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFBcastOpBegin      1799 1.0 1.2405e+00 2.1 0.00e+00 0.0 2.6e+05 4.6e+04 0.0e+00  0  0 99 88  0   0  0 99 88  0     0
SFBcastOpEnd        1799 1.0 1.4379e+0162.8 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  2  0  0  0  0   2  0  0  0  0     0
SFPack              1799 1.0 1.2028e+00 2.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack            1799 1.0 1.5169e-03 2.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               2 1.0 1.1007e-02 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSolve               1 1.0 3.0172e+02 1.0 2.00e+11 1.1 2.6e+05 4.6e+04 3.0e+03 91100 99 88 99  91100 99 88 99 12604
PCSetUp                2 1.0 2.6201e+00 1.1 1.27e+09 1.1 0.0e+00 0.0e+00 0.0e+00  1  1  0  0  0   1  1  0  0  0  9235
PCSetUpOnBlocks        1 1.0 2.6129e+00 1.1 1.27e+09 1.1 0.0e+00 0.0e+00 0.0e+00  1  1  0  0  0   1  1  0  0  0  9260
PCApply             1800 1.0 1.4399e+02 1.1 9.41e+10 1.1 0.0e+00 0.0e+00 0.0e+00 41 47  0  0  0  41 47  0  0  0 12360
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     4              4    666933972     0.
           Index Set     7              7      5403804     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    27             27     75398160     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     2              2         3016     0.
      Preconditioner     2              2         1944     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 3.5e-08
Average time for MPI_Barrier(): 5.2222e-06
Average time for zero size MPI_Send(): 3.604e-06
#PETSc Option Table entries:
-d 3
-ksp_type tcqmr
-log_view
-mat_type aij
-n 100
-pc_type bjacobi
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type tcqmr -pc_type jacobi -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 16:00:32 2020            |
| OS:             Linux                               |
| HostName:       sdumont6181                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.86108, Active time=2.88962                                       |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.4003      0.000008    0.4003      0.000008    13.85    13.85    |
| Ke                            50792      1.7604      0.000035    1.7604      0.000035    60.92    60.92    |
| elem init                     50792      0.7289      0.000014    0.7289      0.000014    25.23    25.23    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.8896                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 1366.324124
Tempo total: 1366.328165
Tempo total: 1366.311300
Tempo total: 1366.325274
Tempo total: 1366.315280
Tempo total: 1366.315101
Tempo total: 1366.297224
Tempo total: 1366.317028
Tempo total: 1366.286842
Tempo total: 1366.301167
Tempo total: 1366.297154
Tempo total: 1366.279291
Tempo total: 1366.356198
Tempo total: 1366.325227
Tempo total: 1366.352776
Tempo total: 1366.361295
Tempo total: 1366.344288
Tempo total: 1366.336038
Tempo total: 1366.324260
Tempo total: 1366.323790
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6181 with 20 processors, by luciano.siqueira Thu Dec 10 16:22:50 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           1.367e+03     1.000   1.367e+03
Objects:              4.100e+01     1.000   4.100e+01
Flop:                 8.800e+11     1.100   8.400e+11  1.680e+13
Flop/sec:             6.439e+08     1.100   6.146e+08  1.229e+10
MPI Messages:         1.651e+05     2.749   1.096e+05  2.192e+06
MPI Message Lengths:  6.832e+09     1.949   4.654e+04  1.020e+11
MPI Reductions:       2.505e+04     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 1.3667e+03 100.0%  1.6799e+13 100.0%  2.192e+06 100.0%  4.654e+04      100.0%  2.504e+04 100.0%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 4.1569e-0181.7 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  0  0  0  0  0   0  0  0  0  0     0
BuildTwoSidedF         5 1.0 4.1413e-0190.3 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatMult            15001 1.0 1.2290e+03 1.1 8.01e+11 1.1 2.2e+06 4.6e+04 0.0e+00 88 91100 98  0  88 91100 98  0 12447
MatAssemblyBegin       2 1.0 5.2989e-01 3.4 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatAssemblyEnd         2 1.0 3.4097e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  0  0  0  0  0   0  0  0  0  0    13
MatZeroEntries         3 1.0 1.2245e-01 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecDot             15000 1.0 3.2649e+01 3.1 1.27e+10 1.1 0.0e+00 0.0e+00 1.5e+04  1  1  0  0 60   1  1  0  0 60  7462
VecNorm            10003 1.0 4.7787e+01 8.9 8.50e+09 1.1 0.0e+00 0.0e+00 1.0e+04  1  1  0  0 40   1  1  0  0 40  3400
VecScale           20001 1.0 8.6566e+00 1.5 8.49e+09 1.1 0.0e+00 0.0e+00 0.0e+00  1  1  0  0  0   1  1  0  0  0 18762
VecCopy            45005 1.0 3.4613e+01 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  2  0  0  0  0   2  0  0  0  0     0
VecSet                10 1.0 4.4411e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY            44998 1.0 3.3654e+01 1.3 3.82e+10 1.1 0.0e+00 0.0e+00 0.0e+00  2  4  0  0  0   2  4  0  0  0 21716
VecAYPX             5000 1.0 5.7401e+00 1.1 4.25e+09 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 14147
VecAssemblyBegin       3 1.0 1.0552e-02 1.1 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAssemblyEnd         3 1.0 6.0148e-04 4.6 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecPointwiseMult   15003 1.0 1.9826e+01 1.2 6.37e+09 1.1 0.0e+00 0.0e+00 0.0e+00  1  1  0  0  0   1  1  0  0  0  6145
VecScatterBegin    15002 1.0 1.0650e+01 2.2 0.00e+00 0.0 2.2e+06 4.6e+04 0.0e+00  1  0100 98  0   1  0100 98  0     0
VecScatterEnd      15002 1.0 1.1968e+0256.8 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  4  0  0  0  0   4  0  0  0  0     0
SFSetGraph             2 1.0 5.1351e-04 1.8 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.1776e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFBcastOpBegin     15002 1.0 1.0616e+01 2.2 0.00e+00 0.0 2.2e+06 4.6e+04 0.0e+00  1  0100 98  0   1  0100 98  0     0
SFBcastOpEnd       15002 1.0 1.1965e+0257.7 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  4  0  0  0  0   4  0  0  0  0     0
SFPack             15002 1.0 1.0317e+01 2.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
SFUnpack           15002 1.0 9.3317e-03 1.6 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               1 1.0 9.0753e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSolve               1 1.0 1.3371e+03 1.0 8.80e+11 1.1 2.2e+06 4.6e+04 2.5e+04 98100100 98100  98100100 98100 12564
PCSetUp                1 1.0 1.0880e-06 4.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
PCApply            15003 1.0 1.9923e+01 1.2 6.37e+09 1.1 0.0e+00 0.0e+00 2.0e+00  1  1  0  0  0   1  1  0  0  0  6115
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     3              3    344047400     0.
           Index Set     4              4       304416     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    26             26     78794504     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     1              1         1600     0.
      Preconditioner     1              1          968     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 2.78e-08
Average time for MPI_Barrier(): 4.8862e-06
Average time for zero size MPI_Send(): 3.26295e-06
#PETSc Option Table entries:
-d 3
-ksp_type tcqmr
-log_view
-mat_type aij
-n 100
-pc_type jacobi
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type tcqmr -pc_type sor -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 16:23:21 2020            |
| OS:             Linux                               |
| HostName:       sdumont6181                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.83141, Active time=2.87566                                       |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.3986      0.000008    0.3986      0.000008    13.86    13.86    |
| Ke                            50792      1.7568      0.000035    1.7568      0.000035    61.09    61.09    |
| elem init                     50792      0.7202      0.000014    0.7202      0.000014    25.05    25.05    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.8757                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 361.768584
Tempo total: 361.766247
Tempo total: 361.766666
Tempo total: 361.733874
Tempo total: 361.746224
Tempo total: 361.737661
Tempo total: 361.750538
Tempo total: 361.729028
Tempo total: 361.734315
Tempo total: 361.733454
Tempo total: 361.736288
Tempo total: 361.724832
Tempo total: 361.739852
Tempo total: 361.730485
Tempo total: 361.706893
Tempo total: 361.708502
Tempo total: 361.708554
Tempo total: 361.708011
Tempo total: 361.704883
Tempo total: 361.819235
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6181 with 20 processors, by luciano.siqueira Thu Dec 10 16:28:55 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           3.621e+02     1.000   3.621e+02
Objects:              4.000e+01     1.000   4.000e+01
Flop:                 1.796e+11     1.106   1.707e+11  3.414e+12
Flop/sec:             4.959e+08     1.106   4.713e+08  9.427e+09
MPI Messages:         1.793e+04     2.739   1.191e+04  2.382e+05
MPI Message Lengths:  8.124e+08     1.818   5.224e+04  1.244e+10
MPI Reductions:       2.742e+03     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 3.6214e+02 100.0%  3.4139e+12 100.0%  2.382e+05 100.0%  5.224e+04      100.0%  2.735e+03  99.7%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 4.0617e-0182.7 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  0  0  0  0  0   0  0  0  0  0     0
BuildTwoSidedF         5 1.0 4.0611e-0199.3 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  0  0  0  2  0   0  0  0  2  0     0
MatMult             1618 1.0 1.3225e+02 1.1 8.64e+10 1.1 2.4e+05 4.6e+04 0.0e+00 36 48 99 87  0  36 48 99 87  0 12476
MatSOR              1620 1.0 1.9267e+02 1.1 8.53e+10 1.1 0.0e+00 0.0e+00 0.0e+00 51 47  0  0  0  51 47  0  0  0  8382
MatAssemblyBegin       2 1.0 5.2937e-01 3.8 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  0  0  0  2  0   0  0  0  2  0     0
MatAssemblyEnd         2 1.0 3.4262e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  0  0  0  0  0   0  0  0  0  0    13
MatZeroEntries         3 1.0 1.2172e-01 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecDot              1617 1.0 7.8384e+00 6.8 1.37e+09 1.1 0.0e+00 0.0e+00 1.6e+03  1  1  0  0 59   1  1  0  0 59  3350
VecNorm             1081 1.0 1.4072e+0122.0 9.18e+08 1.1 0.0e+00 0.0e+00 1.1e+03  2  1  0  0 39   2  1  0  0 40  1248
VecScale            2157 1.0 7.4357e-01 1.1 9.16e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 23557
VecCopy             4856 1.0 3.7227e+00 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
VecSet                10 1.0 4.4409e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY             4849 1.0 3.2711e+00 1.1 4.12e+09 1.1 0.0e+00 0.0e+00 0.0e+00  1  2  0  0  0   1  2  0  0  0 24076
VecAYPX              539 1.0 6.1491e-01 1.1 4.58e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 14236
VecAssemblyBegin       3 1.0 1.0161e-02 1.1 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAssemblyEnd         3 1.0 6.0887e-04 4.7 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecScatterBegin     1619 1.0 1.1247e+00 2.1 0.00e+00 0.0 2.4e+05 4.6e+04 0.0e+00  0  0 99 87  0   0  0 99 87  0     0
VecScatterEnd       1619 1.0 1.2398e+0159.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  2  0  0  0  0   2  0  0  0  0     0
SFSetGraph             2 1.0 5.1872e-04 2.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.1539e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFBcastOpBegin      1619 1.0 1.1207e+00 2.1 0.00e+00 0.0 2.4e+05 4.6e+04 0.0e+00  0  0 99 87  0   0  0 99 87  0     0
SFBcastOpEnd        1619 1.0 1.2394e+0160.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  2  0  0  0  0   2  0  0  0  0     0
SFPack              1619 1.0 1.0861e+00 2.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack            1619 1.0 1.0471e-03 1.6 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               1 1.0 9.6245e-03 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSolve               1 1.0 3.3251e+02 1.0 1.80e+11 1.1 2.4e+05 4.6e+04 2.7e+03 92100 99 87 98  92100 99 87 99 10266
PCSetUp                1 1.0 4.1300e-07 2.8 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
PCApply             1620 1.0 1.9267e+02 1.1 8.53e+10 1.1 0.0e+00 0.0e+00 0.0e+00 51 47  0  0  0  51 47  0  0  0  8381
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     3              3    354240752     0.
           Index Set     4              4       304416     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    25             25     75395024     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     1              1         1600     0.
      Preconditioner     1              1          968     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 2.74e-08
Average time for MPI_Barrier(): 4.8548e-06
Average time for zero size MPI_Send(): 3.32455e-06
#PETSc Option Table entries:
-d 3
-ksp_type tcqmr
-log_view
-mat_type aij
-n 100
-pc_type sor
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type tcqmr -pc_type mg -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 16:29:26 2020            |
| OS:             Linux                               |
| HostName:       sdumont6181                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.85856, Active time=2.88752                                       |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.3993      0.000008    0.3993      0.000008    13.83    13.83    |
| Ke                            50792      1.7594      0.000035    1.7594      0.000035    60.93    60.93    |
| elem init                     50792      0.7288      0.000014    0.7288      0.000014    25.24    25.24    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.8875                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 360.743441
Tempo total: 360.741633
Tempo total: 360.738439
Tempo total: 360.709197
Tempo total: 360.690326
Tempo total: 360.730528
Tempo total: 360.711580
Tempo total: 360.693290
Tempo total: 360.702080
Tempo total: 360.676277
Tempo total: 360.702038
Tempo total: 360.694694
Tempo total: 360.665905
Tempo total: 360.686177
Tempo total: 360.696371
Tempo total: 360.670847
Tempo total: 360.681617
Tempo total: 360.671246
Tempo total: 360.663591
Tempo total: 360.737053
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6181 with 20 processors, by luciano.siqueira Thu Dec 10 16:34:59 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           3.611e+02     1.000   3.611e+02
Objects:              6.500e+01     1.000   6.500e+01
Flop:                 1.783e+11     1.106   1.695e+11  3.390e+12
Flop/sec:             4.939e+08     1.106   4.694e+08  9.388e+09
MPI Messages:         1.791e+04     2.739   1.190e+04  2.380e+05
MPI Message Lengths:  8.115e+08     1.818   5.224e+04  1.243e+10
MPI Reductions:       1.405e+03     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 3.6111e+02 100.0%  3.3902e+12 100.0%  2.380e+05 100.0%  5.224e+04      100.0%  1.398e+03  99.5%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 4.9136e-0140.9 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  0  0  0  0  0   0  0  0  0  1     0
BuildTwoSidedF         5 1.0 4.8973e-0173.2 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  0  0  0  2  0   0  0  0  2  0     0
MatMult             1616 1.0 1.3993e+02 1.1 8.63e+10 1.1 2.4e+05 4.6e+04 0.0e+00 37 49 99 87  0  37 49 99 87  0 11776
MatSOR              1619 1.0 1.9271e+02 1.1 8.53e+10 1.1 0.0e+00 0.0e+00 0.0e+00 51 48  0  0  0  51 48  0  0  0  8375
MatAssemblyBegin       2 1.0 5.7763e-01 4.2 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  0  0  0  2  0   0  0  0  2  0     0
MatAssemblyEnd         2 1.0 3.4330e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  0  0  0  0  0   0  0  0  0  0    13
MatZeroEntries         3 1.0 1.2131e-01 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecDot               801 1.0 4.6624e+00 8.4 6.80e+08 1.1 0.0e+00 0.0e+00 8.0e+02  1  0  0  0 57   1  0  0  0 57  2790
VecMDot               10 1.0 1.4311e-01 6.6 4.67e+07 1.1 0.0e+00 0.0e+00 1.0e+01  0  0  0  0  1   0  0  0  0  1  6242
VecNorm              548 1.0 8.5422e+0026.5 4.65e+08 1.1 0.0e+00 0.0e+00 5.5e+02  1  0  0  0 39   1  0  0  0 39  1042
VecScale            1080 1.0 4.1412e-01 1.3 4.59e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 21178
VecCopy             4017 1.0 2.8887e+00 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
VecSet              1620 1.0 4.9861e-01 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY             2402 1.0 1.5231e+00 1.1 2.04e+09 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 25613
VecAYPX             1875 1.0 2.1111e+00 1.1 1.25e+09 1.1 0.0e+00 0.0e+00 0.0e+00  1  1  0  0  0   1  1  0  0  0 11332
VecAXPBYCZ           804 1.0 1.0860e+00 1.1 1.71e+09 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 30059
VecMAXPY              11 1.0 3.6736e-02 1.1 5.52e+07 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 28737
VecAssemblyBegin       3 1.0 1.0215e-02 1.1 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAssemblyEnd         3 1.0 5.7270e-04 4.5 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecScatterBegin     1617 1.0 1.0666e+00 2.1 0.00e+00 0.0 2.4e+05 4.6e+04 0.0e+00  0  0 99 87  0   0  0 99 87  0     0
VecScatterEnd       1617 1.0 2.1906e+0187.6 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  3  0  0  0  0   3  0  0  0  0     0
VecNormalize          11 1.0 3.1316e-02 2.7 1.40e+07 1.1 0.0e+00 0.0e+00 1.1e+01  0  0  0  0  1   0  0  0  0  1  8557
SFSetGraph             2 1.0 5.4598e-04 1.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.2239e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFBcastOpBegin      1617 1.0 1.0625e+00 2.1 0.00e+00 0.0 2.4e+05 4.6e+04 0.0e+00  0  0 99 87  0   0  0 99 87  0     0
SFBcastOpEnd        1617 1.0 2.1903e+0188.8 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  3  0  0  0  0   3  0  0  0  0     0
SFPack              1617 1.0 1.0272e+00 2.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack            1617 1.0 1.1416e-03 1.6 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               2 1.0 2.3263e+00 1.0 1.23e+09 1.1 1.5e+03 4.6e+04 2.3e+01  1  1  1  1  2   1  1  1  1  2 10060
KSPSolve               1 1.0 3.3161e+02 1.0 1.78e+11 1.1 2.4e+05 4.6e+04 1.4e+03 92100 99 87 97  92100 99 87 97 10223
KSPGMRESOrthog        10 1.0 1.7103e-01 3.3 9.34e+07 1.1 0.0e+00 0.0e+00 1.0e+01  0  0  0  0  1   0  0  0  0  1 10445
PCSetUp                1 1.0 2.3178e+00 1.0 1.23e+09 1.1 1.5e+03 4.6e+04 2.3e+01  1  1  1  1  2   1  1  1  1  2 10097
PCApply              815 1.0 2.6144e+02 1.0 1.31e+11 1.1 1.2e+05 4.6e+04 0.0e+00 71 73 49 43  0  71 73 49 43  0  9509
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     3              3    354240752     0.
           Index Set     4              4       304416     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    44             44    139985144     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     4              4        35144     0.
      Preconditioner     4              4         4256     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 2.93e-08
Average time for MPI_Barrier(): 5.2506e-06
Average time for zero size MPI_Send(): 3.34175e-06
#PETSc Option Table entries:
-d 3
-ksp_type tcqmr
-log_view
-mat_type aij
-n 100
-pc_type mg
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type cgs -pc_type bjacobi -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 16:35:29 2020            |
| OS:             Linux                               |
| HostName:       sdumont6181                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.87059, Active time=2.89963                                       |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.4026      0.000008    0.4026      0.000008    13.89    13.89    |
| Ke                            50792      1.7744      0.000035    1.7744      0.000035    61.20    61.20    |
| elem init                     50792      0.7225      0.000014    0.7225      0.000014    24.92    24.92    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.8996                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 39.075180
Tempo total: 39.078206
Tempo total: 39.078386
Tempo total: 39.056307
Tempo total: 39.081657
Tempo total: 39.066029
Tempo total: 39.078777
Tempo total: 39.061917
Tempo total: 39.049478
Tempo total: 39.056010
Tempo total: 39.024859
Tempo total: 39.048944
Tempo total: 39.056559
Tempo total: 39.044370
Tempo total: 39.066269
Tempo total: 39.039086
Tempo total: 39.057891
Tempo total: 39.029345
Tempo total: 39.024710
Tempo total: 39.145940
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6181 with 20 processors, by luciano.siqueira Thu Dec 10 16:35:41 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           3.942e+01     1.000   3.942e+01
Objects:              3.700e+01     1.000   3.700e+01
Flop:                 6.272e+09     1.107   5.959e+09  1.192e+11
Flop/sec:             1.591e+08     1.107   1.512e+08  3.024e+09
MPI Messages:         6.245e+02     2.459   4.294e+02  8.587e+03
MPI Message Lengths:  1.048e+08     1.200   2.230e+05  1.915e+09
MPI Reductions:       1.130e+02     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 3.9418e+01 100.0%  1.1919e+11 100.0%  8.587e+03 100.0%  2.230e+05      100.0%  1.060e+02  93.8%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 5.2368e-01130.8 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  1  0  5  0  6   1  0  5  0  7     0
BuildTwoSidedF         5 1.0 5.2249e-01153.3 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  1  0  4 11  4   1  0  4 11  5     0
MatMult               45 1.0 3.9021e+00 1.1 2.40e+09 1.1 6.6e+03 4.6e+04 0.0e+00  9 39 77 16  0   9 39 77 16  0 11760
MatSolve              46 1.0 3.6576e+00 1.1 2.40e+09 1.1 0.0e+00 0.0e+00 0.0e+00  9 38  0  0  0   9 38  0  0  0 12435
MatLUFactorNum         1 1.0 2.4401e+00 1.1 1.27e+09 1.1 0.0e+00 0.0e+00 0.0e+00  6 20  0  0  0   6 20  0  0  0  9916
MatILUFactorSym        1 1.0 1.5362e-01 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatAssemblyBegin       2 1.0 5.9506e-01 3.1 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  1  0  2 11  2   1  0  2 11  2     0
MatAssemblyEnd         2 1.0 3.2637e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  1  0  3  0  4   1  0  3  0  5    13
MatGetRowIJ            1 1.0 3.8330e-06 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatGetOrdering         1 1.0 4.1530e-03 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatZeroEntries         3 1.0 1.2155e-01 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecDot                45 1.0 4.5197e-0116.1 3.82e+07 1.1 0.0e+00 0.0e+00 4.5e+01  1  1  0  0 40   1  1  0  0 42  1617
VecNorm               24 1.0 9.0484e-02 6.5 2.04e+07 1.1 0.0e+00 0.0e+00 2.4e+01  0  0  0  0 21   0  0  0  0 23  4308
VecCopy                5 1.0 3.6760e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet                51 1.0 2.3153e-02 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY               66 1.0 5.1634e-02 1.1 5.61e+07 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 20760
VecWAXPY              86 1.0 1.1243e-01 1.1 6.37e+07 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 10834
VecAssemblyBegin       3 1.0 9.0439e-03 1.0 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  3  0  3   0  0  3  0  3     0
VecAssemblyEnd         3 1.0 5.8776e-04 4.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecScatterBegin       46 1.0 3.2106e-02 2.1 0.00e+00 0.0 6.7e+03 4.6e+04 0.0e+00  0  0 78 16  0   0  0 78 16  0     0
VecScatterEnd         46 1.0 6.1736e-0198.8 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
SFSetGraph             2 1.0 5.0077e-04 1.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.1601e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  7  0  2   0  0  7  0  2     0
SFBcastOpBegin        46 1.0 3.1983e-02 2.1 0.00e+00 0.0 6.7e+03 4.6e+04 0.0e+00  0  0 78 16  0   0  0 78 16  0     0
SFBcastOpEnd          46 1.0 6.1725e-01100.6 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
SFPack                46 1.0 3.0330e-02 2.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack              46 1.0 2.9800e-05 1.5 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               2 1.0 3.7105e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSolve               1 1.0 1.0102e+01 1.0 6.26e+09 1.1 6.6e+03 4.6e+04 6.9e+01 26100 77 16 61  26100 77 16 65 11778
PCSetUp                2 1.0 2.6059e+00 1.1 1.27e+09 1.1 0.0e+00 0.0e+00 0.0e+00  6 20  0  0  0   6 20  0  0  0  9285
PCSetUpOnBlocks        1 1.0 2.5979e+00 1.1 1.27e+09 1.1 0.0e+00 0.0e+00 0.0e+00  6 20  0  0  0   6 20  0  0  0  9314
PCApply               46 1.0 3.6796e+00 1.1 2.40e+09 1.1 0.0e+00 0.0e+00 0.0e+00  9 38  0  0  0   9 38  0  0  0 12360
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     4              4    666933972     0.
           Index Set     7              7      5403804     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    16             16     38003880     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     2              2         3016     0.
      Preconditioner     2              2         1944     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 2.93e-08
Average time for MPI_Barrier(): 4.494e-06
Average time for zero size MPI_Send(): 3.2592e-06
#PETSc Option Table entries:
-d 3
-ksp_type cgs
-log_view
-mat_type aij
-n 100
-pc_type bjacobi
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type cgs -pc_type jacobi -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 16:36:12 2020            |
| OS:             Linux                               |
| HostName:       sdumont6181                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.86256, Active time=2.89485                                       |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.4012      0.000008    0.4012      0.000008    13.86    13.86    |
| Ke                            50792      1.7605      0.000035    1.7605      0.000035    60.82    60.82    |
| elem init                     50792      0.7331      0.000014    0.7331      0.000014    25.33    25.33    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.8949                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 904.532642
Tempo total: 904.557208
Tempo total: 904.598357
Tempo total: 904.543164
Tempo total: 904.537363
Tempo total: 904.554443
Tempo total: 904.562971
Tempo total: 904.529782
Tempo total: 904.562253
Tempo total: 904.559688
Tempo total: 904.539196
Tempo total: 904.531698
Tempo total: 904.536636
Tempo total: 904.531226
Tempo total: 904.539124
Tempo total: 904.531211
Tempo total: 904.511124
Tempo total: 904.518422
Tempo total: 904.509983
Tempo total: 904.541981
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6181 with 20 processors, by luciano.siqueira Thu Dec 10 16:50:48 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           9.049e+02     1.000   9.049e+02
Objects:              3.000e+01     1.000   3.000e+01
Flop:                 5.790e+11     1.100   5.526e+11  1.105e+13
Flop/sec:             6.398e+08     1.100   6.107e+08  1.221e+10
MPI Messages:         1.102e+05     2.748   7.312e+04  1.462e+06
MPI Message Lengths:  4.583e+09     1.940   4.689e+04  6.857e+10
MPI Reductions:       1.505e+04     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 9.0492e+02 100.0%  1.1052e+13 100.0%  1.462e+06 100.0%  4.689e+04      100.0%  1.504e+04 100.0%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 4.0180e-0170.9 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  0  0  0  0  0   0  0  0  0  0     0
BuildTwoSidedF         5 1.0 4.0067e-0185.1 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatMult            10002 1.0 8.1805e+02 1.1 5.34e+11 1.1 1.5e+06 4.6e+04 0.0e+00 89 92100 98  0  89 92100 98  0 12468
MatAssemblyBegin       2 1.0 4.9382e-01 4.1 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatAssemblyEnd         2 1.0 3.4189e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  0  0  0  0  0   0  0  0  0  0    13
MatZeroEntries         3 1.0 1.2060e-01 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecDot             10001 1.0 4.8252e+01 8.0 8.50e+09 1.1 0.0e+00 0.0e+00 1.0e+04  2  1  0  0 66   2  1  0  0 66  3366
VecNorm             5002 1.0 2.9144e+00 1.0 4.25e+09 1.1 0.0e+00 0.0e+00 5.0e+03  0  1  0  0 33   0  1  0  0 33 27875
VecCopy                5 1.0 3.6829e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet                 5 1.0 1.7533e-03 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY            15001 1.0 1.2656e+01 1.1 1.27e+10 1.1 0.0e+00 0.0e+00 0.0e+00  1  2  0  0  0   1  2  0  0  0 19251
VecWAXPY           20000 1.0 2.5600e+01 1.1 1.49e+10 1.1 0.0e+00 0.0e+00 0.0e+00  3  3  0  0  0   3  3  0  0  0 11101
VecAssemblyBegin       3 1.0 1.3871e-02 1.5 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAssemblyEnd         3 1.0 6.2302e-04 4.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecPointwiseMult   10003 1.0 1.2629e+01 1.1 4.25e+09 1.1 0.0e+00 0.0e+00 0.0e+00  1  1  0  0  0   1  1  0  0  0  6432
VecScatterBegin    10003 1.0 6.6800e+00 2.1 0.00e+00 0.0 1.5e+06 4.6e+04 0.0e+00  1  0100 98  0   1  0100 98  0     0
VecScatterEnd      10003 1.0 7.8988e+0159.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  4  0  0  0  0   4  0  0  0  0     0
SFSetGraph             2 1.0 5.1244e-04 1.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.1589e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFBcastOpBegin     10003 1.0 6.6584e+00 2.1 0.00e+00 0.0 1.5e+06 4.6e+04 0.0e+00  1  0100 98  0   1  0100 98  0     0
SFBcastOpEnd       10003 1.0 7.8966e+0160.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  4  0  0  0  0   4  0  0  0  0     0
SFPack             10003 1.0 6.4667e+00 2.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack           10003 1.0 5.8223e-03 1.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               1 1.0 3.7028e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSolve               1 1.0 8.7508e+02 1.0 5.79e+11 1.1 1.5e+06 4.6e+04 1.5e+04 97100100 98100  97100100 98100 12630
PCSetUp                1 1.0 8.0100e-07 2.6 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
PCApply            10003 1.0 1.2722e+01 1.1 4.25e+09 1.1 0.0e+00 0.0e+00 2.0e+00  1  1  0  0  0   1  1  0  0  0  6385
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     3              3    344047400     0.
           Index Set     4              4       304416     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    15             15     41400224     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     1              1         1600     0.
      Preconditioner     1              1          968     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 2.91e-08
Average time for MPI_Barrier(): 5.0056e-06
Average time for zero size MPI_Send(): 3.39185e-06
#PETSc Option Table entries:
-d 3
-ksp_type cgs
-log_view
-mat_type aij
-n 100
-pc_type jacobi
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type cgs -pc_type sor -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 16:51:20 2020            |
| OS:             Linux                               |
| HostName:       sdumont6181                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.84281, Active time=2.88311                                       |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.3985      0.000008    0.3985      0.000008    13.82    13.82    |
| Ke                            50792      1.7591      0.000035    1.7591      0.000035    61.02    61.02    |
| elem init                     50792      0.7255      0.000014    0.7255      0.000014    25.16    25.16    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.8831                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 56.980325
Tempo total: 56.928481
Tempo total: 56.935774
Tempo total: 56.898961
Tempo total: 56.908259
Tempo total: 56.888852
Tempo total: 56.902513
Tempo total: 56.902828
Tempo total: 56.863675
Tempo total: 56.901848
Tempo total: 56.885479
Tempo total: 56.870294
Tempo total: 56.877076
Tempo total: 56.879520
Tempo total: 56.881817
Tempo total: 56.877592
Tempo total: 56.858086
Tempo total: 56.868051
Tempo total: 56.883807
Tempo total: 56.976528
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6181 with 20 processors, by luciano.siqueira Thu Dec 10 16:51:48 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           5.727e+01     1.000   5.727e+01
Objects:              2.900e+01     1.000   2.900e+01
Flop:                 1.471e+10     1.106   1.398e+10  2.796e+11
Flop/sec:             2.569e+08     1.106   2.441e+08  4.883e+09
MPI Messages:         1.592e+03     2.628   1.072e+03  2.144e+04
MPI Message Lengths:  1.444e+08     1.344   1.168e+05  2.504e+09
MPI Reductions:       2.450e+02     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 5.7268e+01 100.0%  2.7962e+11 100.0%  2.144e+04 100.0%  1.168e+05      100.0%  2.380e+02  97.1%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 4.7350e-0195.7 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  0  0  2  0  3   0  0  2  0  3     0
BuildTwoSidedF         5 1.0 4.7336e-01117.8 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  0  0  2  8  2   0  0  2  8  2     0
MatMult              133 1.0 1.0917e+01 1.1 7.11e+09 1.1 1.9e+04 4.6e+04 0.0e+00 19 49 91 36  0  19 49 91 36  0 12424
MatSOR               134 1.0 1.6208e+01 1.1 7.06e+09 1.1 0.0e+00 0.0e+00 0.0e+00 27 48  0  0  0  27 48  0  0  0  8242
MatAssemblyBegin       2 1.0 5.8081e-01 3.6 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  1  0  1  8  1   1  0  1  8  1     0
MatAssemblyEnd         2 1.0 3.4272e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  1  0  1  0  2   1  0  1  0  2    13
MatZeroEntries         3 1.0 1.2088e-01 1.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecDot               133 1.0 1.9726e+0023.7 1.13e+08 1.1 0.0e+00 0.0e+00 1.3e+02  2  1  0  0 54   2  1  0  0 56  1095
VecNorm               68 1.0 7.6705e-02 1.9 5.78e+07 1.1 0.0e+00 0.0e+00 6.8e+01  0  0  0  0 28   0  0  0  0 29 14398
VecCopy                5 1.0 3.6624e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet                 5 1.0 1.7885e-03 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY              198 1.0 1.5567e-01 1.1 1.68e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 20657
VecWAXPY             262 1.0 3.4438e-01 1.1 1.95e+08 1.1 0.0e+00 0.0e+00 0.0e+00  1  1  0  0  0   1  1  0  0  0 10800
VecAssemblyBegin       3 1.0 9.6643e-03 1.0 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  1  0  1   0  0  1  0  1     0
VecAssemblyEnd         3 1.0 5.7411e-04 4.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecScatterBegin      134 1.0 8.9515e-02 2.0 0.00e+00 0.0 2.0e+04 4.6e+04 0.0e+00  0  0 91 36  0   0  0 91 36  0     0
VecScatterEnd        134 1.0 1.1086e+0063.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
SFSetGraph             2 1.0 5.1370e-04 1.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.1522e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  3  0  1   0  0  3  0  1     0
SFBcastOpBegin       134 1.0 8.9192e-02 2.0 0.00e+00 0.0 2.0e+04 4.6e+04 0.0e+00  0  0 91 36  0   0  0 91 36  0     0
SFBcastOpEnd         134 1.0 1.1083e+0065.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
SFPack               134 1.0 8.4402e-02 2.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack             134 1.0 9.4910e-05 1.7 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               1 1.0 3.7113e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSolve               1 1.0 2.7536e+01 1.0 1.47e+10 1.1 1.9e+04 4.6e+04 2.0e+02 48100 91 36 82  48100 91 36 84 10147
PCSetUp                1 1.0 4.2100e-07 2.7 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
PCApply              134 1.0 1.6209e+01 1.1 7.06e+09 1.1 0.0e+00 0.0e+00 0.0e+00 27 48  0  0  0  27 48  0  0  0  8242
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     3              3    354240752     0.
           Index Set     4              4       304416     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    14             14     38000744     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     1              1         1600     0.
      Preconditioner     1              1          968     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 3.12e-08
Average time for MPI_Barrier(): 4.9914e-06
Average time for zero size MPI_Send(): 3.32775e-06
#PETSc Option Table entries:
-d 3
-ksp_type cgs
-log_view
-mat_type aij
-n 100
-pc_type sor
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type cgs -pc_type mg -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 16:52:20 2020            |
| OS:             Linux                               |
| HostName:       sdumont6181                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.84999, Active time=2.88784                                       |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.3997      0.000008    0.3997      0.000008    13.84    13.84    |
| Ke                            50792      1.7654      0.000035    1.7654      0.000035    61.13    61.13    |
| elem init                     50792      0.7227      0.000014    0.7227      0.000014    25.03    25.03    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.8878                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 156.021962
Tempo total: 155.975864
Tempo total: 155.998285
Tempo total: 155.987237
Tempo total: 155.969234
Tempo total: 155.963949
Tempo total: 156.000405
Tempo total: 155.980653
Tempo total: 155.992803
Tempo total: 155.973237
Tempo total: 155.984701
Tempo total: 155.974181
Tempo total: 155.982861
Tempo total: 155.963762
Tempo total: 155.951920
Tempo total: 155.970649
Tempo total: 155.953844
Tempo total: 155.970493
Tempo total: 155.953701
Tempo total: 155.983193
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6181 with 20 processors, by luciano.siqueira Thu Dec 10 16:54:28 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           1.564e+02     1.000   1.564e+02
Objects:              5.400e+01     1.000   5.400e+01
Flop:                 6.795e+10     1.106   6.459e+10  1.292e+12
Flop/sec:             4.345e+08     1.106   4.130e+08  8.259e+09
MPI Messages:         6.916e+03     2.721   4.605e+03  9.210e+04
MPI Message Lengths:  3.621e+08     1.661   6.237e+04  5.744e+09
MPI Reductions:       5.230e+02     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 1.5640e+02 100.0%  1.2917e+12 100.0%  9.210e+04 100.0%  6.237e+04      100.0%  5.160e+02  98.7%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 3.9275e-0136.9 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  0  0  0  0  1   0  0  0  0  1     0
BuildTwoSidedF         5 1.0 3.9250e-0167.9 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  0  0  0  4  1   0  0  0  4  1     0
MatMult              617 1.0 5.3812e+01 1.1 3.30e+10 1.1 9.0e+04 4.6e+04 0.0e+00 33 49 98 72  0  33 49 98 72  0 11692
MatSOR               619 1.0 7.4249e+01 1.1 3.26e+10 1.1 0.0e+00 0.0e+00 0.0e+00 45 48  0  0  0  45 48  0  0  0  8311
MatAssemblyBegin       2 1.0 4.8452e-01 4.1 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  0  0  0  4  0   0  0  0  4  0     0
MatAssemblyEnd         2 1.0 3.1004e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  0  0  0  0  1   0  0  0  0  1    14
MatZeroEntries         3 1.0 1.2199e-01 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecDot               303 1.0 5.1605e+0028.3 2.57e+08 1.1 0.0e+00 0.0e+00 3.0e+02  2  0  0  0 58   2  0  0  0 59   954
VecMDot               10 1.0 1.6298e-01 6.9 4.67e+07 1.1 0.0e+00 0.0e+00 1.0e+01  0  0  0  0  2   0  0  0  0  2  5481
VecNorm              164 1.0 1.4602e-01 1.5 1.39e+08 1.1 0.0e+00 0.0e+00 1.6e+02  0  0  0  0 31   0  0  0  0 32 18241
VecScale              11 1.0 3.4997e-03 1.3 4.67e+06 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 25524
VecCopy              614 1.0 3.9164e-01 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet               615 1.0 1.9197e-01 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY              454 1.0 3.4980e-01 1.1 3.86e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 21079
VecAYPX              608 1.0 6.7783e-01 1.1 3.87e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 10926
VecAXPBYCZ           304 1.0 4.0984e-01 1.1 6.46e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 30118
VecWAXPY             602 1.0 7.8236e-01 1.1 4.47e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 10930
VecMAXPY              11 1.0 3.6033e-02 1.1 5.52e+07 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 29298
VecAssemblyBegin       3 1.0 8.5325e-03 1.0 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  0  0  1   0  0  0  0  1     0
VecAssemblyEnd         3 1.0 5.6209e-04 4.6 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecScatterBegin      618 1.0 3.9444e-01 2.0 0.00e+00 0.0 9.0e+04 4.6e+04 0.0e+00  0  0 98 72  0   0  0 98 72  0     0
VecScatterEnd        618 1.0 8.7674e+00101.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  2  0  0  0  0   2  0  0  0  0     0
VecNormalize          11 1.0 3.1240e-02 3.0 1.40e+07 1.1 0.0e+00 0.0e+00 1.1e+01  0  0  0  0  2   0  0  0  0  2  8578
SFSetGraph             2 1.0 5.0431e-04 1.8 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.1192e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  1  0  0   0  0  1  0  0     0
SFBcastOpBegin       618 1.0 3.9287e-01 2.0 0.00e+00 0.0 9.0e+04 4.6e+04 0.0e+00  0  0 98 72  0   0  0 98 72  0     0
SFBcastOpEnd         618 1.0 8.7660e+00102.5 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  2  0  0  0  0   2  0  0  0  0     0
SFPack               618 1.0 3.7784e-01 2.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack             618 1.0 4.4852e-04 1.6 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               2 1.0 2.3209e+00 1.0 1.23e+09 1.1 1.5e+03 4.6e+04 2.3e+01  1  2  2  1  4   1  2  2  1  4 10084
KSPSolve               1 1.0 1.2689e+02 1.0 6.79e+10 1.1 9.0e+04 4.6e+04 4.8e+02 81100 98 72 92  81100 98 72 93 10179
KSPGMRESOrthog        10 1.0 1.9083e-01 3.6 9.34e+07 1.1 0.0e+00 0.0e+00 1.0e+01  0  0  0  0  2   0  0  0  0  2  9362
PCSetUp                1 1.0 2.3177e+00 1.0 1.23e+09 1.1 1.5e+03 4.6e+04 2.3e+01  1  2  2  1  4   1  2  2  1  4 10098
PCApply              315 1.0 1.0022e+02 1.1 4.99e+10 1.1 4.4e+04 4.6e+04 0.0e+00 63 73 48 35  0  63 73 48 35  0  9447
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     3              3    354240752     0.
           Index Set     4              4       304416     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    33             33    102590864     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     4              4        35144     0.
      Preconditioner     4              4         4256     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 2.94e-08
Average time for MPI_Barrier(): 4.8056e-06
Average time for zero size MPI_Send(): 3.32105e-06
#PETSc Option Table entries:
-d 3
-ksp_type cgs
-log_view
-mat_type aij
-n 100
-pc_type mg
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type bcgs -pc_type bjacobi -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 16:54:58 2020            |
| OS:             Linux                               |
| HostName:       sdumont6181                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.85724, Active time=2.89608                                       |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.3996      0.000008    0.3996      0.000008    13.80    13.80    |
| Ke                            50792      1.7605      0.000035    1.7605      0.000035    60.79    60.79    |
| elem init                     50792      0.7360      0.000014    0.7360      0.000014    25.41    25.41    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.8961                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 114.181045
Tempo total: 114.139471
Tempo total: 114.118315
Tempo total: 114.108114
Tempo total: 114.120622
Tempo total: 114.117363
Tempo total: 114.117888
Tempo total: 114.104822
Tempo total: 114.084833
Tempo total: 114.095851
Tempo total: 114.076084
Tempo total: 114.079818
Tempo total: 114.113823
Tempo total: 114.108957
Tempo total: 114.102562
Tempo total: 114.095767
Tempo total: 114.076331
Tempo total: 114.081541
Tempo total: 114.095284
Tempo total: 114.101910
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6181 with 20 processors, by luciano.siqueira Thu Dec 10 16:56:25 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           1.145e+02     1.000   1.145e+02
Objects:              3.600e+01     1.000   3.600e+01
Flop:                 5.728e+10     1.106   5.445e+10  1.089e+12
Flop/sec:             5.003e+08     1.106   4.756e+08  9.511e+09
MPI Messages:         5.706e+03     2.715   3.802e+03  7.604e+04
MPI Message Lengths:  3.126e+08     1.621   6.586e+04  5.008e+09
MPI Reductions:       1.058e+03     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 1.1449e+02 100.0%  1.0889e+12 100.0%  7.604e+04 100.0%  6.586e+04      100.0%  1.051e+03  99.3%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 4.0458e-0181.6 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  0  0  1  0  1   0  0  1  0  1     0
BuildTwoSidedF         5 1.0 4.0256e-01108.1 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  0  0  0  4  0   0  0  0  4  0     0
MatMult              507 1.0 4.1401e+01 1.0 2.71e+10 1.1 7.4e+04 4.6e+04 0.0e+00 36 47 97 68  0  36 47 97 68  0 12487
MatSolve             508 1.0 4.0314e+01 1.1 2.65e+10 1.1 0.0e+00 0.0e+00 0.0e+00 33 46  0  0  0  33 46  0  0  0 12459
MatLUFactorNum         1 1.0 2.4532e+00 1.1 1.27e+09 1.1 0.0e+00 0.0e+00 0.0e+00  2  2  0  0  0   2  2  0  0  0  9863
MatILUFactorSym        1 1.0 1.5177e-01 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatAssemblyBegin       2 1.0 5.2292e-01 3.4 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  0  0  0  4  0   0  0  0  4  0     0
MatAssemblyEnd         2 1.0 3.4343e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  0  0  0  0  0   0  0  0  0  0    13
MatGetRowIJ            1 1.0 4.0050e-06 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatGetOrdering         1 1.0 4.2464e-03 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatZeroEntries         3 1.0 1.2160e-01 1.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecDot               506 1.0 2.7124e+00 7.5 4.30e+08 1.1 0.0e+00 0.0e+00 5.1e+02  1  1  0  0 48   1  1  0  0 48  3030
VecDotNorm2          253 1.0 2.7016e+00 7.4 4.30e+08 1.1 0.0e+00 0.0e+00 2.5e+02  1  1  0  0 24   1  1  0  0 24  3042
VecNorm              255 1.0 3.0561e-01 2.0 2.17e+08 1.1 0.0e+00 0.0e+00 2.6e+02  0  0  0  0 24   0  0  0  0 24 13551
VecCopy                3 1.0 2.2266e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet               515 1.0 2.3922e-01 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY                1 1.0 5.4990e-04 1.3 8.49e+05 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 29535
VecAXPBYCZ           506 1.0 7.0486e-01 1.1 8.60e+08 1.1 0.0e+00 0.0e+00 0.0e+00  1  2  0  0  0   1  2  0  0  0 23318
VecWAXPY             506 1.0 6.3411e-01 1.1 4.30e+08 1.1 0.0e+00 0.0e+00 0.0e+00  1  1  0  0  0   1  1  0  0  0 12960
VecAssemblyBegin       3 1.0 9.6400e-03 1.0 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAssemblyEnd         3 1.0 6.2918e-04 5.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecScatterBegin      508 1.0 3.4128e-01 2.1 0.00e+00 0.0 7.4e+04 4.6e+04 0.0e+00  0  0 98 68  0   0  0 98 68  0     0
VecScatterEnd        508 1.0 3.9245e+0056.5 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
SFSetGraph             2 1.0 5.1434e-04 1.8 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.2028e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  1  0  0   0  0  1  0  0     0
SFBcastOpBegin       508 1.0 3.4011e-01 2.1 0.00e+00 0.0 7.4e+04 4.6e+04 0.0e+00  0  0 98 68  0   0  0 98 68  0     0
SFBcastOpEnd         508 1.0 3.9233e+0057.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
SFPack               508 1.0 3.2910e-01 2.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack             508 1.0 4.3389e-04 1.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               2 1.0 3.1761e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSolve               1 1.0 8.5957e+01 1.0 5.73e+10 1.1 7.4e+04 4.6e+04 1.0e+03 75100 97 68 96  75100 97 68 96 12666
PCSetUp                2 1.0 2.6172e+00 1.1 1.27e+09 1.1 0.0e+00 0.0e+00 0.0e+00  2  2  0  0  0   2  2  0  0  0  9245
PCSetUpOnBlocks        1 1.0 2.6093e+00 1.1 1.27e+09 1.1 0.0e+00 0.0e+00 0.0e+00  2  2  0  0  0   2  2  0  0  0  9273
PCApply              508 1.0 4.0556e+01 1.1 2.65e+10 1.1 0.0e+00 0.0e+00 0.0e+00 34 46  0  0  0  34 46  0  0  0 12385
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     4              4    666933972     0.
           Index Set     7              7      5403804     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    15             15     34604400     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     2              2         3024     0.
      Preconditioner     2              2         1944     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 2.9e-08
Average time for MPI_Barrier(): 4.7636e-06
Average time for zero size MPI_Send(): 3.34135e-06
#PETSc Option Table entries:
-d 3
-ksp_type bcgs
-log_view
-mat_type aij
-n 100
-pc_type bjacobi
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type bcgs -pc_type jacobi -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 16:56:55 2020            |
| OS:             Linux                               |
| HostName:       sdumont6181                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.86972, Active time=2.90313                                       |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.4021      0.000008    0.4021      0.000008    13.85    13.85    |
| Ke                            50792      1.7754      0.000035    1.7754      0.000035    61.16    61.16    |
| elem init                     50792      0.7256      0.000014    0.7256      0.000014    24.99    24.99    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.9031                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 55.261756
Tempo total: 55.245117
Tempo total: 55.262343
Tempo total: 55.224226
Tempo total: 55.234382
Tempo total: 55.213296
Tempo total: 55.230366
Tempo total: 55.220444
Tempo total: 55.222883
Tempo total: 55.226939
Tempo total: 55.207280
Tempo total: 55.219312
Tempo total: 55.210273
Tempo total: 55.196694
Tempo total: 55.215926
Tempo total: 55.203193
Tempo total: 55.184706
Tempo total: 55.206114
Tempo total: 55.208419
Tempo total: 55.246214
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6181 with 20 processors, by luciano.siqueira Thu Dec 10 16:57:23 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           5.560e+01     1.000   5.559e+01
Objects:              2.900e+01     1.000   2.900e+01
Flop:                 1.774e+10     1.100   1.693e+10  3.387e+11
Flop/sec:             3.191e+08     1.100   3.046e+08  6.092e+09
MPI Messages:         3.462e+03     2.692   2.313e+03  4.626e+04
MPI Message Lengths:  2.209e+08     1.510   7.874e+04  3.642e+09
MPI Reductions:       6.520e+02     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 5.5593e+01 100.0%  3.3868e+11 100.0%  4.626e+04 100.0%  7.874e+04      100.0%  6.450e+02  98.9%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 4.3616e-0194.8 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  0  0  1  0  1   0  0  1  0  1     0
BuildTwoSidedF         5 1.0 4.3497e-01123.5 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  0  0  1  6  1   0  0  1  6  1     0
MatMult              303 1.0 2.4750e+01 1.1 1.62e+10 1.1 4.4e+04 4.6e+04 0.0e+00 44 91 96 56  0  44 91 96 56  0 12484
MatAssemblyBegin       2 1.0 5.4065e-01 3.7 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  1  0  0  6  0   1  0  0  6  0     0
MatAssemblyEnd         2 1.0 3.4254e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  1  0  1  0  1   1  0  1  0  1    13
MatZeroEntries         3 1.0 1.2106e-01 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecDot               302 1.0 7.9066e-01 4.0 2.57e+08 1.1 0.0e+00 0.0e+00 3.0e+02  1  1  0  0 46   1  1  0  0 47  6203
VecDotNorm2          151 1.0 8.0327e-01 3.8 2.57e+08 1.1 0.0e+00 0.0e+00 1.5e+02  1  1  0  0 23   1  1  0  0 23  6106
VecNorm              153 1.0 1.4056e-01 1.6 1.30e+08 1.1 0.0e+00 0.0e+00 1.5e+02  0  1  0  0 23   0  1  0  0 24 17678
VecCopy                3 1.0 2.2869e-03 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet                 7 1.0 2.8116e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY                1 1.0 5.4907e-04 1.3 8.49e+05 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 29579
VecAXPBYCZ           302 1.0 4.2617e-01 1.1 5.13e+08 1.1 0.0e+00 0.0e+00 0.0e+00  1  3  0  0  0   1  3  0  0  0 23018
VecWAXPY             302 1.0 3.9275e-01 1.1 2.57e+08 1.1 0.0e+00 0.0e+00 0.0e+00  1  1  0  0  0   1  1  0  0  0 12488
VecAssemblyBegin       3 1.0 9.6949e-03 1.0 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAssemblyEnd         3 1.0 5.4690e-04 4.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecPointwiseMult     304 1.0 3.7869e-01 1.1 1.29e+08 1.1 0.0e+00 0.0e+00 0.0e+00  1  1  0  0  0   1  1  0  0  0  6519
VecScatterBegin      304 1.0 2.0498e-01 2.0 0.00e+00 0.0 4.4e+04 4.6e+04 0.0e+00  0  0 96 56  0   0  0 96 56  0     0
VecScatterEnd        304 1.0 2.2702e+0056.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  2  0  0  0  0   2  0  0  0  0     0
SFSetGraph             2 1.0 5.1248e-04 2.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.1425e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  1  0  0   0  0  1  0  0     0
SFBcastOpBegin       304 1.0 2.0450e-01 2.0 0.00e+00 0.0 4.4e+04 4.6e+04 0.0e+00  0  0 96 56  0   0  0 96 56  0     0
SFBcastOpEnd         304 1.0 2.2696e+0057.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  2  0  0  0  0   2  0  0  0  0     0
SFPack               304 1.0 1.9691e-01 2.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack             304 1.0 1.9405e-04 1.6 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               1 1.0 3.1830e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSolve               1 1.0 2.6480e+01 1.0 1.77e+10 1.1 4.4e+04 4.6e+04 6.1e+02 48100 96 56 93  48100 96 56 94 12782
PCSetUp                1 1.0 8.7600e-07 3.5 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
PCApply              304 1.0 4.5186e-01 1.1 1.29e+08 1.1 0.0e+00 0.0e+00 2.0e+00  1  1  0  0  0   1  1  0  0  0  5463
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     3              3    344047400     0.
           Index Set     4              4       304416     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    14             14     38000744     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     1              1         1608     0.
      Preconditioner     1              1          968     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 2.91e-08
Average time for MPI_Barrier(): 4.8884e-06
Average time for zero size MPI_Send(): 3.27e-06
#PETSc Option Table entries:
-d 3
-ksp_type bcgs
-log_view
-mat_type aij
-n 100
-pc_type jacobi
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type bcgs -pc_type sor -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 16:57:54 2020            |
| OS:             Linux                               |
| HostName:       sdumont6181                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.87897, Active time=2.91251                                       |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.4186      0.000008    0.4186      0.000008    14.37    14.37    |
| Ke                            50792      1.7684      0.000035    1.7684      0.000035    60.72    60.72    |
| elem init                     50792      0.7255      0.000014    0.7255      0.000014    24.91    24.91    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.9125                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 150.697221
Tempo total: 150.762761
Tempo total: 150.731869
Tempo total: 150.690851
Tempo total: 150.701608
Tempo total: 150.689210
Tempo total: 150.645094
Tempo total: 150.686684
Tempo total: 150.644883
Tempo total: 150.653047
Tempo total: 150.664528
Tempo total: 150.652274
Tempo total: 150.673287
Tempo total: 150.642621
Tempo total: 150.656096
Tempo total: 150.653616
Tempo total: 150.663583
Tempo total: 150.646137
Tempo total: 150.646657
Tempo total: 150.761735
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6181 with 20 processors, by luciano.siqueira Thu Dec 10 16:59:57 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           1.510e+02     1.000   1.510e+02
Objects:              2.800e+01     1.000   2.800e+01
Flop:                 6.664e+10     1.106   6.334e+10  1.267e+12
Flop/sec:             4.412e+08     1.106   4.194e+08  8.388e+09
MPI Messages:         6.740e+03     2.720   4.488e+03  8.976e+04
MPI Message Lengths:  3.549e+08     1.656   6.280e+04  5.637e+09
MPI Reductions:       1.246e+03     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 1.5103e+02 100.0%  1.2668e+12 100.0%  8.976e+04 100.0%  6.280e+04      100.0%  1.239e+03  99.4%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 4.7806e-01145.8 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  0  0  0  0  1   0  0  0  0  1     0
BuildTwoSidedF         5 1.0 4.7653e-01218.0 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  0  0  0  4  0   0  0  0  4  0     0
MatMult              601 1.0 4.9014e+01 1.0 3.21e+10 1.1 8.8e+04 4.6e+04 0.0e+00 32 48 98 71  0  32 48 98 71  0 12504
MatSOR               602 1.0 7.1449e+01 1.1 3.17e+10 1.1 0.0e+00 0.0e+00 0.0e+00 45 47  0  0  0  45 47  0  0  0  8399
MatAssemblyBegin       2 1.0 5.5208e-01 3.8 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  0  0  0  4  0   0  0  0  4  0     0
MatAssemblyEnd         2 1.0 3.3535e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  0  0  0  0  0   0  0  0  0  0    13
MatZeroEntries         3 1.0 1.2138e-01 1.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecDot               600 1.0 4.0025e+00 9.8 5.10e+08 1.1 0.0e+00 0.0e+00 6.0e+02  1  1  0  0 48   1  1  0  0 48  2435
VecDotNorm2          300 1.0 3.9888e+00 9.0 5.10e+08 1.1 0.0e+00 0.0e+00 3.0e+02  1  1  0  0 24   1  1  0  0 24  2443
VecNorm              302 1.0 2.6782e-01 1.5 2.57e+08 1.1 0.0e+00 0.0e+00 3.0e+02  0  0  0  0 24   0  0  0  0 24 18314
VecCopy                3 1.0 2.1975e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet                 7 1.0 2.8035e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY                1 1.0 5.7797e-04 1.3 8.49e+05 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 28100
VecAXPBYCZ           600 1.0 8.3479e-01 1.1 1.02e+09 1.1 0.0e+00 0.0e+00 0.0e+00  1  2  0  0  0   1  2  0  0  0 23347
VecWAXPY             600 1.0 7.6744e-01 1.1 5.10e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 12698
VecAssemblyBegin       3 1.0 8.5834e-03 1.0 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAssemblyEnd         3 1.0 5.7039e-04 4.8 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecScatterBegin      602 1.0 4.1200e-01 2.1 0.00e+00 0.0 8.8e+04 4.6e+04 0.0e+00  0  0 98 72  0   0  0 98 72  0     0
VecScatterEnd        602 1.0 4.6272e+0048.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
SFSetGraph             2 1.0 4.8945e-04 1.8 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.1331e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  1  0  0   0  0  1  0  0     0
SFBcastOpBegin       602 1.0 4.1059e-01 2.1 0.00e+00 0.0 8.8e+04 4.6e+04 0.0e+00  0  0 98 72  0   0  0 98 72  0     0
SFBcastOpEnd         602 1.0 4.6258e+0049.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
SFPack               602 1.0 3.9667e-01 2.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack             602 1.0 3.8986e-04 1.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               1 1.0 3.1615e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSolve               1 1.0 1.2217e+02 1.0 6.66e+10 1.1 8.8e+04 4.6e+04 1.2e+03 81100 98 71 96  81100 98 71 97 10368
PCSetUp                1 1.0 3.0500e-07 2.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
PCApply              602 1.0 7.1450e+01 1.1 3.17e+10 1.1 0.0e+00 0.0e+00 0.0e+00 45 47  0  0  0  45 47  0  0  0  8399
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     3              3    354240752     0.
           Index Set     4              4       304416     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    13             13     34601264     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     1              1         1608     0.
      Preconditioner     1              1          968     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 2.84e-08
Average time for MPI_Barrier(): 4.6908e-06
Average time for zero size MPI_Send(): 3.3178e-06
#PETSc Option Table entries:
-d 3
-ksp_type bcgs
-log_view
-mat_type aij
-n 100
-pc_type sor
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type bcgs -pc_type mg -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 17:00:28 2020            |
| OS:             Linux                               |
| HostName:       sdumont6181                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.84886, Active time=2.88881                                       |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.3989      0.000008    0.3989      0.000008    13.81    13.81    |
| Ke                            50792      1.7663      0.000035    1.7663      0.000035    61.14    61.14    |
| elem init                     50792      0.7236      0.000014    0.7236      0.000014    25.05    25.05    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.8888                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 163.549886
Tempo total: 163.553198
Tempo total: 163.548701
Tempo total: 163.497749
Tempo total: 163.477596
Tempo total: 163.489159
Tempo total: 163.498937
Tempo total: 163.479970
Tempo total: 163.501250
Tempo total: 163.484078
Tempo total: 163.493994
Tempo total: 163.477478
Tempo total: 163.488342
Tempo total: 163.473840
Tempo total: 163.489572
Tempo total: 163.482290
Tempo total: 163.488323
Tempo total: 163.469876
Tempo total: 163.462887
Tempo total: 163.603034
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6181 with 20 processors, by luciano.siqueira Thu Dec 10 17:02:44 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           1.639e+02     1.000   1.639e+02
Objects:              5.300e+01     1.000   5.300e+01
Flop:                 7.211e+10     1.106   6.854e+10  1.371e+12
Flop/sec:             4.400e+08     1.106   4.183e+08  8.365e+09
MPI Messages:         7.312e+03     2.722   4.868e+03  9.736e+04
MPI Message Lengths:  3.783e+08     1.672   6.148e+04  5.985e+09
MPI Reductions:       7.090e+02     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 1.6387e+02 100.0%  1.3708e+12 100.0%  9.736e+04 100.0%  6.148e+04      100.0%  7.020e+02  99.0%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 4.1779e-01101.8 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  0  0  0  0  1   0  0  0  0  1     0
BuildTwoSidedF         5 1.0 4.1701e-01120.7 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  0  0  0  4  1   0  0  0  4  1     0
MatMult              653 1.0 5.6911e+01 1.1 3.49e+10 1.1 9.5e+04 4.6e+04 0.0e+00 33 49 98 73  0  33 49 98 73  0 11700
MatSOR               655 1.0 7.8639e+01 1.1 3.45e+10 1.1 0.0e+00 0.0e+00 0.0e+00 45 48  0  0  0  45 48  0  0  0  8303
MatAssemblyBegin       2 1.0 5.2109e-01 3.2 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  0  0  0  3  0   0  0  0  3  0     0
MatAssemblyEnd         2 1.0 3.2736e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  0  0  0  0  1   0  0  0  0  1    13
MatZeroEntries         3 1.0 1.2134e-01 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecDot               320 1.0 2.6893e+0011.7 2.72e+08 1.1 0.0e+00 0.0e+00 3.2e+02  1  0  0  0 45   1  0  0  0 46  1933
VecDotNorm2          160 1.0 2.7196e+0011.5 2.72e+08 1.1 0.0e+00 0.0e+00 1.6e+02  1  0  0  0 23   1  0  0  0 23  1911
VecMDot               10 1.0 1.5253e-01 7.1 4.67e+07 1.1 0.0e+00 0.0e+00 1.0e+01  0  0  0  0  1   0  0  0  0  1  5856
VecNorm              173 1.0 1.8166e-01 1.6 1.47e+08 1.1 0.0e+00 0.0e+00 1.7e+02  0  0  0  0 24   0  0  0  0 25 15467
VecScale              11 1.0 3.4841e-03 1.3 4.67e+06 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 25639
VecCopy              648 1.0 4.1875e-01 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet               653 1.0 2.0786e-01 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY                2 1.0 1.4353e-03 1.3 1.70e+06 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 22631
VecAYPX              644 1.0 7.1985e-01 1.1 4.10e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 10897
VecAXPBYCZ           642 1.0 8.8376e-01 1.1 1.23e+09 1.1 0.0e+00 0.0e+00 0.0e+00  1  2  0  0  0   1  2  0  0  0 26555
VecWAXPY             320 1.0 4.0295e-01 1.1 2.72e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 12898
VecMAXPY              11 1.0 3.5891e-02 1.1 5.52e+07 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 29413
VecAssemblyBegin       3 1.0 9.0734e-03 1.0 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAssemblyEnd         3 1.0 5.5826e-04 4.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecScatterBegin      654 1.0 4.2187e-01 2.0 0.00e+00 0.0 9.5e+04 4.6e+04 0.0e+00  0  0 98 73  0   0  0 98 73  0     0
VecScatterEnd        654 1.0 9.1721e+0049.7 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  2  0  0  0  0   2  0  0  0  0     0
VecNormalize          11 1.0 3.2412e-02 3.1 1.40e+07 1.1 0.0e+00 0.0e+00 1.1e+01  0  0  0  0  2   0  0  0  0  2  8268
SFSetGraph             2 1.0 5.1156e-04 1.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.1443e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  1  0  0   0  0  1  0  0     0
SFBcastOpBegin       654 1.0 4.2045e-01 2.0 0.00e+00 0.0 9.5e+04 4.6e+04 0.0e+00  0  0 98 73  0   0  0 98 73  0     0
SFBcastOpEnd         654 1.0 9.1706e+0050.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  2  0  0  0  0   2  0  0  0  0     0
SFPack               654 1.0 4.0495e-01 2.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack             654 1.0 4.3237e-04 1.5 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               2 1.0 2.3214e+00 1.0 1.23e+09 1.1 1.5e+03 4.6e+04 2.3e+01  1  2  1  1  3   1  2  1  1  3 10082
KSPSolve               1 1.0 1.3447e+02 1.0 7.21e+10 1.1 9.5e+04 4.6e+04 6.6e+02 82100 98 73 94  82100 98 73 95 10193
KSPGMRESOrthog        10 1.0 1.8058e-01 3.5 9.34e+07 1.1 0.0e+00 0.0e+00 1.0e+01  0  0  0  0  1   0  0  0  0  1  9893
PCSetUp                1 1.0 2.3186e+00 1.0 1.23e+09 1.1 1.5e+03 4.6e+04 2.3e+01  1  2  1  1  3   1  2  1  1  3 10094
PCApply              333 1.0 1.0626e+02 1.1 5.28e+10 1.1 4.7e+04 4.6e+04 0.0e+00 63 73 48 36  0  63 73 48 36  0  9431
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     3              3    354240752     0.
           Index Set     4              4       304416     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    32             32     99191384     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     4              4        35152     0.
      Preconditioner     4              4         4256     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 2.94e-08
Average time for MPI_Barrier(): 5.0098e-06
Average time for zero size MPI_Send(): 3.3527e-06
#PETSc Option Table entries:
-d 3
-ksp_type bcgs
-log_view
-mat_type aij
-n 100
-pc_type mg
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type tfqmr -pc_type bjacobi -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 17:03:14 2020            |
| OS:             Linux                               |
| HostName:       sdumont6181                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.91129, Active time=2.91114                                       |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.4035      0.000008    0.4035      0.000008    13.86    13.86    |
| Ke                            50792      1.7753      0.000035    1.7753      0.000035    60.98    60.98    |
| elem init                     50792      0.7323      0.000014    0.7323      0.000014    25.16    25.16    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.9111                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 117.731764
Tempo total: 117.716273
Tempo total: 117.704833
Tempo total: 117.737368
Tempo total: 117.717975
Tempo total: 117.693565
Tempo total: 117.725381
Tempo total: 117.730701
Tempo total: 117.705066
Tempo total: 117.717174
Tempo total: 117.629860
Tempo total: 117.633808
Tempo total: 117.629924
Tempo total: 117.646000
Tempo total: 117.630113
Tempo total: 117.635571
Tempo total: 117.621799
Tempo total: 117.608772
Tempo total: 117.738075
Tempo total: 117.736531
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6181 with 20 processors, by luciano.siqueira Thu Dec 10 17:04:44 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           1.181e+02     1.000   1.180e+02
Objects:              3.900e+01     1.000   3.900e+01
Flop:                 5.871e+10     1.106   5.581e+10  1.116e+12
Flop/sec:             4.974e+08     1.106   4.727e+08  9.455e+09
MPI Messages:         5.816e+03     2.715   3.875e+03  7.750e+04
MPI Message Lengths:  3.171e+08     1.625   6.548e+04  5.075e+09
MPI Reductions:       8.200e+02     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 1.1805e+02 100.0%  1.1161e+12 100.0%  7.750e+04 100.0%  6.548e+04      100.0%  8.130e+02  99.1%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 5.3422e-01104.4 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  0  0  1  0  1   0  0  1  0  1     0
BuildTwoSidedF         5 1.0 5.3402e-01124.1 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  0  0  0  4  1   0  0  0  4  1     0
MatMult              517 1.0 4.2404e+01 1.1 2.76e+10 1.1 7.5e+04 4.6e+04 0.0e+00 35 47 97 68  0  35 47 97 68  0 12433
MatSolve             518 1.0 4.1298e+01 1.1 2.71e+10 1.1 0.0e+00 0.0e+00 0.0e+00 33 46  0  0  0  33 46  0  0  0 12401
MatLUFactorNum         1 1.0 2.4482e+00 1.1 1.27e+09 1.1 0.0e+00 0.0e+00 0.0e+00  2  2  0  0  0   2  2  0  0  0  9883
MatILUFactorSym        1 1.0 1.5388e-01 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatAssemblyBegin       2 1.0 6.0852e-01 3.4 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  0  0  0  4  0   0  0  0  4  0     0
MatAssemblyEnd         2 1.0 3.4127e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  0  0  0  0  1   0  0  0  0  1    13
MatGetRowIJ            1 1.0 3.9610e-06 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatGetOrdering         1 1.0 4.2302e-03 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatZeroEntries         3 1.0 1.2166e-01 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecDot               516 1.0 2.9554e+00 8.8 4.38e+08 1.1 0.0e+00 0.0e+00 5.2e+02  1  1  0  0 63   1  1  0  0 63  2836
VecNorm              260 1.0 2.7750e+0018.7 2.21e+08 1.1 0.0e+00 0.0e+00 2.6e+02  1  0  0  0 32   1  0  0  0 32  1522
VecCopy                6 1.0 4.5369e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet               524 1.0 2.4204e-01 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY             1032 1.0 8.5926e-01 1.1 8.77e+08 1.1 0.0e+00 0.0e+00 0.0e+00  1  2  0  0  0   1  2  0  0  0 19506
VecAYPX              516 1.0 6.0680e-01 1.1 4.37e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 13784
VecWAXPY            1030 1.0 1.3417e+00 1.1 7.65e+08 1.1 0.0e+00 0.0e+00 0.0e+00  1  1  0  0  0   1  1  0  0  0 10907
VecAssemblyBegin       3 1.0 9.9394e-03 1.0 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAssemblyEnd         3 1.0 6.1250e-04 4.8 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecScatterBegin      518 1.0 3.5966e-01 2.1 0.00e+00 0.0 7.6e+04 4.6e+04 0.0e+00  0  0 98 68  0   0  0 98 68  0     0
VecScatterEnd        518 1.0 4.3476e+0058.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  2  0  0  0  0   2  0  0  0  0     0
SFSetGraph             2 1.0 5.1691e-04 1.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.1321e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  1  0  0   0  0  1  0  0     0
SFBcastOpBegin       518 1.0 3.5856e-01 2.1 0.00e+00 0.0 7.6e+04 4.6e+04 0.0e+00  0  0 98 68  0   0  0 98 68  0     0
SFBcastOpEnd         518 1.0 4.3463e+0059.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  2  0  0  0  0   2  0  0  0  0     0
SFPack               518 1.0 3.4737e-01 2.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack             518 1.0 3.0851e-04 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               2 1.0 4.7980e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSolve               1 1.0 8.8951e+01 1.0 5.87e+10 1.1 7.5e+04 4.6e+04 7.8e+02 75100 97 68 95  75100 97 68 95 12545
PCSetUp                2 1.0 2.6139e+00 1.1 1.27e+09 1.1 0.0e+00 0.0e+00 0.0e+00  2  2  0  0  0   2  2  0  0  0  9257
PCSetUpOnBlocks        1 1.0 2.6064e+00 1.1 1.27e+09 1.1 0.0e+00 0.0e+00 0.0e+00  2  2  0  0  0   2  2  0  0  0  9284
PCApply              518 1.0 4.1544e+01 1.1 2.71e+10 1.1 0.0e+00 0.0e+00 0.0e+00 33 46  0  0  0  33 46  0  0  0 12328
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     4              4    666933972     0.
           Index Set     7              7      5403804     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    18             18     44802840     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     2              2         3016     0.
      Preconditioner     2              2         1944     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 2.79e-08
Average time for MPI_Barrier(): 5.2036e-06
Average time for zero size MPI_Send(): 3.3829e-06
#PETSc Option Table entries:
-d 3
-ksp_type tfqmr
-log_view
-mat_type aij
-n 100
-pc_type bjacobi
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type tfqmr -pc_type jacobi -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 17:05:16 2020            |
| OS:             Linux                               |
| HostName:       sdumont6181                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.81238, Active time=2.86514                                       |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.3964      0.000008    0.3964      0.000008    13.83    13.83    |
| Ke                            50792      1.7479      0.000034    1.7479      0.000034    61.00    61.00    |
| elem init                     50792      0.7209      0.000014    0.7209      0.000014    25.16    25.16    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.8651                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 921.045220
Tempo total: 921.055228
Tempo total: 920.985361
Tempo total: 921.021479
Tempo total: 921.044968
Tempo total: 921.023774
Tempo total: 921.007387
Tempo total: 921.015520
Tempo total: 920.989938
Tempo total: 920.985443
Tempo total: 921.000293
Tempo total: 920.999098
Tempo total: 921.002524
Tempo total: 920.994980
Tempo total: 920.999914
Tempo total: 920.997085
Tempo total: 921.003247
Tempo total: 920.986510
Tempo total: 920.980705
Tempo total: 921.068041
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6181 with 20 processors, by luciano.siqueira Thu Dec 10 17:20:08 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           9.214e+02     1.000   9.214e+02
Objects:              3.200e+01     1.000   3.200e+01
Flop:                 5.917e+11     1.100   5.648e+11  1.130e+13
Flop/sec:             6.422e+08     1.100   6.130e+08  1.226e+10
MPI Messages:         1.102e+05     2.748   7.312e+04  1.462e+06
MPI Message Lengths:  4.583e+09     1.940   4.689e+04  6.857e+10
MPI Reductions:       1.505e+04     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 9.2137e+02 100.0%  1.1296e+13 100.0%  1.462e+06 100.0%  4.689e+04      100.0%  1.504e+04 100.0%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 5.2973e-0143.8 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  0  0  0  0  0   0  0  0  0  0     0
BuildTwoSidedF         5 1.0 5.2866e-0170.5 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatMult            10002 1.0 8.1801e+02 1.1 5.34e+11 1.1 1.5e+06 4.6e+04 0.0e+00 87 90100 98  0  87 90100 98  0 12468
MatAssemblyBegin       2 1.0 6.3657e-01 5.1 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatAssemblyEnd         2 1.0 3.2554e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  0  0  0  0  0   0  0  0  0  0    13
MatZeroEntries         3 1.0 1.2116e-01 1.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecDot             10001 1.0 2.7372e+01 3.9 8.50e+09 1.1 0.0e+00 0.0e+00 1.0e+04  2  1  0  0 66   2  1  0  0 66  5934
VecNorm             5002 1.0 2.3461e+01 9.0 4.25e+09 1.1 0.0e+00 0.0e+00 5.0e+03  1  1  0  0 33   1  1  0  0 33  3463
VecCopy                6 1.0 4.5309e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet                 6 1.0 2.2466e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY            20001 1.0 1.7172e+01 1.1 1.70e+10 1.1 0.0e+00 0.0e+00 0.0e+00  2  3  0  0  0   2  3  0  0  0 18917
VecAYPX            10000 1.0 1.1660e+01 1.1 8.49e+09 1.1 0.0e+00 0.0e+00 0.0e+00  1  1  0  0  0   1  1  0  0  0 13928
VecWAXPY           20000 1.0 2.5926e+01 1.1 1.49e+10 1.1 0.0e+00 0.0e+00 0.0e+00  3  3  0  0  0   3  3  0  0  0 10962
VecAssemblyBegin       3 1.0 1.3103e-02 1.4 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAssemblyEnd         3 1.0 5.9147e-04 4.5 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecPointwiseMult   10003 1.0 1.2526e+01 1.1 4.25e+09 1.1 0.0e+00 0.0e+00 0.0e+00  1  1  0  0  0   1  1  0  0  0  6485
VecScatterBegin    10003 1.0 6.9292e+00 2.1 0.00e+00 0.0 1.5e+06 4.6e+04 0.0e+00  1  0100 98  0   1  0100 98  0     0
VecScatterEnd      10003 1.0 7.9160e+0157.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  4  0  0  0  0   4  0  0  0  0     0
SFSetGraph             2 1.0 4.9901e-04 1.8 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.1196e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFBcastOpBegin     10003 1.0 6.9101e+00 2.1 0.00e+00 0.0 1.5e+06 4.6e+04 0.0e+00  1  0100 98  0   1  0100 98  0     0
SFBcastOpEnd       10003 1.0 7.9137e+0158.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  4  0  0  0  0   4  0  0  0  0     0
SFPack             10003 1.0 6.7209e+00 2.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack           10003 1.0 6.2089e-03 1.6 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               1 1.0 4.7951e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSolve               1 1.0 8.9153e+02 1.0 5.92e+11 1.1 1.5e+06 4.6e+04 1.5e+04 97100100 98100  97100100 98100 12670
PCSetUp                1 1.0 1.1600e-06 7.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
PCApply            10003 1.0 1.2617e+01 1.1 4.25e+09 1.1 0.0e+00 0.0e+00 2.0e+00  1  1  0  0  0   1  1  0  0  0  6438
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     3              3    344047400     0.
           Index Set     4              4       304416     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    17             17     48199184     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     1              1         1600     0.
      Preconditioner     1              1          968     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 2.96e-08
Average time for MPI_Barrier(): 5.1334e-06
Average time for zero size MPI_Send(): 3.4625e-06
#PETSc Option Table entries:
-d 3
-ksp_type tfqmr
-log_view
-mat_type aij
-n 100
-pc_type jacobi
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type tfqmr -pc_type sor -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 17:20:39 2020            |
| OS:             Linux                               |
| HostName:       sdumont6181                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.83661, Active time=2.88302                                       |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.3961      0.000008    0.3961      0.000008    13.74    13.74    |
| Ke                            50792      1.7637      0.000035    1.7637      0.000035    61.18    61.18    |
| elem init                     50792      0.7233      0.000014    0.7233      0.000014    25.09    25.09    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.8830                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 150.260285
Tempo total: 150.282608
Tempo total: 150.262263
Tempo total: 150.262239
Tempo total: 150.267857
Tempo total: 150.231974
Tempo total: 150.222290
Tempo total: 150.227620
Tempo total: 150.261926
Tempo total: 150.237952
Tempo total: 150.236393
Tempo total: 150.241170
Tempo total: 150.246247
Tempo total: 150.221502
Tempo total: 150.241596
Tempo total: 150.221529
Tempo total: 150.230099
Tempo total: 150.222124
Tempo total: 150.242193
Tempo total: 150.270906
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6181 with 20 processors, by luciano.siqueira Thu Dec 10 17:22:42 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           1.506e+02     1.000   1.506e+02
Objects:              3.100e+01     1.000   3.100e+01
Flop:                 6.546e+10     1.106   6.222e+10  1.244e+12
Flop/sec:             4.346e+08     1.106   4.131e+08  8.262e+09
MPI Messages:         6.586e+03     2.719   4.386e+03  8.772e+04
MPI Message Lengths:  3.486e+08     1.651   6.319e+04  5.543e+09
MPI Reductions:       9.250e+02     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 1.5062e+02 100.0%  1.2444e+12 100.0%  8.772e+04 100.0%  6.319e+04      100.0%  9.180e+02  99.2%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 4.8120e-01115.7 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  0  0  0  0  1   0  0  0  0  1     0
BuildTwoSidedF         5 1.0 4.7969e-01133.9 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  0  0  0  4  1   0  0  0  4  1     0
MatMult              587 1.0 4.7978e+01 1.1 3.14e+10 1.1 8.6e+04 4.6e+04 0.0e+00 31 48 98 71  0  31 48 98 71  0 12476
MatSOR               588 1.0 7.0352e+01 1.1 3.10e+10 1.1 0.0e+00 0.0e+00 0.0e+00 44 47  0  0  0  44 47  0  0  0  8332
MatAssemblyBegin       2 1.0 5.5241e-01 2.9 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  0  0  0  4  0   0  0  0  4  0     0
MatAssemblyEnd         2 1.0 3.2560e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  0  0  0  0  1   0  0  0  0  1    13
MatZeroEntries         3 1.0 1.2217e-01 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecDot               586 1.0 4.1167e+0010.7 4.98e+08 1.1 0.0e+00 0.0e+00 5.9e+02  2  1  0  0 63   2  1  0  0 64  2312
VecNorm              295 1.0 3.8364e+0023.1 2.51e+08 1.1 0.0e+00 0.0e+00 3.0e+02  1  0  0  0 32   1  0  0  0 32  1249
VecCopy                6 1.0 4.4747e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet                 6 1.0 2.2385e-03 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY             1172 1.0 9.7577e-01 1.1 9.96e+08 1.1 0.0e+00 0.0e+00 0.0e+00  1  2  0  0  0   1  2  0  0  0 19507
VecAYPX              586 1.0 6.7713e-01 1.1 4.97e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 14032
VecWAXPY            1170 1.0 1.5147e+00 1.1 8.69e+08 1.1 0.0e+00 0.0e+00 0.0e+00  1  1  0  0  0   1  1  0  0  0 10974
VecAssemblyBegin       3 1.0 9.3210e-03 1.0 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAssemblyEnd         3 1.0 6.0584e-04 4.7 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecScatterBegin      588 1.0 4.0705e-01 2.2 0.00e+00 0.0 8.6e+04 4.6e+04 0.0e+00  0  0 98 71  0   0  0 98 71  0     0
VecScatterEnd        588 1.0 4.6456e+0060.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
SFSetGraph             2 1.0 4.9705e-04 1.8 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.1196e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  1  0  0   0  0  1  0  0     0
SFBcastOpBegin       588 1.0 4.0554e-01 2.2 0.00e+00 0.0 8.6e+04 4.6e+04 0.0e+00  0  0 98 71  0   0  0 98 71  0     0
SFBcastOpEnd         588 1.0 4.6442e+0061.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
SFPack               588 1.0 3.9183e-01 2.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack             588 1.0 3.8052e-04 1.5 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               1 1.0 4.8045e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSolve               1 1.0 1.2110e+02 1.0 6.54e+10 1.1 8.6e+04 4.6e+04 8.8e+02 80100 98 71 95  80100 98 71 96 10274
PCSetUp                1 1.0 3.4000e-07 2.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
PCApply              588 1.0 7.0353e+01 1.1 3.10e+10 1.1 0.0e+00 0.0e+00 0.0e+00 44 47  0  0  0  44 47  0  0  0  8332
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     3              3    354240752     0.
           Index Set     4              4       304416     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    16             16     44799704     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     1              1         1600     0.
      Preconditioner     1              1          968     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 2.86e-08
Average time for MPI_Barrier(): 5.1952e-06
Average time for zero size MPI_Send(): 3.23765e-06
#PETSc Option Table entries:
-d 3
-ksp_type tfqmr
-log_view
-mat_type aij
-n 100
-pc_type sor
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type tfqmr -pc_type mg -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 17:23:13 2020            |
| OS:             Linux                               |
| HostName:       sdumont6181                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.89043, Active time=2.91066                                       |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.4029      0.000008    0.4029      0.000008    13.84    13.84    |
| Ke                            50792      1.7801      0.000035    1.7801      0.000035    61.16    61.16    |
| elem init                     50792      0.7277      0.000014    0.7277      0.000014    25.00    25.00    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.9107                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 152.247819
Tempo total: 152.293896
Tempo total: 152.270118
Tempo total: 152.281095
Tempo total: 152.258305
Tempo total: 152.233386
Tempo total: 152.253109
Tempo total: 152.241273
Tempo total: 152.217714
Tempo total: 152.230322
Tempo total: 152.243317
Tempo total: 152.226169
Tempo total: 152.197940
Tempo total: 152.205284
Tempo total: 152.231263
Tempo total: 152.206214
Tempo total: 152.200263
Tempo total: 152.219477
Tempo total: 152.202880
Tempo total: 152.295127
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6181 with 20 processors, by luciano.siqueira Thu Dec 10 17:25:17 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           1.526e+02     1.000   1.526e+02
Objects:              5.600e+01     1.000   5.600e+01
Flop:                 6.613e+10     1.106   6.285e+10  1.257e+12
Flop/sec:             4.333e+08     1.106   4.119e+08  8.237e+09
MPI Messages:         6.696e+03     2.720   4.459e+03  8.918e+04
MPI Message Lengths:  3.531e+08     1.654   6.291e+04  5.610e+09
MPI Reductions:       5.070e+02     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 1.5260e+02 100.0%  1.2570e+12 100.0%  8.918e+04 100.0%  6.291e+04      100.0%  5.000e+02  98.6%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 4.8294e-0197.4 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  0  0  0  0  1   0  0  0  0  1     0
BuildTwoSidedF         5 1.0 4.8140e-01118.4 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  0  0  0  4  1   0  0  0  4  1     0
MatMult              597 1.0 5.1740e+01 1.1 3.19e+10 1.1 8.7e+04 4.6e+04 0.0e+00 32 48 98 71  0  32 48 98 71  0 11766
MatSOR               599 1.0 7.1738e+01 1.1 3.16e+10 1.1 0.0e+00 0.0e+00 0.0e+00 45 48  0  0  0  45 48  0  0  0  8324
MatAssemblyBegin       2 1.0 5.9712e-01 5.6 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  0  0  0  4  0   0  0  0  4  0     0
MatAssemblyEnd         2 1.0 3.4208e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  0  0  0  0  1   0  0  0  0  1    13
MatZeroEntries         3 1.0 1.2158e-01 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecDot               292 1.0 2.5223e+0013.6 2.48e+08 1.1 0.0e+00 0.0e+00 2.9e+02  1  0  0  0 58   1  0  0  0 58  1880
VecMDot               10 1.0 1.3727e-01 6.4 4.67e+07 1.1 0.0e+00 0.0e+00 1.0e+01  0  0  0  0  2   0  0  0  0  2  6507
VecNorm              159 1.0 2.4570e+0024.8 1.35e+08 1.1 0.0e+00 0.0e+00 1.6e+02  1  0  0  0 31   1  0  0  0 32  1051
VecScale              11 1.0 3.3901e-03 1.3 4.67e+06 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 26349
VecCopy              595 1.0 3.8725e-01 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet               596 1.0 1.8620e-01 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY              584 1.0 4.7611e-01 1.1 4.96e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 19921
VecAYPX              879 1.0 1.0056e+00 1.1 6.21e+08 1.1 0.0e+00 0.0e+00 0.0e+00  1  1  0  0  0   1  1  0  0  0 11806
VecAXPBYCZ           294 1.0 4.0110e-01 1.1 6.24e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 29761
VecWAXPY             582 1.0 7.5857e-01 1.1 4.32e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 10898
VecMAXPY              11 1.0 3.6234e-02 1.1 5.52e+07 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 29135
VecAssemblyBegin       3 1.0 9.7447e-03 1.0 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  0  0  1   0  0  0  0  1     0
VecAssemblyEnd         3 1.0 6.1408e-04 4.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecScatterBegin      598 1.0 3.8668e-01 2.0 0.00e+00 0.0 8.7e+04 4.6e+04 0.0e+00  0  0 98 71  0   0  0 98 71  0     0
VecScatterEnd        598 1.0 7.8895e+0097.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  2  0  0  0  0   2  0  0  0  0     0
VecNormalize          11 1.0 3.8244e-02 3.7 1.40e+07 1.1 0.0e+00 0.0e+00 1.1e+01  0  0  0  0  2   0  0  0  0  2  7007
SFSetGraph             2 1.0 5.1324e-04 1.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.1663e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  1  0  0   0  0  1  0  0     0
SFBcastOpBegin       598 1.0 3.8518e-01 2.0 0.00e+00 0.0 8.7e+04 4.6e+04 0.0e+00  0  0 98 71  0   0  0 98 71  0     0
SFBcastOpEnd         598 1.0 7.8879e+0098.8 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  2  0  0  0  0   2  0  0  0  0     0
SFPack               598 1.0 3.7158e-01 2.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack             598 1.0 3.8872e-04 1.5 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               2 1.0 2.3210e+00 1.0 1.23e+09 1.1 1.5e+03 4.6e+04 2.3e+01  2  2  2  1  5   2  2  2  1  5 10083
KSPSolve               1 1.0 1.2301e+02 1.0 6.61e+10 1.1 8.7e+04 4.6e+04 4.6e+02 81100 98 71 91  81100 98 71 93 10217
KSPGMRESOrthog        10 1.0 1.6499e-01 3.2 9.34e+07 1.1 0.0e+00 0.0e+00 1.0e+01  0  0  0  0  2   0  0  0  0  2 10828
PCSetUp                1 1.0 2.3168e+00 1.0 1.23e+09 1.1 1.5e+03 4.6e+04 2.3e+01  2  2  2  1  5   2  2  2  1  5 10102
PCApply              305 1.0 9.6714e+01 1.0 4.83e+10 1.1 4.3e+04 4.6e+04 0.0e+00 62 73 48 35  0  62 73 48 35  0  9471
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     3              3    354240752     0.
           Index Set     4              4       304416     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    35             35    109389824     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     4              4        35144     0.
      Preconditioner     4              4         4256     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 2.85e-08
Average time for MPI_Barrier(): 4.9486e-06
Average time for zero size MPI_Send(): 3.4253e-06
#PETSc Option Table entries:
-d 3
-ksp_type tfqmr
-log_view
-mat_type aij
-n 100
-pc_type mg
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type cr -pc_type bjacobi -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 17:25:48 2020            |
| OS:             Linux                               |
| HostName:       sdumont6181                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.83174, Active time=2.88019                                       |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.3993      0.000008    0.3993      0.000008    13.86    13.86    |
| Ke                            50792      1.7591      0.000035    1.7591      0.000035    61.08    61.08    |
| elem init                     50792      0.7218      0.000014    0.7218      0.000014    25.06    25.06    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.8802                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 97.456250
Tempo total: 97.461357
Tempo total: 97.434272
Tempo total: 97.442411
Tempo total: 97.425264
Tempo total: 97.445867
Tempo total: 97.410969
Tempo total: 97.441425
Tempo total: 97.456435
Tempo total: 97.426377
Tempo total: 97.446390
Tempo total: 97.415089
Tempo total: 97.432061
Tempo total: 97.430205
Tempo total: 97.432257
Tempo total: 97.426151
Tempo total: 97.432607
Tempo total: 97.419928
Tempo total: 97.425049
Tempo total: 97.483649
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6181 with 20 processors, by luciano.siqueira Thu Dec 10 17:26:58 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           9.781e+01     1.000   9.781e+01
Objects:              3.600e+01     1.000   3.600e+01
Flop:                 4.537e+10     1.106   4.312e+10  8.624e+11
Flop/sec:             4.638e+08     1.106   4.409e+08  8.818e+09
MPI Messages:         4.474e+03     2.705   2.984e+03  5.969e+04
MPI Message Lengths:  2.623e+08     1.567   7.134e+04  4.258e+09
MPI Reductions:       8.320e+02     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 9.7805e+01 100.0%  8.6245e+11 100.0%  5.969e+04 100.0%  7.134e+04      100.0%  8.250e+02  99.2%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 4.1492e-0194.3 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  0  0  1  0  1   0  0  1  0  1     0
BuildTwoSidedF         5 1.0 4.1579e-01106.5 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  0  0  1  5  1   0  0  1  5  1     0
MatMult              395 1.0 3.2298e+01 1.1 2.11e+10 1.1 5.8e+04 4.6e+04 0.0e+00 32 47 97 62  0  32 47 97 62  0 12471
MatSolve             395 1.0 3.1476e+01 1.1 2.06e+10 1.1 0.0e+00 0.0e+00 0.0e+00 30 45  0  0  0  30 45  0  0  0 12408
MatLUFactorNum         1 1.0 2.4495e+00 1.1 1.27e+09 1.1 0.0e+00 0.0e+00 0.0e+00  2  3  0  0  0   2  3  0  0  0  9878
MatILUFactorSym        1 1.0 1.5036e-01 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatAssemblyBegin       2 1.0 4.9104e-01 3.2 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  0  0  0  5  0   0  0  0  5  0     0
MatAssemblyEnd         2 1.0 3.4237e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  0  0  0  0  1   0  0  0  0  1    13
MatGetRowIJ            1 1.0 3.8780e-06 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatGetOrdering         1 1.0 4.1567e-03 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatZeroEntries         3 1.0 1.2073e-01 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecDot               393 1.0 3.5929e+0015.0 3.34e+08 1.1 0.0e+00 0.0e+00 3.9e+02  2  1  0  0 47   2  1  0  0 48  1776
VecNorm                1 1.0 9.1305e-0316.7 8.49e+05 1.1 0.0e+00 0.0e+00 1.0e+00  0  0  0  0  0   0  0  0  0  0  1779
VecCopy                3 1.0 2.0580e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet               400 1.0 2.0136e-01 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY              786 1.0 6.6320e-01 1.1 6.68e+08 1.1 0.0e+00 0.0e+00 0.0e+00  1  1  0  0  0   1  1  0  0  0 19248
VecAYPX              785 1.0 8.7665e-01 1.1 6.66e+08 1.1 0.0e+00 0.0e+00 0.0e+00  1  1  0  0  0   1  1  0  0  0 14534
VecAssemblyBegin       3 1.0 9.6682e-03 1.0 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAssemblyEnd         3 1.0 5.9872e-04 4.5 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecScatterBegin      396 1.0 2.5992e-01 2.2 0.00e+00 0.0 5.8e+04 4.6e+04 0.0e+00  0  0 97 62  0   0  0 97 62  0     0
VecScatterEnd        396 1.0 3.3312e+0062.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
VecReduceArith       788 1.0 4.7646e-01 1.2 6.69e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 26861
VecReduceComm        394 1.0 1.6132e+00228.6 0.00e+00 0.0 0.0e+00 0.0e+00 3.9e+02  1  0  0  0 47   1  0  0  0 48     0
SFSetGraph             2 1.0 5.1385e-04 2.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.1343e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  1  0  0   0  0  1  0  0     0
SFBcastOpBegin       396 1.0 2.5898e-01 2.2 0.00e+00 0.0 5.8e+04 4.6e+04 0.0e+00  0  0 97 62  0   0  0 97 62  0     0
SFBcastOpEnd         396 1.0 3.3303e+0063.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
SFPack               396 1.0 2.4983e-01 2.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack             396 1.0 2.7484e-04 1.7 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               2 1.0 3.1743e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSolve               1 1.0 6.8755e+01 1.0 4.54e+10 1.1 5.8e+04 4.6e+04 7.9e+02 70100 97 62 95  70100 97 62 96 12541
PCSetUp                2 1.0 2.6120e+00 1.1 1.27e+09 1.1 0.0e+00 0.0e+00 0.0e+00  3  3  0  0  0   3  3  0  0  0  9264
PCSetUpOnBlocks        1 1.0 2.6041e+00 1.1 1.27e+09 1.1 0.0e+00 0.0e+00 0.0e+00  3  3  0  0  0   3  3  0  0  0  9292
PCApply              395 1.0 3.1680e+01 1.1 2.06e+10 1.1 0.0e+00 0.0e+00 0.0e+00 31 45  0  0  0  31 45  0  0  0 12328
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     4              4    666933972     0.
           Index Set     7              7      5403804     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    15             15     34604400     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     2              2         3016     0.
      Preconditioner     2              2         1944     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 2.91e-08
Average time for MPI_Barrier(): 4.8416e-06
Average time for zero size MPI_Send(): 3.34e-06
#PETSc Option Table entries:
-d 3
-ksp_type cr
-log_view
-mat_type aij
-n 100
-pc_type bjacobi
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type cr -pc_type jacobi -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

slurmstepd: error: *** JOB 801703 ON sdumont6181 CANCELLED AT 2020-12-10T17:27:15 DUE TO TIME LIMIT ***
mpirun: Forwarding signal 18 to job
[19]PETSC ERROR: ------------------------------------------------------------------------
[19]PETSC ERROR: Caught signal number 15 Terminate: Some process (or the batch system) has told this process to end
[19]PETSC ERROR: Try option -start_in_debugger or -on_error_attach_debugger
[19]PETSC ERROR: or see https://www.mcs.anl.gov/petsc/documentation/faq.html#valgrind
[19]PETSC ERROR: or try http://valgrind.org on GNU/linux and Apple Mac OS X to find memory corruption errors
[19]PETSC ERROR: configure using --with-debugging=yes, recompile, link, and run 
[19]PETSC ERROR: to get more information on the crash.
[19]PETSC ERROR: --------------------- Error Message --------------------------------------------------------------
[19]PETSC ERROR: Signal received
[19]PETSC ERROR: See https://www.mcs.anl.gov/petsc/documentation/faq.html for trouble shooting.
[19]PETSC ERROR: Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500
[19]PETSC ERROR: [0]PETSC ERROR: [1]PETSC ERROR: ------------------------------------------------------------------------
[1]PETSC ERROR: Caught signal number 15 Terminate: Some process (or the batch system) has told this process to end
[1]PETSC ERROR: Try option -start_in_debugger or -on_error_attach_debugger
[1]PETSC ERROR: or see https://www.mcs.anl.gov/petsc/documentation/faq.html#valgrind
[1]PETSC ERROR: or try http://valgrind.org on GNU/linux and Apple Mac OS X to find memory corruption errors
[1]PETSC ERROR: configure using --with-debugging=yes, recompile, link, and run 
[1]PETSC ERROR: to get more information on the crash.
[2]PETSC ERROR: ------------------------------------------------------------------------
[2]PETSC ERROR: Caught signal number 15 Terminate: Some process (or the batch system) has told this process to end
[2]PETSC ERROR: Try option -start_in_debugger or -on_error_attach_debugger
[2]PETSC ERROR: or see https://www.mcs.anl.gov/petsc/documentation/faq.html#valgrind
[2]PETSC ERROR: or try http://valgrind.org on GNU/linux and Apple Mac OS X to find memory corruption errors
[2]PETSC ERROR: configure using --with-debugging=yes, recompile, link, and run 
[2]PETSC ERROR: to get more information on the crash.
[2]PETSC ERROR: --------------------- Error Message --------------------------------------------------------------
[2]PETSC ERROR: Signal received
[2]PETSC ERROR: See https://www.mcs.anl.gov/petsc/documentation/faq.html for trouble shooting.
[2]PETSC ERROR: Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500
[2]PETSC ERROR: /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6181 by luciano.siqueira Thu Dec 10 17:27:00 2020
[2]PETSC ERROR: Configure options --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
[2]PETSC ERROR: #1 User provided function() line 0 in  unknown file
[3]PETSC ERROR: ------------------------------------------------------------------------
[3]PETSC ERROR: Caught signal number 15 Terminate: Some process (or the batch system) has told this process to end
[3]PETSC ERROR: Try option -start_in_debugger or -on_error_attach_debugger
[3]PETSC ERROR: or see https://www.mcs.anl.gov/petsc/documentation/faq.html#valgrind
[3]PETSC ERROR: or try http://valgrind.org on GNU/linux and Apple Mac OS X to find memory corruption errors
[3]PETSC ERROR: configure using --with-debugging=yes, recompile, link, and run 
[3]PETSC ERROR: to get more information on the crash.
[3]PETSC ERROR: --------------------- Error Message --------------------------------------------------------------
[3]PETSC ERROR: Signal received
[3]PETSC ERROR: See https://www.mcs.anl.gov/petsc/documentation/faq.html for trouble shooting.
[3]PETSC ERROR: Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500
[3]PETSC ERROR: /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6181 by luciano.siqueira Thu Dec 10 17:27:00 2020
[3]PETSC ERROR: Configure options --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
[3]PETSC ERROR: #1 User provided function() line 0 in  unknown file
[4]PETSC ERROR: ------------------------------------------------------------------------
[5]PETSC ERROR: ------------------------------------------------------------------------
[5]PETSC ERROR: Caught signal number 15 Terminate: Some process (or the batch system) has told this process to end
[5]PETSC ERROR: Try option -start_in_debugger or -on_error_attach_debugger
[5]PETSC ERROR: or see https://www.mcs.anl.gov/petsc/documentation/faq.html#valgrind
[5]PETSC ERROR: or try http://valgrind.org on GNU/linux and Apple Mac OS X to find memory corruption errors
[5]PETSC ERROR: configure using --with-debugging=yes, recompile, link, and run 
[5]PETSC ERROR: to get more information on the crash.
[5]PETSC ERROR: --------------------- Error Message --------------------------------------------------------------
[5]PETSC ERROR: Signal received
[5]PETSC ERROR: See https://www.mcs.anl.gov/petsc/documentation/faq.html for trouble shooting.
[5]PETSC ERROR: Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500
[5]PETSC ERROR: /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6181 by luciano.siqueira Thu Dec 10 17:27:00 2020
[5]PETSC ERROR: Configure options --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
[5]PETSC ERROR: #1 User provided function() line 0 in  unknown file
[6]PETSC ERROR: ------------------------------------------------------------------------
[6]PETSC ERROR: Caught signal number 15 Terminate: Some process (or the batch system) has told this process to end
[6]PETSC ERROR: Try option -start_in_debugger or -on_error_attach_debugger
[6]PETSC ERROR: or see https://www.mcs.anl.gov/petsc/documentation/faq.html#valgrind
[6]PETSC ERROR: or try http://valgrind.org on GNU/linux and Apple Mac OS X to find memory corruption errors
[6]PETSC ERROR: configure using --with-debugging=yes, recompile, link, and run 
[6]PETSC ERROR: to get more information on the crash.
[6]PETSC ERROR: --------------------- Error Message --------------------------------------------------------------
[6]PETSC ERROR: Signal received
[6]PETSC ERROR: See https://www.mcs.anl.gov/petsc/documentation/faq.html for trouble shooting.
[6]PETSC ERROR: Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500
[6]PETSC ERROR: /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6181 by luciano.siqueira Thu Dec 10 17:27:00 2020
[6]PETSC ERROR: Configure options --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
[6]PETSC ERROR: #1 User provided function() line 0 in  unknown file
[7]PETSC ERROR: ------------------------------------------------------------------------
[7]PETSC ERROR: Caught signal number 15 Terminate: Some process (or the batch system) has told this process to end
[7]PETSC ERROR: Try option -start_in_debugger or -on_error_attach_debugger
[7]PETSC ERROR: or see https://www.mcs.anl.gov/petsc/documentation/faq.html#valgrind
[7]PETSC ERROR: or try http://valgrind.org on GNU/linux and Apple Mac OS X to find memory corruption errors
[7]PETSC ERROR: configure using --with-debugging=yes, recompile, link, and run 
[7]PETSC ERROR: to get more information on the crash.
[7]PETSC ERROR: [8]PETSC ERROR: ------------------------------------------------------------------------
[8]PETSC ERROR: Caught signal number 15 Terminate: Some process (or the batch system) has told this process to end
[8]PETSC ERROR: Try option -start_in_debugger or -on_error_attach_debugger
[8]PETSC ERROR: or see https://www.mcs.anl.gov/petsc/documentation/faq.html#valgrind
[8]PETSC ERROR: or try http://valgrind.org on GNU/linux and Apple Mac OS X to find memory corruption errors
[8]PETSC ERROR: configure using --with-debugging=yes, recompile, link, and run 
[8]PETSC ERROR: to get more information on the crash.
[8]PETSC ERROR: --------------------- Error Message --------------------------------------------------------------
[8]PETSC ERROR: Signal received
[8]PETSC ERROR: See https://www.mcs.anl.gov/petsc/documentation/faq.html for trouble shooting.
[8]PETSC ERROR: Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500
[8]PETSC ERROR: /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6181 by luciano.siqueira Thu Dec 10 17:27:00 2020
[8]PETSC ERROR: Configure options --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
[8]PETSC ERROR: #1 User provided function() line 0 in  unknown file
[9]PETSC ERROR: ------------------------------------------------------------------------
[9]PETSC ERROR: Caught signal number 15 Terminate: Some process (or the batch system) has told this process to end
[9]PETSC ERROR: Try option -start_in_debugger or -on_error_attach_debugger
[9]PETSC ERROR: or see https://www.mcs.anl.gov/petsc/documentation/faq.html#valgrind
[9]PETSC ERROR: or try http://valgrind.org on GNU/linux and Apple Mac OS X to find memory corruption errors
[9]PETSC ERROR: configure using --with-debugging=yes, recompile, link, and run 
[9]PETSC ERROR: to get more information on the crash.
[9]PETSC ERROR: [10]PETSC ERROR: ------------------------------------------------------------------------
[10]PETSC ERROR: Caught signal number 15 Terminate: Some process (or the batch system) has told this process to end
[11]PETSC ERROR: ------------------------------------------------------------------------
[11]PETSC ERROR: Caught signal number 15 Terminate: Some process (or the batch system) has told this process to end
[11]PETSC ERROR: Try option -start_in_debugger or -on_error_attach_debugger
[11]PETSC ERROR: or see https://www.mcs.anl.gov/petsc/documentation/faq.html#valgrind
[11]PETSC ERROR: or try http://valgrind.org on GNU/linux and Apple Mac OS X to find memory corruption errors
[11]PETSC ERROR: configure using --with-debugging=yes, recompile, link, and run 
[11]PETSC ERROR: to get more information on the crash.
[11]PETSC ERROR: --------------------- Error Message --------------------------------------------------------------
[11]PETSC ERROR: Signal received
[11]PETSC ERROR: See https://www.mcs.anl.gov/petsc/documentation/faq.html for trouble shooting.
[11]PETSC ERROR: Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500
[11]PETSC ERROR: /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6181 by luciano.siqueira Thu Dec 10 17:27:00 2020
[11]PETSC ERROR: Configure options --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
[11]PETSC ERROR: #1 User provided function() line 0 in  unknown file
[12]PETSC ERROR: ------------------------------------------------------------------------
[12]PETSC ERROR: Caught signal number 15 Terminate: Some process (or the batch system) has told this process to end
[12]PETSC ERROR: Try option -start_in_debugger or -on_error_attach_debugger
[12]PETSC ERROR: or see https://www.mcs.anl.gov/petsc/documentation/faq.html#valgrind
[12]PETSC ERROR: [13]PETSC ERROR: ------------------------------------------------------------------------
[13]PETSC ERROR: Caught signal number 15 Terminate: Some process (or the batch system) has told this process to end
[13]PETSC ERROR: Try option -start_in_debugger or -on_error_attach_debugger
[13]PETSC ERROR: or see https://www.mcs.anl.gov/petsc/documentation/faq.html#valgrind
[13]PETSC ERROR: or try http://valgrind.org on GNU/linux and Apple Mac OS X to find memory corruption errors
[13]PETSC ERROR: configure using --with-debugging=yes, recompile, link, and run 
[13]PETSC ERROR: to get more information on the crash.
[13]PETSC ERROR: --------------------- Error Message --------------------------------------------------------------
[13]PETSC ERROR: Signal received
[13]PETSC ERROR: [14]PETSC ERROR: ------------------------------------------------------------------------
[14]PETSC ERROR: Caught signal number 15 Terminate: Some process (or the batch system) has told this process to end
[14]PETSC ERROR: Try option -start_in_debugger or -on_error_attach_debugger
[14]PETSC ERROR: or see https://www.mcs.anl.gov/petsc/documentation/faq.html#valgrind
[14]PETSC ERROR: or try http://valgrind.org on GNU/linux and Apple Mac OS X to find memory corruption errors
[14]PETSC ERROR: configure using --with-debugging=yes, recompile, link, and run 
[14]PETSC ERROR: to get more information on the crash.
[14]PETSC ERROR: --------------------- Error Message --------------------------------------------------------------
[14]PETSC ERROR: Signal received
[14]PETSC ERROR: See https://www.mcs.anl.gov/petsc/documentation/faq.html for trouble shooting.
[14]PETSC ERROR: Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500
[14]PETSC ERROR: /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6181 by luciano.siqueira Thu Dec 10 17:27:00 2020
[14]PETSC ERROR: Configure options --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
[14]PETSC ERROR: #1 User provided function() line 0 in  unknown file
[15]PETSC ERROR: ------------------------------------------------------------------------
[15]PETSC ERROR: Caught signal number 15 Terminate: Some process (or the batch system) has told this process to end
[15]PETSC ERROR: Try option -start_in_debugger or -on_error_attach_debugger
[15]PETSC ERROR: or see https://www.mcs.anl.gov/petsc/documentation/faq.html#valgrind
[15]PETSC ERROR: or try http://valgrind.org on GNU/linux and Apple Mac OS X to find memory corruption errors
[15]PETSC ERROR: configure using --with-debugging=yes, recompile, link, and run 
[16]PETSC ERROR: ------------------------------------------------------------------------
[16]PETSC ERROR: Caught signal number 15 Terminate: Some process (or the batch system) has told this process to end
[16]PETSC ERROR: Try option -start_in_debugger or -on_error_attach_debugger
[16]PETSC ERROR: or see https://www.mcs.anl.gov/petsc/documentation/faq.html#valgrind
[16]PETSC ERROR: or try http://valgrind.org on GNU/linux and Apple Mac OS X to find memory corruption errors
[16]PETSC ERROR: configure using --with-debugging=yes, recompile, link, and run 
[16]PETSC ERROR: to get more information on the crash.
[17]PETSC ERROR: ------------------------------------------------------------------------
[17]PETSC ERROR: Caught signal number 15 Terminate: Some process (or the batch system) has told this process to end
[17]PETSC ERROR: Try option -start_in_debugger or -on_error_attach_debugger
[17]PETSC ERROR: or see https://www.mcs.anl.gov/petsc/documentation/faq.html#valgrind
[17]PETSC ERROR: or try http://valgrind.org on GNU/linux and Apple Mac OS X to find memory corruption errors
[17]PETSC ERROR: configure using --with-debugging=yes, recompile, link, and run 
[17]PETSC ERROR: to get more information on the crash.
[17]PETSC ERROR: --------------------- Error Message --------------------------------------------------------------
[17]PETSC ERROR: Signal received
[17]PETSC ERROR: [18]PETSC ERROR: ------------------------------------------------------------------------
[18]PETSC ERROR: Caught signal number 15 Terminate: Some process (or the batch system) has told this process to end
[18]PETSC ERROR: Try option -start_in_debugger or -on_error_attach_debugger
[18]PETSC ERROR: or see https://www.mcs.anl.gov/petsc/documentation/faq.html#valgrind
[18]PETSC ERROR: or try http://valgrind.org on GNU/linux and Apple Mac OS X to find memory corruption errors
[18]PETSC ERROR: configure using --with-debugging=yes, recompile, link, and run 
[18]PETSC ERROR: to get more information on the crash.
[18]PETSC ERROR: --------------------- Error Message --------------------------------------------------------------
[18]PETSC ERROR: Signal received
[18]PETSC ERROR: See https://www.mcs.anl.gov/petsc/documentation/faq.html for trouble shooting.
[18]PETSC ERROR: Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500
[18]PETSC ERROR: /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6181 by luciano.siqueira Thu Dec 10 17:27:00 2020
