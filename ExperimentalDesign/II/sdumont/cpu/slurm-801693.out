Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type cg -pc_type bjacobi -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 15:27:31 2020            |
| OS:             Linux                               |
| HostName:       sdumont6171                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.86065, Active time=2.89585                                       |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.3986      0.000008    0.3986      0.000008    13.77    13.77    |
| Ke                            50792      1.7743      0.000035    1.7743      0.000035    61.27    61.27    |
| elem init                     50792      0.7229      0.000014    0.7229      0.000014    24.96    24.96    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.8959                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 97.915683
Tempo total: 97.915521
Tempo total: 97.915768
Tempo total: 97.915599
Tempo total: 97.915596
Tempo total: 97.915699
Tempo total: 97.915702
Tempo total: 97.915534
Tempo total: 97.915643
Tempo total: 97.915568
Tempo total: 97.915657
Tempo total: 97.915572
Tempo total: 97.915542
Tempo total: 97.915680
Tempo total: 97.915660
Tempo total: 97.915522
Tempo total: 97.915546
Tempo total: 97.915615
Tempo total: 97.915651
Tempo total: 97.915625
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6171 with 20 processors, by luciano.siqueira Thu Dec 10 15:28:42 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           9.823e+01     1.000   9.822e+01
Objects:              3.300e+01     1.000   3.300e+01
Flop:                 4.587e+10     1.106   4.359e+10  8.719e+11
Flop/sec:             4.669e+08     1.106   4.438e+08  8.877e+09
MPI Messages:         4.552e+03     2.706   3.035e+03  6.071e+04
MPI Message Lengths:  2.654e+08     1.571   7.091e+04  4.305e+09
MPI Reductions:       1.249e+03     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 9.8223e+01 100.0%  8.7189e+11 100.0%  6.071e+04 100.0%  7.091e+04      100.0%  1.242e+03  99.4%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 4.9682e-0139.8 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  0  0  1  0  1   0  0  1  0  1     0
BuildTwoSidedF         5 1.0 4.9534e-0169.3 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  0  0  1  5  0   0  0  1  5  0     0
MatMult              402 1.0 3.2819e+01 1.1 2.15e+10 1.1 5.9e+04 4.6e+04 0.0e+00 33 47 97 63  0  33 47 97 63  0 12491
MatSolve             403 1.0 3.2066e+01 1.1 2.11e+10 1.1 0.0e+00 0.0e+00 0.0e+00 31 46  0  0  0  31 46  0  0  0 12426
MatLUFactorNum         1 1.0 2.4522e+00 1.1 1.27e+09 1.1 0.0e+00 0.0e+00 0.0e+00  2  3  0  0  0   2  3  0  0  0  9867
MatILUFactorSym        1 1.0 1.5495e-01 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatAssemblyBegin       2 1.0 5.6969e-01 6.8 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  0  0  0  5  0   0  0  0  5  0     0
MatAssemblyEnd         2 1.0 3.2464e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  0  0  0  0  0   0  0  0  0  0    13
MatGetRowIJ            1 1.0 3.7290e-06 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatGetOrdering         1 1.0 4.1852e-03 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatZeroEntries         3 1.0 1.2321e-01 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecTDot              802 1.0 2.0878e+00 4.2 6.81e+08 1.1 0.0e+00 0.0e+00 8.0e+02  1  1  0  0 64   1  1  0  0 65  6239
VecNorm              403 1.0 3.6025e+0016.3 3.42e+08 1.1 0.0e+00 0.0e+00 4.0e+02  2  1  0  0 32   2  1  0  0 32  1817
VecCopy                2 1.0 1.5917e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet               408 1.0 1.2997e-01 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY              802 1.0 7.7301e-01 1.3 6.81e+08 1.1 0.0e+00 0.0e+00 0.0e+00  1  1  0  0  0   1  1  0  0  0 16850
VecAYPX              401 1.0 4.3238e-01 1.1 3.40e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 15044
VecAssemblyBegin       3 1.0 9.0484e-03 1.0 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAssemblyEnd         3 1.0 6.4362e-04 5.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecScatterBegin      403 1.0 2.6518e-01 2.2 0.00e+00 0.0 5.9e+04 4.6e+04 0.0e+00  0  0 97 63  0   0  0 97 63  0     0
VecScatterEnd        403 1.0 3.2681e+0063.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
SFSetGraph             2 1.0 4.9704e-04 1.8 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.1236e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  1  0  0   0  0  1  0  0     0
SFBcastOpBegin       403 1.0 2.6438e-01 2.2 0.00e+00 0.0 5.9e+04 4.6e+04 0.0e+00  0  0 97 63  0   0  0 97 63  0     0
SFBcastOpEnd         403 1.0 3.2671e+0064.8 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
SFPack               403 1.0 2.5581e-01 2.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack             403 1.0 3.3079e-04 1.8 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               2 1.0 1.5970e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSolve               1 1.0 6.9413e+01 1.0 4.59e+10 1.1 5.9e+04 4.6e+04 1.2e+03 71100 97 63 96  71100 97 63 97 12558
PCSetUp                2 1.0 2.6190e+00 1.1 1.27e+09 1.1 0.0e+00 0.0e+00 0.0e+00  3  3  0  0  0   3  3  0  0  0  9239
PCSetUpOnBlocks        1 1.0 2.6114e+00 1.1 1.27e+09 1.1 0.0e+00 0.0e+00 0.0e+00  3  3  0  0  0   3  3  0  0  0  9266
PCApply              403 1.0 3.2195e+01 1.1 2.11e+10 1.1 0.0e+00 0.0e+00 0.0e+00 31 46  0  0  0  31 46  0  0  0 12376
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     4              4    666933972     0.
           Index Set     7              7      5403804     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    12             12     24405960     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     2              2         3088     0.
      Preconditioner     2              2         1944     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 2.78e-08
Average time for MPI_Barrier(): 5.0542e-06
Average time for zero size MPI_Send(): 3.4284e-06
#PETSc Option Table entries:
-d 3
-ksp_type cg
-log_view
-mat_type aij
-n 100
-pc_type bjacobi
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type cg -pc_type jacobi -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 15:29:12 2020            |
| OS:             Linux                               |
| HostName:       sdumont6171                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.86376, Active time=2.89981                                       |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.4035      0.000008    0.4035      0.000008    13.92    13.92    |
| Ke                            50792      1.7689      0.000035    1.7689      0.000035    61.00    61.00    |
| elem init                     50792      0.7274      0.000014    0.7274      0.000014    25.09    25.09    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.8998                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 40.335962
Tempo total: 40.357962
Tempo total: 40.382911
Tempo total: 40.381764
Tempo total: 40.380691
Tempo total: 40.356090
Tempo total: 40.369142
Tempo total: 40.357815
Tempo total: 40.378064
Tempo total: 40.352235
Tempo total: 40.326895
Tempo total: 40.347368
Tempo total: 40.335566
Tempo total: 40.360722
Tempo total: 40.329840
Tempo total: 40.345147
Tempo total: 40.370157
Tempo total: 40.345525
Tempo total: 40.370512
Tempo total: 40.349264
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6171 with 20 processors, by luciano.siqueira Thu Dec 10 15:29:25 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           4.074e+01     1.000   4.073e+01
Objects:              2.600e+01     1.000   2.600e+01
Flop:                 8.024e+09     1.100   7.659e+09  1.532e+11
Flop/sec:             1.970e+08     1.100   1.880e+08  3.761e+09
MPI Messages:         1.626e+03     2.630   1.094e+03  2.187e+04
MPI Message Lengths:  1.458e+08     1.348   1.154e+05  2.524e+09
MPI Reductions:       4.530e+02     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 4.0732e+01 100.0%  1.5319e+11 100.0%  2.187e+04 100.0%  1.154e+05      100.0%  4.460e+02  98.5%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 4.3771e-0199.2 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  1  0  2  0  2   1  0  2  0  2     0
BuildTwoSidedF         5 1.0 4.3844e-01118.7 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  1  0  2  8  1   1  0  2  8  1     0
MatMult              136 1.0 1.1092e+01 1.0 7.27e+09 1.1 2.0e+04 4.6e+04 0.0e+00 27 91 91 36  0  27 91 91 36  0 12502
MatAssemblyBegin       2 1.0 5.3448e-01 3.5 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  1  0  1  8  0   1  0  1  8  0     0
MatAssemblyEnd         2 1.0 3.4407e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  1  0  1  0  1   1  0  1  0  1    13
MatZeroEntries         3 1.0 1.2162e-01 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecTDot              270 1.0 6.7340e-01 3.9 2.29e+08 1.1 0.0e+00 0.0e+00 2.7e+02  1  3  0  0 60   1  3  0  0 61  6512
VecNorm              137 1.0 1.3503e-01 1.7 1.16e+08 1.1 0.0e+00 0.0e+00 1.4e+02  0  1  0  0 30   0  1  0  0 31 16478
VecCopy                2 1.0 1.5602e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet                 5 1.0 1.7727e-03 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY              270 1.0 2.4605e-01 1.2 2.29e+08 1.1 0.0e+00 0.0e+00 0.0e+00  1  3  0  0  0   1  3  0  0  0 17822
VecAYPX              135 1.0 1.4625e-01 1.1 1.14e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 14936
VecAssemblyBegin       3 1.0 9.6642e-03 1.0 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  1  0  1   0  0  1  0  1     0
VecAssemblyEnd         3 1.0 6.2824e-04 5.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecPointwiseMult     137 1.0 1.7881e-01 1.1 5.82e+07 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0  6222
VecScatterBegin      137 1.0 8.7565e-02 2.0 0.00e+00 0.0 2.0e+04 4.6e+04 0.0e+00  0  0 91 36  0   0  0 91 36  0     0
VecScatterEnd        137 1.0 1.0534e+0057.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
SFSetGraph             2 1.0 5.1854e-04 1.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.1362e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  3  0  0   0  0  3  0  0     0
SFBcastOpBegin       137 1.0 8.7282e-02 2.0 0.00e+00 0.0 2.0e+04 4.6e+04 0.0e+00  0  0 91 36  0   0  0 91 36  0     0
SFBcastOpEnd         137 1.0 1.0531e+0058.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
SFPack               137 1.0 8.3242e-02 2.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack             137 1.0 9.3470e-05 1.6 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               1 1.0 1.5944e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSolve               1 1.0 1.1982e+01 1.0 8.01e+09 1.1 2.0e+04 4.6e+04 4.1e+02 29100 91 36 90  29100 91 36 92 12767
PCSetUp                1 1.0 8.1500e-07 3.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
PCApply              137 1.0 2.4973e-01 1.1 5.82e+07 1.1 0.0e+00 0.0e+00 2.0e+00  1  1  0  0  0   1  1  0  0  0  4455
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     3              3    344047400     0.
           Index Set     4              4       304416     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    11             11     27802304     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     1              1         1672     0.
      Preconditioner     1              1          968     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 2.98e-08
Average time for MPI_Barrier(): 5.0972e-06
Average time for zero size MPI_Send(): 3.3058e-06
#PETSc Option Table entries:
-d 3
-ksp_type cg
-log_view
-mat_type aij
-n 100
-pc_type jacobi
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type cg -pc_type sor -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 15:29:56 2020            |
| OS:             Linux                               |
| HostName:       sdumont6171                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.80002, Active time=2.87744                                       |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.4007      0.000008    0.4007      0.000008    13.92    13.92    |
| Ke                            50792      1.7608      0.000035    1.7608      0.000035    61.19    61.19    |
| elem init                     50792      0.7159      0.000014    0.7159      0.000014    24.88    24.88    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.8774                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 124.217385
Tempo total: 124.186538
Tempo total: 124.180487
Tempo total: 124.170569
Tempo total: 124.188538
Tempo total: 124.170062
Tempo total: 124.158596
Tempo total: 124.166037
Tempo total: 124.177933
Tempo total: 124.165062
Tempo total: 124.131975
Tempo total: 124.139344
Tempo total: 124.168385
Tempo total: 124.154411
Tempo total: 124.122870
Tempo total: 124.136925
Tempo total: 124.159500
Tempo total: 124.137817
Tempo total: 124.161860
Tempo total: 124.231657
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6171 with 20 processors, by luciano.siqueira Thu Dec 10 15:31:33 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           1.246e+02     1.000   1.246e+02
Objects:              2.500e+01     1.000   2.500e+01
Flop:                 5.110e+10     1.106   4.857e+10  9.715e+11
Flop/sec:             4.103e+08     1.106   3.900e+08  7.800e+09
MPI Messages:         5.178e+03     2.711   3.452e+03  6.903e+04
MPI Message Lengths:  2.910e+08     1.600   6.789e+04  4.686e+09
MPI Reductions:       1.420e+03     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 1.2455e+02 100.0%  9.7148e+11 100.0%  6.903e+04 100.0%  6.789e+04      100.0%  1.413e+03  99.5%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 6.7083e-01105.9 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  0  0  1  0  0   0  0  1  0  0     0
BuildTwoSidedF         5 1.0 6.6958e-01107.7 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  0  0  1  4  0   0  0  1  4  0     0
MatMult              459 1.0 3.7605e+01 1.0 2.45e+10 1.1 6.7e+04 4.6e+04 0.0e+00 30 48 97 66  0  30 48 97 66  0 12446
MatSOR               460 1.0 5.5479e+01 1.1 2.42e+10 1.1 0.0e+00 0.0e+00 0.0e+00 42 47  0  0  0  42 47  0  0  0  8265
MatAssemblyBegin       2 1.0 7.6709e-01 4.1 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  0  0  0  4  0   0  0  0  4  0     0
MatAssemblyEnd         2 1.0 3.2594e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  0  0  0  0  0   0  0  0  0  0    13
MatZeroEntries         3 1.0 1.2169e-01 1.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecTDot              916 1.0 2.2698e+00 3.9 7.78e+08 1.1 0.0e+00 0.0e+00 9.2e+02  1  2  0  0 65   1  2  0  0 65  6554
VecNorm              460 1.0 5.7875e+0022.4 3.91e+08 1.1 0.0e+00 0.0e+00 4.6e+02  3  1  0  0 32   3  1  0  0 33  1291
VecCopy                2 1.0 1.4871e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet                 5 1.0 1.7607e-03 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY              916 1.0 8.1204e-01 1.1 7.78e+08 1.1 0.0e+00 0.0e+00 0.0e+00  1  2  0  0  0   1  2  0  0  0 18321
VecAYPX              458 1.0 4.9518e-01 1.1 3.89e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 15005
VecAssemblyBegin       3 1.0 9.0728e-03 1.0 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAssemblyEnd         3 1.0 6.0523e-04 4.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecScatterBegin      460 1.0 2.9485e-01 2.1 0.00e+00 0.0 6.7e+04 4.6e+04 0.0e+00  0  0 97 66  0   0  0 97 66  0     0
VecScatterEnd        460 1.0 3.5704e+0060.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
SFSetGraph             2 1.0 5.0095e-04 2.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.1126e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  1  0  0   0  0  1  0  0     0
SFBcastOpBegin       460 1.0 2.9378e-01 2.1 0.00e+00 0.0 6.7e+04 4.6e+04 0.0e+00  0  0 97 66  0   0  0 97 66  0     0
SFBcastOpEnd         460 1.0 3.5692e+0061.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
SFPack               460 1.0 2.8355e-01 2.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack             460 1.0 3.7425e-04 1.7 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               1 1.0 1.5771e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSolve               1 1.0 9.5219e+01 1.0 5.11e+10 1.1 6.7e+04 4.6e+04 1.4e+03 76100 97 66 97  76100 97 66 97 10200
PCSetUp                1 1.0 4.3100e-07 2.7 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
PCApply              460 1.0 5.5480e+01 1.1 2.42e+10 1.1 0.0e+00 0.0e+00 0.0e+00 42 47  0  0  0  42 47  0  0  0  8265
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     3              3    354240752     0.
           Index Set     4              4       304416     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    10             10     24402824     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     1              1         1672     0.
      Preconditioner     1              1          968     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 2.95e-08
Average time for MPI_Barrier(): 5.1482e-06
Average time for zero size MPI_Send(): 3.3361e-06
#PETSc Option Table entries:
-d 3
-ksp_type cg
-log_view
-mat_type aij
-n 100
-pc_type sor
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type cg -pc_type mg -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 15:32:03 2020            |
| OS:             Linux                               |
| HostName:       sdumont6171                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.85259, Active time=2.88895                                       |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.4016      0.000008    0.4016      0.000008    13.90    13.90    |
| Ke                            50792      1.7637      0.000035    1.7637      0.000035    61.05    61.05    |
| elem init                     50792      0.7236      0.000014    0.7236      0.000014    25.05    25.05    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.8889                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 134.000578
Tempo total: 134.007460
Tempo total: 134.044364
Tempo total: 134.012693
Tempo total: 133.981745
Tempo total: 133.971840
Tempo total: 133.931097
Tempo total: 133.953270
Tempo total: 133.937124
Tempo total: 133.935682
Tempo total: 133.970508
Tempo total: 133.950158
Tempo total: 133.914083
Tempo total: 133.934371
Tempo total: 133.979906
Tempo total: 133.947494
Tempo total: 133.949101
Tempo total: 133.932828
Tempo total: 133.945776
Tempo total: 134.058757
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6171 with 20 processors, by luciano.siqueira Thu Dec 10 15:33:50 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           1.344e+02     1.000   1.344e+02
Objects:              5.000e+01     1.000   5.000e+01
Flop:                 5.658e+10     1.106   5.378e+10  1.076e+12
Flop/sec:             4.211e+08     1.106   4.002e+08  8.005e+09
MPI Messages:         5.750e+03     2.715   3.831e+03  7.662e+04
MPI Message Lengths:  3.144e+08     1.622   6.570e+04  5.034e+09
MPI Reductions:       8.160e+02     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 1.3436e+02 100.0%  1.0755e+12 100.0%  7.662e+04 100.0%  6.570e+04      100.0%  8.090e+02  99.1%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 4.6744e-0194.5 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  0  0  1  0  1   0  0  1  0  1     0
BuildTwoSidedF         5 1.0 4.6748e-01122.5 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  0  0  0  4  1   0  0  0  4  1     0
MatMult              511 1.0 4.4699e+01 1.1 2.73e+10 1.1 7.5e+04 4.6e+04 0.0e+00 31 48 97 68  0  31 48 97 68  0 11658
MatSOR               513 1.0 6.1711e+01 1.1 2.70e+10 1.1 0.0e+00 0.0e+00 0.0e+00 43 48  0  0  0  43 48  0  0  0  8287
MatAssemblyBegin       2 1.0 5.8445e-01 3.0 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  0  0  0  4  0   0  0  0  4  0     0
MatAssemblyEnd         2 1.0 3.4208e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  0  0  0  0  1   0  0  0  0  1    13
MatZeroEntries         3 1.0 1.2243e-01 1.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecMDot               10 1.0 1.5190e-01 7.0 4.67e+07 1.1 0.0e+00 0.0e+00 1.0e+01  0  0  0  0  1   0  0  0  0  1  5881
VecTDot              498 1.0 1.2484e+00 4.0 4.23e+08 1.1 0.0e+00 0.0e+00 5.0e+02  1  1  0  0 61   1  1  0  0 62  6479
VecNorm              262 1.0 4.4617e+0029.9 2.23e+08 1.1 0.0e+00 0.0e+00 2.6e+02  2  0  0  0 32   2  0  0  0 32   954
VecScale              11 1.0 3.4800e-03 1.3 4.67e+06 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 25669
VecCopy              505 1.0 3.6594e-01 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet               509 1.0 1.5339e-01 1.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY              499 1.0 4.4560e-01 1.2 4.24e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 18187
VecAYPX              751 1.0 8.3005e-01 1.1 5.31e+08 1.1 0.0e+00 0.0e+00 0.0e+00  1  1  0  0  0   1  1  0  0  0 12229
VecAXPBYCZ           251 1.0 3.4483e-01 1.1 5.33e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 29554
VecMAXPY              11 1.0 3.6037e-02 1.1 5.52e+07 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 29294
VecAssemblyBegin       3 1.0 9.6259e-03 1.0 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAssemblyEnd         3 1.0 6.0612e-04 4.8 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecScatterBegin      512 1.0 3.2576e-01 2.0 0.00e+00 0.0 7.5e+04 4.6e+04 0.0e+00  0  0 98 68  0   0  0 98 68  0     0
VecScatterEnd        512 1.0 7.3795e+0076.6 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  2  0  0  0  0   2  0  0  0  0     0
VecNormalize          11 1.0 3.0946e-02 3.1 1.40e+07 1.1 0.0e+00 0.0e+00 1.1e+01  0  0  0  0  1   0  0  0  0  1  8660
SFSetGraph             2 1.0 5.1575e-04 2.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.1371e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  1  0  0   0  0  1  0  0     0
SFBcastOpBegin       512 1.0 3.2463e-01 2.0 0.00e+00 0.0 7.5e+04 4.6e+04 0.0e+00  0  0 98 68  0   0  0 98 68  0     0
SFBcastOpEnd         512 1.0 7.3784e+0077.5 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  2  0  0  0  0   2  0  0  0  0     0
SFPack               512 1.0 3.1247e-01 2.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack             512 1.0 4.1188e-04 1.7 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               2 1.0 2.3169e+00 1.0 1.23e+09 1.1 1.5e+03 4.6e+04 2.3e+01  2  2  2  1  3   2  2  2  1  3 10101
KSPSolve               1 1.0 1.0573e+02 1.0 5.66e+10 1.1 7.5e+04 4.6e+04 7.7e+02 79100 97 68 95  79100 97 68 95 10171
KSPGMRESOrthog        10 1.0 1.8019e-01 3.5 9.34e+07 1.1 0.0e+00 0.0e+00 1.0e+01  0  0  0  0  1   0  0  0  0  1  9915
PCSetUp                1 1.0 2.3157e+00 1.0 1.23e+09 1.1 1.5e+03 4.6e+04 2.3e+01  2  2  2  1  3   2  2  2  1  3 10107
PCApply              262 1.0 8.3228e+01 1.1 4.13e+10 1.1 3.7e+04 4.6e+04 0.0e+00 60 73 48 33  0  60 73 48 33  0  9416
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     3              3    354240752     0.
           Index Set     4              4       304416     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    29             29     88992944     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     4              4        35216     0.
      Preconditioner     4              4         4256     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 2.92e-08
Average time for MPI_Barrier(): 4.993e-06
Average time for zero size MPI_Send(): 3.4233e-06
#PETSc Option Table entries:
-d 3
-ksp_type cg
-log_view
-mat_type aij
-n 100
-pc_type mg
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type gmres -pc_type bjacobi -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 15:34:21 2020            |
| OS:             Linux                               |
| HostName:       sdumont6171                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.84296, Active time=2.88074                                       |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.3983      0.000008    0.3983      0.000008    13.82    13.82    |
| Ke                            50792      1.7523      0.000034    1.7523      0.000034    60.83    60.83    |
| elem init                     50792      0.7302      0.000014    0.7302      0.000014    25.35    25.35    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.8807                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 166.002432
Tempo total: 165.991479
Tempo total: 165.926111
Tempo total: 165.956467
Tempo total: 165.931063
Tempo total: 165.962619
Tempo total: 165.967697
Tempo total: 165.938262
Tempo total: 165.921257
Tempo total: 165.923594
Tempo total: 165.961092
Tempo total: 165.931967
Tempo total: 165.944594
Tempo total: 165.927350
Tempo total: 165.902039
Tempo total: 165.926511
Tempo total: 165.948118
Tempo total: 165.924281
Tempo total: 165.912121
Tempo total: 165.987757
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6171 with 20 processors, by luciano.siqueira Thu Dec 10 15:36:39 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           1.664e+02     1.000   1.663e+02
Objects:              6.400e+01     1.000   6.400e+01
Flop:                 1.036e+11     1.104   9.855e+10  1.971e+12
Flop/sec:             6.227e+08     1.104   5.924e+08  1.185e+10
MPI Messages:         8.578e+03     2.726   5.707e+03  1.141e+05
MPI Message Lengths:  4.300e+08     1.703   5.918e+04  6.755e+09
MPI Reductions:       1.556e+03     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 1.6635e+02 100.0%  1.9710e+12 100.0%  1.141e+05 100.0%  5.918e+04      100.0%  1.549e+03  99.6%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 4.4037e-0182.8 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  0  0  0  0  0   0  0  0  0  0     0
BuildTwoSidedF         5 1.0 4.3923e-0196.4 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  0  0  0  3  0   0  0  0  3  0     0
MatMult              768 1.0 6.2611e+01 1.1 4.10e+10 1.1 1.1e+05 4.6e+04 0.0e+00 37 40 98 76  0  37 40 98 76  0 12508
MatSolve             769 1.0 6.1196e+01 1.1 4.02e+10 1.1 0.0e+00 0.0e+00 0.0e+00 35 39  0  0  0  35 39  0  0  0 12424
MatLUFactorNum         1 1.0 2.4500e+00 1.1 1.27e+09 1.1 0.0e+00 0.0e+00 0.0e+00  1  1  0  0  0   1  1  0  0  0  9876
MatILUFactorSym        1 1.0 1.5213e-01 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatAssemblyBegin       2 1.0 5.1396e-01 3.3 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  0  0  0  3  0   0  0  0  3  0     0
MatAssemblyEnd         2 1.0 3.4313e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  0  0  0  0  0   0  0  0  0  0    13
MatGetRowIJ            1 1.0 3.7930e-06 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatGetOrdering         1 1.0 4.1492e-03 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatZeroEntries         3 1.0 1.2378e-01 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecMDot              743 1.0 1.1468e+01 2.6 9.71e+09 1.1 0.0e+00 0.0e+00 7.4e+02  5  9  0  0 48   5  9  0  0 48 16196
VecNorm              769 1.0 1.2073e+00 2.5 6.53e+08 1.1 0.0e+00 0.0e+00 7.7e+02  0  1  0  0 49   0  1  0  0 50 10345
VecScale             768 1.0 1.9964e-01 1.1 3.26e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 31239
VecCopy               26 1.0 1.8289e-02 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet               799 1.0 3.7364e-01 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY               50 1.0 3.1689e-02 1.2 4.25e+07 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 25626
VecMAXPY             768 1.0 6.2202e+00 1.1 1.03e+10 1.1 0.0e+00 0.0e+00 0.0e+00  4 10  0  0  0   4 10  0  0  0 31800
VecAssemblyBegin       3 1.0 1.0724e-02 1.1 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAssemblyEnd         3 1.0 6.0799e-04 4.8 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecScatterBegin      769 1.0 3.5763e-01 2.6 0.00e+00 0.0 1.1e+05 4.6e+04 0.0e+00  0  0 98 76  0   0  0 98 76  0     0
VecScatterEnd        769 1.0 6.1246e+0059.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  2  0  0  0  0   2  0  0  0  0     0
VecNormalize         768 1.0 1.3962e+00 2.1 9.79e+08 1.1 0.0e+00 0.0e+00 7.7e+02  1  1  0  0 49   1  1  0  0 50 13400
SFSetGraph             2 1.0 5.1396e-04 1.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.1499e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  1  0  0   0  0  1  0  0     0
SFBcastOpBegin       769 1.0 3.5633e-01 2.6 0.00e+00 0.0 1.1e+05 4.6e+04 0.0e+00  0  0 98 76  0   0  0 98 76  0     0
SFBcastOpEnd         769 1.0 6.1227e+0060.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  2  0  0  0  0   2  0  0  0  0     0
SFPack               769 1.0 3.4249e-01 2.7 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack             769 1.0 5.4450e-04 1.6 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               2 1.0 2.6656e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSolve               1 1.0 1.3686e+02 1.0 1.04e+11 1.1 1.1e+05 4.6e+04 1.5e+03 82100 98 76 97  82100 98 76 98 14400
KSPGMRESOrthog       743 1.0 1.6834e+01 1.7 1.94e+10 1.1 0.0e+00 0.0e+00 7.4e+02  8 19  0  0 48   8 19  0  0 48 22066
PCSetUp                2 1.0 2.6139e+00 1.1 1.27e+09 1.1 0.0e+00 0.0e+00 0.0e+00  1  1  0  0  0   1  1  0  0  0  9257
PCSetUpOnBlocks        1 1.0 2.6064e+00 1.1 1.27e+09 1.1 0.0e+00 0.0e+00 0.0e+00  1  1  0  0  0   1  1  0  0  0  9284
PCApply              769 1.0 6.1565e+01 1.1 4.02e+10 1.1 0.0e+00 0.0e+00 0.0e+00 35 39  0  0  0  35 39  0  0  0 12350
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     4              4    666933972     0.
           Index Set     7              7      5403804     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    43             43    129789840     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     2              2        20072     0.
      Preconditioner     2              2         1944     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 2.79e-08
Average time for MPI_Barrier(): 5.1058e-06
Average time for zero size MPI_Send(): 3.32085e-06
#PETSc Option Table entries:
-d 3
-ksp_type gmres
-log_view
-mat_type aij
-n 100
-pc_type bjacobi
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type gmres -pc_type jacobi -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 15:37:10 2020            |
| OS:             Linux                               |
| HostName:       sdumont6171                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.83721, Active time=2.87816                                       |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.3972      0.000008    0.3972      0.000008    13.80    13.80    |
| Ke                            50792      1.7576      0.000035    1.7576      0.000035    61.07    61.07    |
| elem init                     50792      0.7233      0.000014    0.7233      0.000014    25.13    25.13    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.8782                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 194.448438
Tempo total: 194.433036
Tempo total: 194.454740
Tempo total: 194.423734
Tempo total: 194.451674
Tempo total: 194.446226
Tempo total: 194.462809
Tempo total: 194.414592
Tempo total: 194.444512
Tempo total: 194.429387
Tempo total: 194.399345
Tempo total: 194.446442
Tempo total: 194.442016
Tempo total: 194.412312
Tempo total: 194.414389
Tempo total: 194.411197
Tempo total: 194.438893
Tempo total: 194.412085
Tempo total: 194.395858
Tempo total: 194.454519
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6171 with 20 processors, by luciano.siqueira Thu Dec 10 15:39:56 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           1.948e+02     1.000   1.948e+02
Objects:              5.700e+01     1.000   5.700e+01
Flop:                 1.366e+11     1.098   1.304e+11  2.609e+12
Flop/sec:             7.011e+08     1.098   6.695e+08  1.339e+10
MPI Messages:         1.858e+04     2.739   1.234e+04  2.469e+05
MPI Message Lengths:  8.389e+08     1.823   5.201e+04  1.284e+10
MPI Reductions:       3.346e+03     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 1.9481e+02 100.0%  2.6086e+12 100.0%  2.469e+05 100.0%  5.201e+04      100.0%  3.339e+03  99.8%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 4.4707e-0187.0 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  0  0  0  0  0   0  0  0  0  0     0
BuildTwoSidedF         5 1.0 4.4695e-01109.1 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  0  0  0  2  0   0  0  0  2  0     0
MatMult             1677 1.0 1.3682e+02 1.1 8.96e+10 1.1 2.4e+05 4.6e+04 0.0e+00 69 66 99 87  0  69 66 99 87  0 12499
MatAssemblyBegin       2 1.0 5.4132e-01 3.7 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  0  0  0  2  0   0  0  0  2  0     0
MatAssemblyEnd         2 1.0 3.4174e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  0  0  0  0  0   0  0  0  0  0    13
MatZeroEntries         3 1.0 1.2203e-01 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecMDot             1622 1.0 1.6946e+01 1.7 2.13e+10 1.1 0.0e+00 0.0e+00 1.6e+03  7 16  0  0 48   7 16  0  0 49 24069
VecNorm             1678 1.0 2.1574e+00 2.0 1.43e+09 1.1 0.0e+00 0.0e+00 1.7e+03  1  1  0  0 50   1  1  0  0 50 12632
VecScale            1677 1.0 6.0970e-01 1.1 7.12e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 22336
VecCopy               56 1.0 3.9001e-02 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet                60 1.0 3.0860e-02 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY              110 1.0 6.7166e-02 1.2 9.34e+07 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 26599
VecMAXPY            1677 1.0 1.4030e+01 1.1 2.27e+10 1.1 0.0e+00 0.0e+00 0.0e+00  7 17  0  0  0   7 17  0  0  0 30950
VecAssemblyBegin       3 1.0 9.9208e-03 1.0 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAssemblyEnd         3 1.0 6.2243e-04 4.6 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecPointwiseMult    1678 1.0 2.1815e+00 1.2 7.13e+08 1.1 0.0e+00 0.0e+00 0.0e+00  1  1  0  0  0   1  1  0  0  0  6246
VecScatterBegin     1678 1.0 9.0234e-01 2.5 0.00e+00 0.0 2.4e+05 4.6e+04 0.0e+00  0  0 99 88  0   0  0 99 88  0     0
VecScatterEnd       1678 1.0 1.2813e+0158.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  3  0  0  0  0   3  0  0  0  0     0
VecNormalize        1677 1.0 2.7414e+00 1.7 2.14e+09 1.1 0.0e+00 0.0e+00 1.7e+03  1  2  0  0 50   1  2  0  0 50 14903
SFSetGraph             2 1.0 5.2849e-04 2.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.1600e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFBcastOpBegin      1678 1.0 8.9909e-01 2.5 0.00e+00 0.0 2.4e+05 4.6e+04 0.0e+00  0  0 99 88  0   0  0 99 88  0     0
SFBcastOpEnd        1678 1.0 1.2809e+0159.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  3  0  0  0  0   3  0  0  0  0     0
SFPack              1678 1.0 8.6911e-01 2.5 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack            1678 1.0 1.3700e-03 2.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               1 1.0 2.6177e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSolve               1 1.0 1.6513e+02 1.0 1.37e+11 1.1 2.4e+05 4.6e+04 3.3e+03 85100 99 87 99  85100 99 87 99 15796
KSPGMRESOrthog      1622 1.0 2.9948e+01 1.3 4.27e+10 1.1 0.0e+00 0.0e+00 1.6e+03 13 31  0  0 48  13 31  0  0 49 27238
PCSetUp                1 1.0 7.7400e-07 5.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
PCApply             1678 1.0 2.2570e+00 1.2 7.13e+08 1.1 0.0e+00 0.0e+00 2.0e+00  1  1  0  0  0   1  1  0  0  0  6037
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     3              3    344047400     0.
           Index Set     4              4       304416     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    42             42    133186184     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     1              1        18656     0.
      Preconditioner     1              1          968     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 2.94e-08
Average time for MPI_Barrier(): 4.932e-06
Average time for zero size MPI_Send(): 3.26875e-06
#PETSc Option Table entries:
-d 3
-ksp_type gmres
-log_view
-mat_type aij
-n 100
-pc_type jacobi
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type gmres -pc_type sor -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 15:40:27 2020            |
| OS:             Linux                               |
| HostName:       sdumont6171                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.80104, Active time=2.87065                                       |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.3979      0.000008    0.3979      0.000008    13.86    13.86    |
| Ke                            50792      1.7522      0.000034    1.7522      0.000034    61.04    61.04    |
| elem init                     50792      0.7206      0.000014    0.7206      0.000014    25.10    25.10    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.8707                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 249.855859
Tempo total: 249.841785
Tempo total: 249.862978
Tempo total: 249.792445
Tempo total: 249.769401
Tempo total: 249.808067
Tempo total: 249.810416
Tempo total: 249.778227
Tempo total: 249.756309
Tempo total: 249.778210
Tempo total: 249.797751
Tempo total: 249.770024
Tempo total: 249.791547
Tempo total: 249.774534
Tempo total: 249.752689
Tempo total: 249.771669
Tempo total: 249.756893
Tempo total: 249.770117
Tempo total: 249.790925
Tempo total: 249.890005
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6171 with 20 processors, by luciano.siqueira Thu Dec 10 15:44:09 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           2.502e+02     1.000   2.502e+02
Objects:              5.600e+01     1.000   5.600e+01
Flop:                 1.363e+11     1.104   1.296e+11  2.593e+12
Flop/sec:             5.446e+08     1.104   5.182e+08  1.036e+10
MPI Messages:         1.134e+04     2.732   7.540e+03  1.508e+05
MPI Message Lengths:  5.429e+08     1.752   5.594e+04  8.435e+09
MPI Reductions:       2.050e+03     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 2.5018e+02 100.0%  2.5928e+12 100.0%  1.508e+05 100.0%  5.594e+04      100.0%  2.043e+03  99.7%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 4.4929e-0180.6 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  0  0  0  0  0   0  0  0  0  0     0
BuildTwoSidedF         5 1.0 4.4859e-0189.6 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  0  0  0  2  0   0  0  0  2  0     0
MatMult             1019 1.0 8.3274e+01 1.0 5.44e+10 1.1 1.5e+05 4.6e+04 0.0e+00 33 40 99 81  0  33 40 99 81  0 12478
MatSOR              1020 1.0 1.2417e+02 1.1 5.37e+10 1.1 0.0e+00 0.0e+00 0.0e+00 47 39  0  0  0  47 39  0  0  0  8188
MatAssemblyBegin       2 1.0 5.5112e-01 3.0 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  0  0  0  2  0   0  0  0  2  0     0
MatAssemblyEnd         2 1.0 3.4276e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  0  0  0  0  0   0  0  0  0  0    13
MatZeroEntries         3 1.0 1.2235e-01 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecMDot              986 1.0 1.9852e+01 3.5 1.29e+10 1.1 0.0e+00 0.0e+00 9.9e+02  5 10  0  0 48   5 10  0  0 48 12461
VecNorm             1020 1.0 1.8152e+00 2.4 8.66e+08 1.1 0.0e+00 0.0e+00 1.0e+03  0  1  0  0 50   0  1  0  0 50  9126
VecScale            1019 1.0 3.0202e-01 1.2 4.33e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 27399
VecCopy               34 1.0 2.3644e-02 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet                38 1.0 1.9248e-02 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY               66 1.0 3.9628e-02 1.2 5.61e+07 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 27050
VecMAXPY            1019 1.0 8.4135e+00 1.1 1.38e+10 1.1 0.0e+00 0.0e+00 0.0e+00  3 10  0  0  0   3 10  0  0  0 31305
VecAssemblyBegin       3 1.0 1.0962e-02 1.1 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAssemblyEnd         3 1.0 5.7171e-04 4.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecScatterBegin     1020 1.0 5.0851e-01 2.7 0.00e+00 0.0 1.5e+05 4.6e+04 0.0e+00  0  0 99 81  0   0  0 99 81  0     0
VecScatterEnd       1020 1.0 8.0111e+0055.5 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
VecNormalize        1019 1.0 2.0664e+00 2.0 1.30e+09 1.1 0.0e+00 0.0e+00 1.0e+03  1  1  0  0 50   1  1  0  0 50 12014
SFSetGraph             2 1.0 5.1321e-04 1.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.1532e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFBcastOpBegin      1020 1.0 5.0687e-01 2.8 0.00e+00 0.0 1.5e+05 4.6e+04 0.0e+00  0  0 99 81  0   0  0 99 81  0     0
SFBcastOpEnd        1020 1.0 8.0089e+0056.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
SFPack              1020 1.0 4.8698e-01 2.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack            1020 1.0 8.3760e-04 1.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               1 1.0 2.6512e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSolve               1 1.0 2.2083e+02 1.0 1.36e+11 1.1 1.5e+05 4.6e+04 2.0e+03 88100 99 81 98  88100 99 81 98 11740
KSPGMRESOrthog       986 1.0 2.7029e+01 2.0 2.59e+10 1.1 0.0e+00 0.0e+00 9.9e+02  8 19  0  0 48   8 19  0  0 48 18304
PCSetUp                1 1.0 3.9400e-07 2.5 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
PCApply             1020 1.0 1.2418e+02 1.1 5.37e+10 1.1 0.0e+00 0.0e+00 0.0e+00 47 39  0  0  0  47 39  0  0  0  8188
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     3              3    354240752     0.
           Index Set     4              4       304416     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    41             41    129786704     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     1              1        18656     0.
      Preconditioner     1              1          968     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 2.83e-08
Average time for MPI_Barrier(): 5.244e-06
Average time for zero size MPI_Send(): 4.28535e-06
#PETSc Option Table entries:
-d 3
-ksp_type gmres
-log_view
-mat_type aij
-n 100
-pc_type sor
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type gmres -pc_type mg -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 15:44:39 2020            |
| OS:             Linux                               |
| HostName:       sdumont6171                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.81823, Active time=2.85843                                       |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.3954      0.000008    0.3954      0.000008    13.83    13.83    |
| Ke                            50792      1.7414      0.000034    1.7414      0.000034    60.92    60.92    |
| elem init                     50792      0.7216      0.000014    0.7216      0.000014    25.25    25.25    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.8584                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 187.643650
Tempo total: 187.625163
Tempo total: 187.645967
Tempo total: 187.637804
Tempo total: 187.656426
Tempo total: 187.609107
Tempo total: 187.626022
Tempo total: 187.605711
Tempo total: 187.581509
Tempo total: 187.613555
Tempo total: 187.592986
Tempo total: 187.598702
Tempo total: 187.618166
Tempo total: 187.601370
Tempo total: 187.581458
Tempo total: 187.590779
Tempo total: 187.584590
Tempo total: 187.591394
Tempo total: 187.610417
Tempo total: 187.637258
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6171 with 20 processors, by luciano.siqueira Thu Dec 10 15:47:20 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           1.880e+02     1.000   1.880e+02
Objects:              8.100e+01     1.000   8.100e+01
Flop:                 9.162e+10     1.105   8.713e+10  1.743e+12
Flop/sec:             4.873e+08     1.105   4.635e+08  9.269e+09
MPI Messages:         8.412e+03     2.726   5.598e+03  1.120e+05
MPI Message Lengths:  4.233e+08     1.699   5.944e+04  6.654e+09
MPI Reductions:       7.980e+02     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 1.8800e+02 100.0%  1.7426e+12 100.0%  1.120e+05 100.0%  5.944e+04      100.0%  7.910e+02  99.1%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 4.6693e-0198.0 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  0  0  0  0  1   0  0  0  0  1     0
BuildTwoSidedF         5 1.0 4.6675e-01108.3 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  0  0  0  3  1   0  0  0  3  1     0
MatMult              753 1.0 6.5771e+01 1.1 4.02e+10 1.1 1.1e+05 4.6e+04 0.0e+00 33 44 98 76  0  33 44 98 76  0 11675
MatSOR               755 1.0 9.1099e+01 1.1 3.98e+10 1.1 0.0e+00 0.0e+00 0.0e+00 46 43  0  0  0  46 43  0  0  0  8262
MatAssemblyBegin       2 1.0 5.4691e-01 3.3 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  0  0  0  3  0   0  0  0  3  0     0
MatAssemblyEnd         2 1.0 3.2584e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  0  0  0  0  1   0  0  0  0  1    13
MatZeroEntries         3 1.0 1.2231e-01 1.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecMDot              369 1.0 8.7623e+00 4.4 4.76e+09 1.1 0.0e+00 0.0e+00 3.7e+02  3  5  0  0 46   3  5  0  0 47 10389
VecNorm              383 1.0 6.4995e-01 2.4 3.25e+08 1.1 0.0e+00 0.0e+00 3.8e+02  0  0  0  0 48   0  0  0  0 48  9570
VecScale             382 1.0 1.0662e-01 1.4 1.62e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 29094
VecCopy              758 1.0 5.1408e-01 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet               763 1.0 2.3806e-01 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY               25 1.0 1.6560e-02 1.3 2.12e+07 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 24518
VecAYPX              744 1.0 8.4019e-01 1.1 4.74e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 10786
VecAXPBYCZ           372 1.0 5.0395e-01 1.1 7.90e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 29972
VecMAXPY             382 1.0 3.0618e+00 1.1 5.07e+09 1.1 0.0e+00 0.0e+00 0.0e+00  2  6  0  0  0   2  6  0  0  0 31689
VecAssemblyBegin       3 1.0 1.0609e-02 1.2 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAssemblyEnd         3 1.0 5.9097e-04 3.8 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecScatterBegin      754 1.0 4.2524e-01 2.3 0.00e+00 0.0 1.1e+05 4.6e+04 0.0e+00  0  0 98 76  0   0  0 98 76  0     0
VecScatterEnd        754 1.0 1.0623e+0170.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  2  0  0  0  0   2  0  0  0  0     0
VecNormalize         382 1.0 7.4642e-01 2.2 4.87e+08 1.1 0.0e+00 0.0e+00 3.8e+02  0  1  0  0 48   0  1  0  0 48 12468
SFSetGraph             2 1.0 5.0058e-04 1.8 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.1086e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  1  0  0   0  0  1  0  0     0
SFBcastOpBegin       754 1.0 4.2387e-01 2.3 0.00e+00 0.0 1.1e+05 4.6e+04 0.0e+00  0  0 98 76  0   0  0 98 76  0     0
SFBcastOpEnd         754 1.0 1.0621e+0171.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  2  0  0  0  0   2  0  0  0  0     0
SFPack               754 1.0 4.0788e-01 2.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack             754 1.0 4.8897e-04 1.5 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               2 1.0 2.3187e+00 1.0 1.23e+09 1.1 1.5e+03 4.6e+04 2.3e+01  1  1  1  1  3   1  1  1  1  3 10093
KSPSolve               1 1.0 1.5908e+02 1.0 9.16e+10 1.1 1.1e+05 4.6e+04 7.5e+02 85100 98 76 94  85100 98 76 95 10953
KSPGMRESOrthog       369 1.0 1.1418e+01 2.4 9.52e+09 1.1 0.0e+00 0.0e+00 3.7e+02  4 10  0  0 46   4 10  0  0 47 15945
PCSetUp                1 1.0 2.3164e+00 1.0 1.23e+09 1.1 1.5e+03 4.6e+04 2.3e+01  1  1  1  1  3   1  1  1  1  3 10103
PCApply              383 1.0 1.2302e+02 1.1 6.09e+10 1.1 5.4e+04 4.6e+04 0.0e+00 64 66 49 37  0  64 66 49 37  0  9398
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     3              3    354240752     0.
           Index Set     4              4       304416     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    60             60    194376824     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     4              4        52200     0.
      Preconditioner     4              4         4256     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 3.18e-08
Average time for MPI_Barrier(): 5.0388e-06
Average time for zero size MPI_Send(): 3.58445e-06
#PETSc Option Table entries:
-d 3
-ksp_type gmres
-log_view
-mat_type aij
-n 100
-pc_type mg
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type fcg -pc_type bjacobi -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 15:47:50 2020            |
| OS:             Linux                               |
| HostName:       sdumont6171                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.82855, Active time=2.88341                                       |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.3992      0.000008    0.3992      0.000008    13.84    13.84    |
| Ke                            50792      1.7611      0.000035    1.7611      0.000035    61.08    61.08    |
| elem init                     50792      0.7231      0.000014    0.7231      0.000014    25.08    25.08    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.8834                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 104.962922
Tempo total: 104.986848
Tempo total: 105.007474
Tempo total: 104.986989
Tempo total: 104.977523
Tempo total: 104.948125
Tempo total: 104.928796
Tempo total: 104.947887
Tempo total: 104.974006
Tempo total: 104.936963
Tempo total: 104.955377
Tempo total: 104.934947
Tempo total: 104.938883
Tempo total: 104.938408
Tempo total: 104.950160
Tempo total: 104.928783
Tempo total: 104.913062
Tempo total: 104.933516
Tempo total: 104.951739
Tempo total: 105.062939
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6171 with 20 processors, by luciano.siqueira Thu Dec 10 15:49:08 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           1.054e+02     1.000   1.054e+02
Objects:              9.400e+01     1.000   9.400e+01
Flop:                 5.619e+10     1.104   5.346e+10  1.069e+12
Flop/sec:             5.332e+08     1.104   5.074e+08  1.015e+10
MPI Messages:         4.562e+03     2.706   3.043e+03  6.086e+04
MPI Message Lengths:  2.659e+08     1.572   7.085e+04  4.311e+09
MPI Reductions:       1.653e+03     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 1.0537e+02 100.0%  1.0692e+12 100.0%  6.086e+04 100.0%  7.085e+04      100.0%  1.646e+03  99.6%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 4.7288e-0140.9 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  0  0  1  0  0   0  0  1  0  0     0
BuildTwoSidedF         5 1.0 4.7118e-0173.5 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  0  0  1  5  0   0  0  1  5  0     0
MatMult              403 1.0 3.2995e+01 1.1 2.15e+10 1.1 5.9e+04 4.6e+04 0.0e+00 31 38 97 63  0  31 38 97 63  0 12455
MatSolve             404 1.0 3.2239e+01 1.1 2.11e+10 1.1 0.0e+00 0.0e+00 0.0e+00 29 37  0  0  0  29 37  0  0  0 12390
MatLUFactorNum         1 1.0 2.4549e+00 1.1 1.27e+09 1.1 0.0e+00 0.0e+00 0.0e+00  2  2  0  0  0   2  2  0  0  0  9857
MatILUFactorSym        1 1.0 1.5052e-01 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatAssemblyBegin       2 1.0 5.5318e-01 4.0 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  0  0  0  5  0   0  0  0  5  0     0
MatAssemblyEnd         2 1.0 3.4304e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  0  0  0  0  0   0  0  0  0  0    13
MatGetRowIJ            1 1.0 4.0680e-06 1.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatGetOrdering         1 1.0 4.1546e-03 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatZeroEntries         3 1.0 1.2253e-01 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecTDot              804 1.0 2.2882e+00 4.2 6.83e+08 1.1 0.0e+00 0.0e+00 8.0e+02  1  1  0  0 49   1  1  0  0 49  5707
VecMTDot             401 1.0 2.5463e+00 1.0 5.19e+09 1.1 0.0e+00 0.0e+00 4.0e+02  2  9  0  0 24   2  9  0  0 24 38978
VecNorm              404 1.0 3.7826e+0017.0 3.43e+08 1.1 0.0e+00 0.0e+00 4.0e+02  2  1  0  0 24   2  1  0  0 25  1735
VecScale             401 1.0 2.5039e-01 1.1 1.70e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 13005
VecCopy              403 1.0 2.7131e-01 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet               409 1.0 2.0365e-01 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY              804 1.0 7.2029e-01 1.1 6.83e+08 1.1 0.0e+00 0.0e+00 0.0e+00  1  1  0  0  0   1  1  0  0  0 18129
VecAYPX                1 1.0 1.1314e-03 1.1 4.25e+05 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0  7177
VecMAXPY             401 1.0 3.4169e+00 1.1 5.19e+09 1.1 0.0e+00 0.0e+00 0.0e+00  3  9  0  0  0   3  9  0  0  0 29047
VecAssemblyBegin       3 1.0 9.6760e-03 1.0 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAssemblyEnd         3 1.0 6.0420e-04 4.6 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecScatterBegin      404 1.0 2.6319e-01 2.1 0.00e+00 0.0 5.9e+04 4.6e+04 0.0e+00  0  0 97 63  0   0  0 97 63  0     0
VecScatterEnd        404 1.0 3.3211e+0063.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
SFSetGraph             2 1.0 5.1522e-04 1.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.1457e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  1  0  0   0  0  1  0  0     0
SFBcastOpBegin       404 1.0 2.6243e-01 2.1 0.00e+00 0.0 5.9e+04 4.6e+04 0.0e+00  0  0 97 63  0   0  0 97 63  0     0
SFBcastOpEnd         404 1.0 3.3202e+0064.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
SFPack               404 1.0 2.5541e-01 2.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack             404 1.0 2.4212e-04 1.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               2 1.0 1.5164e-02 1.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSolve               1 1.0 7.5955e+01 1.0 5.62e+10 1.1 5.9e+04 4.6e+04 1.6e+03 72100 97 63 97  72100 97 63 98 14074
PCSetUp                2 1.0 2.6164e+00 1.1 1.27e+09 1.1 0.0e+00 0.0e+00 0.0e+00  2  2  0  0  0   2  2  0  0  0  9248
PCSetUpOnBlocks        1 1.0 2.6096e+00 1.1 1.27e+09 1.1 0.0e+00 0.0e+00 0.0e+00  2  2  0  0  0   2  2  0  0  0  9272
PCApply              404 1.0 3.2447e+01 1.1 2.11e+10 1.1 0.0e+00 0.0e+00 0.0e+00 29 37  0  0  0  29 37  0  0  0 12311
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     4              4    666933972     0.
           Index Set     7              7      5403804     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    73             73    231774240     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     2              2         4264     0.
      Preconditioner     2              2         1944     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 2.86e-08
Average time for MPI_Barrier(): 4.8792e-06
Average time for zero size MPI_Send(): 3.3719e-06
#PETSc Option Table entries:
-d 3
-ksp_type fcg
-log_view
-mat_type aij
-n 100
-pc_type bjacobi
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type fcg -pc_type jacobi -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 15:49:39 2020            |
| OS:             Linux                               |
| HostName:       sdumont6171                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.83518, Active time=2.8798                                        |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.3989      0.000008    0.3989      0.000008    13.85    13.85    |
| Ke                            50792      1.7584      0.000035    1.7584      0.000035    61.06    61.06    |
| elem init                     50792      0.7226      0.000014    0.7226      0.000014    25.09    25.09    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.8798                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 43.693035
Tempo total: 43.621715
Tempo total: 43.633769
Tempo total: 43.651546
Tempo total: 43.634411
Tempo total: 43.627122
Tempo total: 43.632157
Tempo total: 43.656254
Tempo total: 43.617389
Tempo total: 43.590136
Tempo total: 43.615212
Tempo total: 43.628115
Tempo total: 43.611402
Tempo total: 43.630181
Tempo total: 43.614748
Tempo total: 43.629819
Tempo total: 43.605711
Tempo total: 43.621131
Tempo total: 43.698766
Tempo total: 43.677802
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6171 with 20 processors, by luciano.siqueira Thu Dec 10 15:49:54 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           4.403e+01     1.000   4.403e+01
Objects:              8.700e+01     1.000   8.700e+01
Flop:                 1.131e+10     1.098   1.080e+10  2.159e+11
Flop/sec:             2.568e+08     1.098   2.452e+08  4.905e+09
MPI Messages:         1.626e+03     2.630   1.094e+03  2.187e+04
MPI Message Lengths:  1.458e+08     1.348   1.154e+05  2.524e+09
MPI Reductions:       5.870e+02     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 4.4026e+01 100.0%  2.1593e+11 100.0%  2.187e+04 100.0%  1.154e+05      100.0%  5.800e+02  98.8%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 5.4011e-0151.4 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  1  0  2  0  1   1  0  2  0  1     0
BuildTwoSidedF         5 1.0 5.3860e-0195.1 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  1  0  2  8  1   1  0  2  8  1     0
MatMult              136 1.0 1.1087e+01 1.1 7.27e+09 1.1 2.0e+04 4.6e+04 0.0e+00 25 64 91 36  0  25 64 91 36  0 12509
MatAssemblyBegin       2 1.0 6.2974e-01 4.6 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  1  0  1  8  0   1  0  1  8  0     0
MatAssemblyEnd         2 1.0 3.4131e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  1  0  1  0  1   1  0  1  0  1    13
MatZeroEntries         3 1.0 1.2290e-01 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecTDot              270 1.0 7.6071e-01 4.2 2.29e+08 1.1 0.0e+00 0.0e+00 2.7e+02  1  2  0  0 46   1  2  0  0 47  5765
VecMTDot             134 1.0 9.6739e-01 1.0 1.67e+09 1.1 0.0e+00 0.0e+00 1.3e+02  2 15  0  0 23   2 15  0  0 23 32990
VecNorm              137 1.0 1.2484e-01 1.5 1.16e+08 1.1 0.0e+00 0.0e+00 1.4e+02  0  1  0  0 23   0  1  0  0 24 17824
VecScale             134 1.0 7.6007e-02 1.2 5.69e+07 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 14317
VecCopy              136 1.0 1.1261e-01 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet                 5 1.0 1.8095e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY              270 1.0 2.4202e-01 1.1 2.29e+08 1.1 0.0e+00 0.0e+00 0.0e+00  1  2  0  0  0   1  2  0  0  0 18119
VecAYPX                1 1.0 1.1325e-03 1.1 4.25e+05 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0  7170
VecMAXPY             134 1.0 1.0804e+00 1.1 1.67e+09 1.1 0.0e+00 0.0e+00 0.0e+00  2 15  0  0  0   2 15  0  0  0 29539
VecAssemblyBegin       3 1.0 8.5371e-03 1.0 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  1  0  1   0  0  1  0  1     0
VecAssemblyEnd         3 1.0 5.8731e-04 4.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecPointwiseMult     137 1.0 1.8994e-01 1.1 5.82e+07 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0  5857
VecScatterBegin      137 1.0 8.3932e-02 2.1 0.00e+00 0.0 2.0e+04 4.6e+04 0.0e+00  0  0 91 36  0   0  0 91 36  0     0
VecScatterEnd        137 1.0 1.0014e+0053.5 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
SFSetGraph             2 1.0 4.9942e-04 1.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.1250e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  3  0  0   0  0  3  0  0     0
SFBcastOpBegin       137 1.0 8.3694e-02 2.1 0.00e+00 0.0 2.0e+04 4.6e+04 0.0e+00  0  0 91 36  0   0  0 91 36  0     0
SFBcastOpEnd         137 1.0 1.0011e+0054.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
SFPack               137 1.0 8.0617e-02 2.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack             137 1.0 9.3392e-05 1.7 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               1 1.0 1.2718e-02 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSolve               1 1.0 1.4119e+01 1.0 1.13e+10 1.1 2.0e+04 4.6e+04 5.4e+02 32100 91 36 93  32100 91 36 94 15278
PCSetUp                1 1.0 7.7100e-07 3.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
PCApply              137 1.0 2.6197e-01 1.1 5.82e+07 1.1 0.0e+00 0.0e+00 2.0e+00  1  1  0  0  0   1  1  0  0  0  4247
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     3              3    344047400     0.
           Index Set     4              4       304416     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    72             72    235170584     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     1              1         2848     0.
      Preconditioner     1              1          968     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 2.77e-08
Average time for MPI_Barrier(): 4.8148e-06
Average time for zero size MPI_Send(): 3.3374e-06
#PETSc Option Table entries:
-d 3
-ksp_type fcg
-log_view
-mat_type aij
-n 100
-pc_type jacobi
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type fcg -pc_type sor -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 15:50:25 2020            |
| OS:             Linux                               |
| HostName:       sdumont6171                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.83658, Active time=2.88147                                       |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.3981      0.000008    0.3981      0.000008    13.81    13.81    |
| Ke                            50792      1.7540      0.000035    1.7540      0.000035    60.87    60.87    |
| elem init                     50792      0.7294      0.000014    0.7294      0.000014    25.31    25.31    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.8815                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 130.607671
Tempo total: 130.597028
Tempo total: 130.579604
Tempo total: 130.567081
Tempo total: 130.581560
Tempo total: 130.553562
Tempo total: 130.541553
Tempo total: 130.545560
Tempo total: 130.521054
Tempo total: 130.536917
Tempo total: 130.567086
Tempo total: 130.549552
Tempo total: 130.510241
Tempo total: 130.529969
Tempo total: 130.547611
Tempo total: 130.529155
Tempo total: 130.545510
Tempo total: 130.529066
Tempo total: 130.549030
Tempo total: 130.637507
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6171 with 20 processors, by luciano.siqueira Thu Dec 10 15:52:08 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           1.311e+02     1.000   1.311e+02
Objects:              8.600e+01     1.000   8.600e+01
Flop:                 6.293e+10     1.104   5.988e+10  1.198e+12
Flop/sec:             4.800e+08     1.104   4.567e+08  9.134e+09
MPI Messages:         5.190e+03     2.711   3.459e+03  6.918e+04
MPI Message Lengths:  2.915e+08     1.600   6.784e+04  4.693e+09
MPI Reductions:       1.881e+03     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 1.3111e+02 100.0%  1.1976e+12 100.0%  6.918e+04 100.0%  6.784e+04      100.0%  1.874e+03  99.6%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 4.6631e-0194.5 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  0  0  1  0  0   0  0  1  0  0     0
BuildTwoSidedF         5 1.0 4.6524e-01125.3 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  0  0  1  4  0   0  0  1  4  0     0
MatMult              460 1.0 3.7534e+01 1.1 2.46e+10 1.1 6.7e+04 4.6e+04 0.0e+00 28 39 97 66  0  28 39 97 66  0 12497
MatSOR               461 1.0 5.5326e+01 1.1 2.43e+10 1.1 0.0e+00 0.0e+00 0.0e+00 40 38  0  0  0  40 38  0  0  0  8306
MatAssemblyBegin       2 1.0 5.4874e-01 3.0 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  0  0  0  4  0   0  0  0  4  0     0
MatAssemblyEnd         2 1.0 3.4403e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  0  0  0  0  0   0  0  0  0  0    13
MatZeroEntries         3 1.0 1.2266e-01 1.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecTDot              918 1.0 2.5107e+00 4.1 7.80e+08 1.1 0.0e+00 0.0e+00 9.2e+02  1  1  0  0 49   1  1  0  0 49  5938
VecMTDot             458 1.0 3.0873e+00 1.0 5.96e+09 1.1 0.0e+00 0.0e+00 4.6e+02  2 10  0  0 24   2 10  0  0 24 36883
VecNorm              461 1.0 6.6338e+0025.4 3.92e+08 1.1 0.0e+00 0.0e+00 4.6e+02  3  1  0  0 25   3  1  0  0 25  1129
VecScale             458 1.0 2.7908e-01 1.1 1.95e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 13327
VecCopy              460 1.0 3.4471e-01 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet                 5 1.0 1.7491e-03 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY              918 1.0 8.3066e-01 1.2 7.80e+08 1.1 0.0e+00 0.0e+00 0.0e+00  1  1  0  0  0   1  1  0  0  0 17949
VecAYPX                1 1.0 1.1439e-03 1.1 4.25e+05 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0  7099
VecMAXPY             458 1.0 3.9187e+00 1.1 5.96e+09 1.1 0.0e+00 0.0e+00 0.0e+00  3 10  0  0  0   3 10  0  0  0 29057
VecAssemblyBegin       3 1.0 9.6416e-03 1.0 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAssemblyEnd         3 1.0 6.2936e-04 5.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecScatterBegin      461 1.0 2.9271e-01 2.1 0.00e+00 0.0 6.7e+04 4.6e+04 0.0e+00  0  0 97 66  0   0  0 97 66  0     0
VecScatterEnd        461 1.0 3.5511e+0058.5 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
SFSetGraph             2 1.0 5.1658e-04 1.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.1465e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  1  0  0   0  0  1  0  0     0
SFBcastOpBegin       461 1.0 2.9195e-01 2.1 0.00e+00 0.0 6.7e+04 4.6e+04 0.0e+00  0  0 97 66  0   0  0 97 66  0     0
SFBcastOpEnd         461 1.0 3.5501e+0059.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
SFPack               461 1.0 2.8416e-01 2.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack             461 1.0 3.4131e-04 1.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               1 1.0 1.4637e-02 1.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSolve               1 1.0 1.0212e+02 1.0 6.29e+10 1.1 6.7e+04 4.6e+04 1.8e+03 78100 97 66 98  78100 97 66 98 11725
PCSetUp                1 1.0 3.3100e-07 2.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
PCApply              461 1.0 5.5328e+01 1.1 2.43e+10 1.1 0.0e+00 0.0e+00 0.0e+00 40 38  0  0  0  40 38  0  0  0  8306
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     3              3    354240752     0.
           Index Set     4              4       304416     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    71             71    231771104     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     1              1         2848     0.
      Preconditioner     1              1          968     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 2.79e-08
Average time for MPI_Barrier(): 4.898e-06
Average time for zero size MPI_Send(): 3.55485e-06
#PETSc Option Table entries:
-d 3
-ksp_type fcg
-log_view
-mat_type aij
-n 100
-pc_type sor
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type fcg -pc_type mg -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 15:52:38 2020            |
| OS:             Linux                               |
| HostName:       sdumont6171                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.8553, Active time=2.88657                                        |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.3993      0.000008    0.3993      0.000008    13.83    13.83    |
| Ke                            50792      1.7652      0.000035    1.7652      0.000035    61.15    61.15    |
| elem init                     50792      0.7220      0.000014    0.7220      0.000014    25.01    25.01    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.8866                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 138.186392
Tempo total: 138.093121
Tempo total: 138.079333
Tempo total: 138.075543
Tempo total: 138.082242
Tempo total: 138.061199
Tempo total: 138.051769
Tempo total: 138.035825
Tempo total: 138.046232
Tempo total: 138.024077
Tempo total: 138.059059
Tempo total: 138.036887
Tempo total: 138.051520
Tempo total: 138.028764
Tempo total: 138.044503
Tempo total: 138.040175
Tempo total: 138.043993
Tempo total: 138.027267
Tempo total: 138.012613
Tempo total: 138.161020
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6171 with 20 processors, by luciano.siqueira Thu Dec 10 15:54:29 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           1.385e+02     1.000   1.385e+02
Objects:              1.110e+02     1.000   1.110e+02
Flop:                 6.285e+10     1.105   5.977e+10  1.195e+12
Flop/sec:             4.538e+08     1.105   4.316e+08  8.632e+09
MPI Messages:         5.750e+03     2.715   3.831e+03  7.662e+04
MPI Message Lengths:  3.144e+08     1.622   6.570e+04  5.034e+09
MPI Reductions:       1.064e+03     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 1.3850e+02 100.0%  1.1955e+12 100.0%  7.662e+04 100.0%  6.570e+04      100.0%  1.057e+03  99.3%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 4.5091e-01101.1 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  0  0  1  0  1   0  0  1  0  1     0
BuildTwoSidedF         5 1.0 4.4940e-01120.7 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  0  0  0  4  0   0  0  0  4  0     0
MatMult              511 1.0 4.4793e+01 1.1 2.73e+10 1.1 7.5e+04 4.6e+04 0.0e+00 31 44 97 68  0  31 44 97 68  0 11633
MatSOR               513 1.0 6.1647e+01 1.1 2.70e+10 1.1 0.0e+00 0.0e+00 0.0e+00 42 43  0  0  0  42 43  0  0  0  8295
MatAssemblyBegin       2 1.0 5.5420e-01 3.1 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  0  0  0  4  0   0  0  0  4  0     0
MatAssemblyEnd         2 1.0 3.4132e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  0  0  0  0  0   0  0  0  0  0    13
MatZeroEntries         3 1.0 1.2176e-01 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecMDot               10 1.0 1.5498e-01 6.7 4.67e+07 1.1 0.0e+00 0.0e+00 1.0e+01  0  0  0  0  1   0  0  0  0  1  5764
VecTDot              498 1.0 1.4213e+00 4.2 4.23e+08 1.1 0.0e+00 0.0e+00 5.0e+02  1  1  0  0 47   1  1  0  0 47  5691
VecMTDot             248 1.0 1.5867e+00 1.0 3.19e+09 1.1 0.0e+00 0.0e+00 2.5e+02  1  5  0  0 23   1  5  0  0 23 38446
VecNorm              262 1.0 4.5490e+0027.4 2.23e+08 1.1 0.0e+00 0.0e+00 2.6e+02  1  0  0  0 25   1  0  0  0 25   935
VecScale             259 1.0 1.7116e-01 1.1 1.10e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 12288
VecCopy              753 1.0 5.5180e-01 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet               509 1.0 2.3825e-01 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY              499 1.0 4.4891e-01 1.1 4.24e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 18053
VecAYPX              503 1.0 5.6505e-01 1.1 3.20e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 10836
VecAXPBYCZ           251 1.0 3.4237e-01 1.1 5.33e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 29767
VecMAXPY             259 1.0 2.1425e+00 1.1 3.25e+09 1.1 0.0e+00 0.0e+00 0.0e+00  1  5  0  0  0   1  5  0  0  0 28965
VecAssemblyBegin       3 1.0 9.6242e-03 1.0 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAssemblyEnd         3 1.0 6.2332e-04 4.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecScatterBegin      512 1.0 3.2192e-01 2.0 0.00e+00 0.0 7.5e+04 4.6e+04 0.0e+00  0  0 98 68  0   0  0 98 68  0     0
VecScatterEnd        512 1.0 7.4680e+0075.6 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  2  0  0  0  0   2  0  0  0  0     0
VecNormalize          11 1.0 3.4308e-02 3.2 1.40e+07 1.1 0.0e+00 0.0e+00 1.1e+01  0  0  0  0  1   0  0  0  0  1  7811
SFSetGraph             2 1.0 5.1826e-04 1.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.1414e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  1  0  0   0  0  1  0  0     0
SFBcastOpBegin       512 1.0 3.2082e-01 2.0 0.00e+00 0.0 7.5e+04 4.6e+04 0.0e+00  0  0 98 68  0   0  0 98 68  0     0
SFBcastOpEnd         512 1.0 7.4667e+0076.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  2  0  0  0  0   2  0  0  0  0     0
SFPack               512 1.0 3.0955e-01 2.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack             512 1.0 3.4404e-04 1.6 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               2 1.0 2.3780e+00 1.0 1.23e+09 1.1 1.5e+03 4.6e+04 2.3e+01  2  2  2  1  2   2  2  2  1  2  9842
KSPSolve               1 1.0 1.0968e+02 1.0 6.28e+10 1.1 7.5e+04 4.6e+04 1.0e+03 79100 97 68 96  79100 97 68 96 10898
KSPGMRESOrthog        10 1.0 1.8324e-01 3.4 9.34e+07 1.1 0.0e+00 0.0e+00 1.0e+01  0  0  0  0  1   0  0  0  0  1  9750
PCSetUp                1 1.0 2.3673e+00 1.0 1.23e+09 1.1 1.5e+03 4.6e+04 2.3e+01  2  2  2  1  2   2  2  2  1  2  9886
PCApply              262 1.0 8.3232e+01 1.1 4.13e+10 1.1 3.7e+04 4.6e+04 0.0e+00 59 66 48 33  0  59 66 48 33  0  9415
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     3              3    354240752     0.
           Index Set     4              4       304416     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    90             90    296361224     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     4              4        36392     0.
      Preconditioner     4              4         4256     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 2.93e-08
Average time for MPI_Barrier(): 4.83e-06
Average time for zero size MPI_Send(): 3.35255e-06
#PETSc Option Table entries:
-d 3
-ksp_type fcg
-log_view
-mat_type aij
-n 100
-pc_type mg
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type tcqmr -pc_type bjacobi -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 15:55:00 2020            |
| OS:             Linux                               |
| HostName:       sdumont6171                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.85047, Active time=2.89022                                       |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.3974      0.000008    0.3974      0.000008    13.75    13.75    |
| Ke                            50792      1.7655      0.000035    1.7655      0.000035    61.09    61.09    |
| elem init                     50792      0.7273      0.000014    0.7273      0.000014    25.17    25.17    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.8902                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 713.527336
Tempo total: 713.495006
Tempo total: 713.447187
Tempo total: 713.465304
Tempo total: 713.481664
Tempo total: 713.465570
Tempo total: 713.481584
Tempo total: 713.456534
Tempo total: 713.433011
Tempo total: 713.451349
Tempo total: 713.472529
Tempo total: 713.446322
Tempo total: 713.464194
Tempo total: 713.439194
Tempo total: 713.421116
Tempo total: 713.444251
Tempo total: 713.464827
Tempo total: 713.440741
Tempo total: 713.427200
Tempo total: 713.497756
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6171 with 20 processors, by luciano.siqueira Thu Dec 10 16:06:26 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           7.138e+02     1.000   7.138e+02
Objects:              4.800e+01     1.000   4.800e+01
Flop:                 4.546e+11     1.106   4.321e+11  8.642e+12
Flop/sec:             6.369e+08     1.106   6.054e+08  1.211e+10
MPI Messages:         4.525e+04     2.746   3.005e+04  6.009e+05
MPI Message Lengths:  1.930e+09     1.902   4.838e+04  2.907e+10
MPI Reductions:       6.882e+03     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 7.1384e+02 100.0%  8.6425e+12 100.0%  6.009e+05 100.0%  4.838e+04      100.0%  6.875e+03  99.9%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 4.6083e-01110.8 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  0  0  0  0  0   0  0  0  0  0     0
BuildTwoSidedF         5 1.0 4.5965e-01177.4 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  0  0  0  1  0   0  0  0  1  0     0
MatMult             4102 1.0 3.3476e+02 1.1 2.19e+11 1.1 6.0e+05 4.6e+04 0.0e+00 46 48100 94  0  46 48100 94  0 12495
MatSolve            4104 1.0 3.2604e+02 1.1 2.14e+11 1.1 0.0e+00 0.0e+00 0.0e+00 43 47  0  0  0  43 47  0  0  0 12445
MatLUFactorNum         1 1.0 2.4406e+00 1.1 1.27e+09 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0  9914
MatILUFactorSym        1 1.0 1.5523e-01 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatAssemblyBegin       2 1.0 5.3234e-01 3.2 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  0  0  0  1  0   0  0  0  1  0     0
MatAssemblyEnd         2 1.0 3.4674e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  0  0  0  0  0   0  0  0  0  0    12
MatGetRowIJ            1 1.0 4.3660e-06 1.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatGetOrdering         1 1.0 4.2202e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatZeroEntries         3 1.0 1.2221e-01 1.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecDot              4101 1.0 1.5493e+01 5.4 3.48e+09 1.1 0.0e+00 0.0e+00 4.1e+03  1  1  0  0 60   1  1  0  0 60  4299
VecNorm             2737 1.0 2.7133e+0118.9 2.32e+09 1.1 0.0e+00 0.0e+00 2.7e+03  2  1  0  0 40   2  1  0  0 40  1638
VecScale            5469 1.0 1.9422e+00 1.2 2.32e+09 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 22867
VecCopy            12308 1.0 9.9396e+00 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
VecSet              4114 1.0 1.8994e+00 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY            12301 1.0 8.3235e+00 1.1 1.04e+10 1.1 0.0e+00 0.0e+00 0.0e+00  1  2  0  0  0   1  2  0  0  0 24002
VecAYPX             1367 1.0 1.5642e+00 1.1 1.16e+09 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 14194
VecAssemblyBegin       3 1.0 9.1969e-03 1.1 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAssemblyEnd         3 1.0 5.8955e-04 4.6 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecScatterBegin     4103 1.0 2.8305e+00 2.1 0.00e+00 0.0 6.0e+05 4.6e+04 0.0e+00  0  0100 94  0   0  0100 94  0     0
VecScatterEnd       4103 1.0 3.1675e+0158.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  2  0  0  0  0   2  0  0  0  0     0
SFSetGraph             2 1.0 5.3186e-04 1.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.1952e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFBcastOpBegin      4103 1.0 2.8190e+00 2.2 0.00e+00 0.0 6.0e+05 4.6e+04 0.0e+00  0  0100 94  0   0  0100 94  0     0
SFBcastOpEnd        4103 1.0 3.1665e+0159.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  2  0  0  0  0   2  0  0  0  0     0
SFPack              4103 1.0 2.7360e+00 2.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack            4103 1.0 2.5324e-03 1.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               2 1.0 1.0907e-02 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSolve               1 1.0 6.8443e+02 1.0 4.55e+11 1.1 6.0e+05 4.6e+04 6.8e+03 96100100 94 99  96100100 94 99 12627
PCSetUp                2 1.0 2.6031e+00 1.1 1.27e+09 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0  9295
PCSetUpOnBlocks        1 1.0 2.5956e+00 1.1 1.27e+09 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0  9322
PCApply             4104 1.0 3.2798e+02 1.1 2.14e+11 1.1 0.0e+00 0.0e+00 0.0e+00 44 47  0  0  0  44 47  0  0  0 12372
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     4              4    666933972     0.
           Index Set     7              7      5403804     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    27             27     75398160     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     2              2         3016     0.
      Preconditioner     2              2         1944     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 2.87e-08
Average time for MPI_Barrier(): 4.6876e-06
Average time for zero size MPI_Send(): 3.34195e-06
#PETSc Option Table entries:
-d 3
-ksp_type tcqmr
-log_view
-mat_type aij
-n 100
-pc_type bjacobi
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type tcqmr -pc_type jacobi -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 16:06:57 2020            |
| OS:             Linux                               |
| HostName:       sdumont6171                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.87482, Active time=2.90285                                       |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.4026      0.000008    0.4026      0.000008    13.87    13.87    |
| Ke                            50792      1.7718      0.000035    1.7718      0.000035    61.04    61.04    |
| elem init                     50792      0.7285      0.000014    0.7285      0.000014    25.10    25.10    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.9028                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 313.879669
Tempo total: 313.850406
Tempo total: 313.846178
Tempo total: 313.822632
Tempo total: 313.805918
Tempo total: 313.817961
Tempo total: 313.819986
Tempo total: 313.802554
Tempo total: 313.811745
Tempo total: 313.813930
Tempo total: 313.810177
Tempo total: 313.794064
Tempo total: 313.810273
Tempo total: 313.792868
Tempo total: 313.811876
Tempo total: 313.792453
Tempo total: 313.814625
Tempo total: 313.793324
Tempo total: 313.813889
Tempo total: 313.818606
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6171 with 20 processors, by luciano.siqueira Thu Dec 10 16:11:43 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           3.142e+02     1.000   3.142e+02
Objects:              4.100e+01     1.000   4.100e+01
Flop:                 1.878e+11     1.100   1.792e+11  3.585e+12
Flop/sec:             5.977e+08     1.100   5.705e+08  1.141e+10
MPI Messages:         3.534e+04     2.744   2.347e+04  4.694e+05
MPI Message Lengths:  1.524e+09     1.886   4.909e+04  2.304e+10
MPI Reductions:       5.384e+03     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 3.1419e+02 100.0%  3.5848e+12 100.0%  4.694e+05 100.0%  4.909e+04      100.0%  5.377e+03  99.9%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 4.8983e-01107.0 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  0  0  0  0  0   0  0  0  0  0     0
BuildTwoSidedF         5 1.0 4.8832e-01139.7 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  0  0  0  1  0   0  0  0  1  0     0
MatMult             3201 1.0 2.6176e+02 1.1 1.71e+11 1.1 4.7e+05 4.6e+04 0.0e+00 82 91100 93  0  82 91100 93  0 12470
MatAssemblyBegin       2 1.0 5.7235e-01 3.6 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  0  0  0  1  0   0  0  0  1  0     0
MatAssemblyEnd         2 1.0 3.5537e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  0  0  0  0  0   0  0  0  0  0    12
MatZeroEntries         3 1.0 1.2379e-01 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecDot              3201 1.0 6.3693e+00 2.9 2.72e+09 1.1 0.0e+00 0.0e+00 3.2e+03  1  1  0  0 59   1  1  0  0 60  8162
VecNorm             2136 1.0 9.8115e+00 9.1 1.81e+09 1.1 0.0e+00 0.0e+00 2.1e+03  1  1  0  0 40   1  1  0  0 40  3536
VecScale            4265 1.0 1.7630e+00 1.4 1.81e+09 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 19645
VecCopy             9601 1.0 7.5464e+00 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  2  0  0  0  0   2  0  0  0  0     0
VecSet                10 1.0 4.4417e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY             9594 1.0 6.7406e+00 1.2 8.15e+09 1.1 0.0e+00 0.0e+00 0.0e+00  2  4  0  0  0   2  4  0  0  0 23116
VecAYPX             1066 1.0 1.2129e+00 1.1 9.06e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 14274
VecAssemblyBegin       3 1.0 9.6866e-03 1.0 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAssemblyEnd         3 1.0 5.9987e-04 4.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecPointwiseMult    3203 1.0 4.1091e+00 1.1 1.36e+09 1.1 0.0e+00 0.0e+00 0.0e+00  1  1  0  0  0   1  1  0  0  0  6330
VecScatterBegin     3202 1.0 2.3058e+00 2.2 0.00e+00 0.0 4.7e+05 4.6e+04 0.0e+00  1  0100 93  0   1  0100 93  0     0
VecScatterEnd       3202 1.0 2.5028e+0161.8 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  3  0  0  0  0   3  0  0  0  0     0
SFSetGraph             2 1.0 5.1254e-04 1.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.1595e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFBcastOpBegin      3202 1.0 2.2985e+00 2.2 0.00e+00 0.0 4.7e+05 4.6e+04 0.0e+00  1  0100 93  0   1  0100 93  0     0
SFBcastOpEnd        3202 1.0 2.5022e+0162.8 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  3  0  0  0  0   3  0  0  0  0     0
SFPack              3202 1.0 2.2312e+00 2.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack            3202 1.0 2.2087e-03 2.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               1 1.0 9.0284e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSolve               1 1.0 2.8485e+02 1.0 1.88e+11 1.1 4.7e+05 4.6e+04 5.3e+03 91100100 93 99  91100100 93 99 12584
PCSetUp                1 1.0 7.7500e-07 2.5 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
PCApply             3203 1.0 4.1859e+00 1.1 1.36e+09 1.1 0.0e+00 0.0e+00 2.0e+00  1  1  0  0  0   1  1  0  0  0  6214
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     3              3    344047400     0.
           Index Set     4              4       304416     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    26             26     78794504     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     1              1         1600     0.
      Preconditioner     1              1          968     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 2.89e-08
Average time for MPI_Barrier(): 4.875e-06
Average time for zero size MPI_Send(): 3.38775e-06
#PETSc Option Table entries:
-d 3
-ksp_type tcqmr
-log_view
-mat_type aij
-n 100
-pc_type jacobi
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type tcqmr -pc_type sor -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 16:12:14 2020            |
| OS:             Linux                               |
| HostName:       sdumont6171                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.86399, Active time=2.89755                                       |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.4029      0.000008    0.4029      0.000008    13.90    13.90    |
| Ke                            50792      1.7634      0.000035    1.7634      0.000035    60.86    60.86    |
| elem init                     50792      0.7313      0.000014    0.7313      0.000014    25.24    25.24    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.8976                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 390.279303
Tempo total: 390.249883
Tempo total: 390.236906
Tempo total: 390.238538
Tempo total: 390.208476
Tempo total: 390.226148
Tempo total: 390.206164
Tempo total: 390.199738
Tempo total: 390.242807
Tempo total: 390.226228
Tempo total: 390.233189
Tempo total: 390.208231
Tempo total: 390.222702
Tempo total: 390.200029
Tempo total: 390.187723
Tempo total: 390.196465
Tempo total: 390.228437
Tempo total: 390.197005
Tempo total: 390.224932
Tempo total: 390.301229
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6171 with 20 processors, by luciano.siqueira Thu Dec 10 16:18:16 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           3.906e+02     1.000   3.906e+02
Objects:              4.000e+01     1.000   4.000e+01
Flop:                 1.939e+11     1.106   1.843e+11  3.686e+12
Flop/sec:             4.964e+08     1.106   4.718e+08  9.436e+09
MPI Messages:         1.935e+04     2.740   1.285e+04  2.571e+05
MPI Message Lengths:  8.704e+08     1.828   5.177e+04  1.331e+10
MPI Reductions:       2.957e+03     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 3.9060e+02 100.0%  3.6859e+12 100.0%  2.571e+05 100.0%  5.177e+04      100.0%  2.950e+03  99.8%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 4.9703e-0195.8 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  0  0  0  0  0   0  0  0  0  0     0
BuildTwoSidedF         5 1.0 4.9605e-01120.5 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  0  0  0  2  0   0  0  0  2  0     0
MatMult             1747 1.0 1.4291e+02 1.1 9.33e+10 1.1 2.6e+05 4.6e+04 0.0e+00 36 48 99 88  0  36 48 99 88  0 12465
MatSOR              1749 1.0 2.1020e+02 1.1 9.21e+10 1.1 0.0e+00 0.0e+00 0.0e+00 51 47  0  0  0  51 47  0  0  0  8294
MatAssemblyBegin       2 1.0 5.6961e-01 4.1 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  0  0  0  2  0   0  0  0  2  0     0
MatAssemblyEnd         2 1.0 3.4299e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  0  0  0  0  0   0  0  0  0  0    13
MatZeroEntries         3 1.0 1.2294e-01 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecDot              1746 1.0 8.9285e+00 7.6 1.48e+09 1.1 0.0e+00 0.0e+00 1.7e+03  1  1  0  0 59   1  1  0  0 59  3176
VecNorm             1167 1.0 1.6350e+0126.4 9.91e+08 1.1 0.0e+00 0.0e+00 1.2e+03  2  1  0  0 39   2  1  0  0 40  1159
VecScale            2329 1.0 8.2247e-01 1.2 9.89e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 22995
VecCopy             5243 1.0 4.1299e+00 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
VecSet                10 1.0 4.3889e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY             5236 1.0 3.5788e+00 1.2 4.45e+09 1.1 0.0e+00 0.0e+00 0.0e+00  1  2  0  0  0   1  2  0  0  0 23762
VecAYPX              582 1.0 6.6964e-01 1.1 4.94e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 14116
VecAssemblyBegin       3 1.0 1.0423e-02 1.1 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAssemblyEnd         3 1.0 5.8475e-04 4.5 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecScatterBegin     1748 1.0 1.2011e+00 2.1 0.00e+00 0.0 2.6e+05 4.6e+04 0.0e+00  0  0 99 88  0   0  0 99 88  0     0
VecScatterEnd       1748 1.0 1.2417e+0152.8 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
SFSetGraph             2 1.0 5.2211e-04 1.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.1384e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFBcastOpBegin      1748 1.0 1.1963e+00 2.1 0.00e+00 0.0 2.6e+05 4.6e+04 0.0e+00  0  0 99 88  0   0  0 99 88  0     0
SFBcastOpEnd        1748 1.0 1.2413e+0153.7 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
SFPack              1748 1.0 1.1598e+00 2.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack            1748 1.0 1.1234e-03 1.7 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               1 1.0 9.0071e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSolve               1 1.0 3.6127e+02 1.0 1.94e+11 1.1 2.6e+05 4.6e+04 2.9e+03 92100 99 88 99  92100 99 88 99 10202
PCSetUp                1 1.0 3.8300e-07 2.6 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
PCApply             1749 1.0 2.1021e+02 1.1 9.21e+10 1.1 0.0e+00 0.0e+00 0.0e+00 51 47  0  0  0  51 47  0  0  0  8294
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     3              3    354240752     0.
           Index Set     4              4       304416     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    25             25     75395024     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     1              1         1600     0.
      Preconditioner     1              1          968     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 2.85e-08
Average time for MPI_Barrier(): 4.8772e-06
Average time for zero size MPI_Send(): 3.3291e-06
#PETSc Option Table entries:
-d 3
-ksp_type tcqmr
-log_view
-mat_type aij
-n 100
-pc_type sor
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type tcqmr -pc_type mg -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 16:18:46 2020            |
| OS:             Linux                               |
| HostName:       sdumont6171                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.86153, Active time=2.89279                                       |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.3980      0.000008    0.3980      0.000008    13.76    13.76    |
| Ke                            50792      1.7661      0.000035    1.7661      0.000035    61.05    61.05    |
| elem init                     50792      0.7287      0.000014    0.7287      0.000014    25.19    25.19    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.8928                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 361.090184
Tempo total: 361.078648
Tempo total: 361.048558
Tempo total: 361.070460
Tempo total: 361.078066
Tempo total: 361.058477
Tempo total: 361.075012
Tempo total: 361.046923
Tempo total: 361.028130
Tempo total: 361.038060
Tempo total: 361.022981
Tempo total: 361.032398
Tempo total: 361.023931
Tempo total: 361.032824
Tempo total: 361.052226
Tempo total: 361.034120
Tempo total: 361.014994
Tempo total: 361.028689
Tempo total: 361.051748
Tempo total: 361.077378
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6171 with 20 processors, by luciano.siqueira Thu Dec 10 16:24:20 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           3.614e+02     1.000   3.614e+02
Objects:              6.500e+01     1.000   6.500e+01
Flop:                 1.783e+11     1.106   1.695e+11  3.390e+12
Flop/sec:             4.934e+08     1.106   4.690e+08  9.380e+09
MPI Messages:         1.791e+04     2.739   1.190e+04  2.380e+05
MPI Message Lengths:  8.115e+08     1.818   5.224e+04  1.243e+10
MPI Reductions:       1.405e+03     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 3.6143e+02 100.0%  3.3902e+12 100.0%  2.380e+05 100.0%  5.224e+04      100.0%  1.398e+03  99.5%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 4.7823e-01102.2 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  0  0  0  0  0   0  0  0  0  1     0
BuildTwoSidedF         5 1.0 4.7719e-01121.4 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  0  0  0  2  0   0  0  0  2  0     0
MatMult             1616 1.0 1.4035e+02 1.1 8.63e+10 1.1 2.4e+05 4.6e+04 0.0e+00 37 49 99 87  0  37 49 99 87  0 11741
MatSOR              1619 1.0 1.9367e+02 1.1 8.53e+10 1.1 0.0e+00 0.0e+00 0.0e+00 51 48  0  0  0  51 48  0  0  0  8333
MatAssemblyBegin       2 1.0 5.7367e-01 4.3 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  0  0  0  2  0   0  0  0  2  0     0
MatAssemblyEnd         2 1.0 3.4311e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  0  0  0  0  0   0  0  0  0  0    13
MatZeroEntries         3 1.0 1.2175e-01 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecDot               801 1.0 4.8184e+00 8.7 6.80e+08 1.1 0.0e+00 0.0e+00 8.0e+02  1  0  0  0 57   1  0  0  0 57  2700
VecMDot               10 1.0 1.4017e-01 6.6 4.67e+07 1.1 0.0e+00 0.0e+00 1.0e+01  0  0  0  0  1   0  0  0  0  1  6373
VecNorm              548 1.0 8.8829e+0030.0 4.65e+08 1.1 0.0e+00 0.0e+00 5.5e+02  1  0  0  0 39   1  0  0  0 39  1002
VecScale            1080 1.0 4.0037e-01 1.2 4.59e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 21905
VecCopy             4017 1.0 2.8406e+00 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
VecSet              1620 1.0 4.9778e-01 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY             2402 1.0 1.5496e+00 1.1 2.04e+09 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 25175
VecAYPX             1875 1.0 2.1137e+00 1.1 1.25e+09 1.1 0.0e+00 0.0e+00 0.0e+00  1  1  0  0  0   1  1  0  0  0 11318
VecAXPBYCZ           804 1.0 1.0768e+00 1.1 1.71e+09 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 30316
VecMAXPY              11 1.0 3.7075e-02 1.1 5.52e+07 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 28474
VecAssemblyBegin       3 1.0 1.0177e-02 1.1 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAssemblyEnd         3 1.0 6.2694e-04 4.6 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecScatterBegin     1617 1.0 1.0426e+00 2.0 0.00e+00 0.0 2.4e+05 4.6e+04 0.0e+00  0  0 99 87  0   0  0 99 87  0     0
VecScatterEnd       1617 1.0 2.2086e+01103.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  3  0  0  0  0   3  0  0  0  0     0
VecNormalize          11 1.0 3.3229e-02 3.2 1.40e+07 1.1 0.0e+00 0.0e+00 1.1e+01  0  0  0  0  1   0  0  0  0  1  8065
SFSetGraph             2 1.0 5.1660e-04 1.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.1589e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFBcastOpBegin      1617 1.0 1.0386e+00 2.0 0.00e+00 0.0 2.4e+05 4.6e+04 0.0e+00  0  0 99 87  0   0  0 99 87  0     0
SFBcastOpEnd        1617 1.0 2.2082e+01105.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  3  0  0  0  0   3  0  0  0  0     0
SFPack              1617 1.0 1.0042e+00 2.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack            1617 1.0 1.2999e-03 1.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               2 1.0 2.3311e+00 1.0 1.23e+09 1.1 1.5e+03 4.6e+04 2.3e+01  1  1  1  1  2   1  1  1  1  2 10040
KSPSolve               1 1.0 3.3252e+02 1.0 1.78e+11 1.1 2.4e+05 4.6e+04 1.4e+03 92100 99 87 97  92100 99 87 97 10195
KSPGMRESOrthog        10 1.0 1.6818e-01 3.2 9.34e+07 1.1 0.0e+00 0.0e+00 1.0e+01  0  0  0  0  1   0  0  0  0  1 10623
PCSetUp                1 1.0 2.3227e+00 1.0 1.23e+09 1.1 1.5e+03 4.6e+04 2.3e+01  1  1  1  1  2   1  1  1  1  2 10076
PCApply              815 1.0 2.6245e+02 1.0 1.31e+11 1.1 1.2e+05 4.6e+04 0.0e+00 71 73 49 43  0  71 73 49 43  0  9472
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     3              3    354240752     0.
           Index Set     4              4       304416     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    44             44    139985144     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     4              4        35144     0.
      Preconditioner     4              4         4256     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 2.89e-08
Average time for MPI_Barrier(): 5.043e-06
Average time for zero size MPI_Send(): 3.35625e-06
#PETSc Option Table entries:
-d 3
-ksp_type tcqmr
-log_view
-mat_type aij
-n 100
-pc_type mg
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type cgs -pc_type bjacobi -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 16:24:51 2020            |
| OS:             Linux                               |
| HostName:       sdumont6171                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.85637, Active time=2.89063                                       |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.3996      0.000008    0.3996      0.000008    13.82    13.82    |
| Ke                            50792      1.7636      0.000035    1.7636      0.000035    61.01    61.01    |
| elem init                     50792      0.7275      0.000014    0.7275      0.000014    25.17    25.17    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.8906                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 39.204692
Tempo total: 39.263973
Tempo total: 39.234377
Tempo total: 39.227207
Tempo total: 39.214001
Tempo total: 39.184642
Tempo total: 39.219037
Tempo total: 39.202761
Tempo total: 39.174859
Tempo total: 39.194879
Tempo total: 39.215482
Tempo total: 39.204594
Tempo total: 39.216273
Tempo total: 39.185311
Tempo total: 39.174040
Tempo total: 39.192575
Tempo total: 39.204743
Tempo total: 39.191136
Tempo total: 39.199532
Tempo total: 39.246499
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6171 with 20 processors, by luciano.siqueira Thu Dec 10 16:25:02 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           3.959e+01     1.000   3.959e+01
Objects:              3.700e+01     1.000   3.700e+01
Flop:                 6.272e+09     1.107   5.959e+09  1.192e+11
Flop/sec:             1.584e+08     1.107   1.505e+08  3.011e+09
MPI Messages:         6.245e+02     2.459   4.294e+02  8.587e+03
MPI Message Lengths:  1.048e+08     1.200   2.230e+05  1.915e+09
MPI Reductions:       1.130e+02     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 3.9590e+01 100.0%  1.1919e+11 100.0%  8.587e+03 100.0%  2.230e+05      100.0%  1.060e+02  93.8%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 3.9536e-0179.9 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  0  0  5  0  6   0  0  5  0  7     0
BuildTwoSidedF         5 1.0 3.9379e-0190.2 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  0  0  4 11  4   0  0  4 11  5     0
MatMult               45 1.0 3.9015e+00 1.1 2.40e+09 1.1 6.6e+03 4.6e+04 0.0e+00  9 39 77 16  0   9 39 77 16  0 11762
MatSolve              46 1.0 3.6521e+00 1.1 2.40e+09 1.1 0.0e+00 0.0e+00 0.0e+00  9 38  0  0  0   9 38  0  0  0 12454
MatLUFactorNum         1 1.0 2.4606e+00 1.1 1.27e+09 1.1 0.0e+00 0.0e+00 0.0e+00  6 20  0  0  0   6 20  0  0  0  9834
MatILUFactorSym        1 1.0 1.5092e-01 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatAssemblyBegin       2 1.0 5.1956e-01 4.7 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  1  0  2 11  2   1  0  2 11  2     0
MatAssemblyEnd         2 1.0 3.4221e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  1  0  3  0  4   1  0  3  0  5    13
MatGetRowIJ            1 1.0 3.6430e-06 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatGetOrdering         1 1.0 4.1444e-03 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatZeroEntries         3 1.0 1.2342e-01 1.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecDot                45 1.0 4.0735e-0114.6 3.82e+07 1.1 0.0e+00 0.0e+00 4.5e+01  1  1  0  0 40   1  1  0  0 42  1794
VecNorm               24 1.0 1.0780e-01 7.7 2.04e+07 1.1 0.0e+00 0.0e+00 2.4e+01  0  0  0  0 21   0  0  0  0 23  3616
VecCopy                5 1.0 3.6719e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet                51 1.0 2.3078e-02 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY               66 1.0 5.1900e-02 1.1 5.61e+07 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 20653
VecWAXPY              86 1.0 1.1189e-01 1.1 6.37e+07 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 10887
VecAssemblyBegin       3 1.0 9.6785e-03 1.0 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  3  0  3   0  0  3  0  3     0
VecAssemblyEnd         3 1.0 5.7242e-04 4.5 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecScatterBegin       46 1.0 3.0727e-02 2.0 0.00e+00 0.0 6.7e+03 4.6e+04 0.0e+00  0  0 78 16  0   0  0 78 16  0     0
VecScatterEnd         46 1.0 6.0342e-0196.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
SFSetGraph             2 1.0 5.1968e-04 1.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.1750e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  7  0  2   0  0  7  0  2     0
SFBcastOpBegin        46 1.0 3.0599e-02 2.0 0.00e+00 0.0 6.7e+03 4.6e+04 0.0e+00  0  0 78 16  0   0  0 78 16  0     0
SFBcastOpEnd          46 1.0 6.0331e-0198.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
SFPack                46 1.0 2.8922e-02 2.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack              46 1.0 3.0251e-05 1.5 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               2 1.0 3.7099e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSolve               1 1.0 1.0113e+01 1.0 6.26e+09 1.1 6.6e+03 4.6e+04 6.9e+01 26100 77 16 61  26100 77 16 65 11764
PCSetUp                2 1.0 2.6233e+00 1.1 1.27e+09 1.1 0.0e+00 0.0e+00 0.0e+00  6 20  0  0  0   6 20  0  0  0  9224
PCSetUpOnBlocks        1 1.0 2.6157e+00 1.1 1.27e+09 1.1 0.0e+00 0.0e+00 0.0e+00  6 20  0  0  0   6 20  0  0  0  9250
PCApply               46 1.0 3.6738e+00 1.1 2.40e+09 1.1 0.0e+00 0.0e+00 0.0e+00  9 38  0  0  0   9 38  0  0  0 12380
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     4              4    666933972     0.
           Index Set     7              7      5403804     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    16             16     38003880     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     2              2         3016     0.
      Preconditioner     2              2         1944     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 2.87e-08
Average time for MPI_Barrier(): 4.6026e-06
Average time for zero size MPI_Send(): 3.25935e-06
#PETSc Option Table entries:
-d 3
-ksp_type cgs
-log_view
-mat_type aij
-n 100
-pc_type bjacobi
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type cgs -pc_type jacobi -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 16:25:33 2020            |
| OS:             Linux                               |
| HostName:       sdumont6171                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.87315, Active time=2.90607                                       |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.4009      0.000008    0.4009      0.000008    13.79    13.79    |
| Ke                            50792      1.7711      0.000035    1.7711      0.000035    60.94    60.94    |
| elem init                     50792      0.7341      0.000014    0.7341      0.000014    25.26    25.26    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.9061                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 904.323168
Tempo total: 904.257966
Tempo total: 904.232493
Tempo total: 904.252892
Tempo total: 904.271554
Tempo total: 904.256903
Tempo total: 904.278125
Tempo total: 904.239396
Tempo total: 904.224341
Tempo total: 904.240991
Tempo total: 904.245505
Tempo total: 904.236720
Tempo total: 904.213514
Tempo total: 904.230065
Tempo total: 904.215594
Tempo total: 904.232357
Tempo total: 904.263829
Tempo total: 904.229970
Tempo total: 904.253444
Tempo total: 904.295976
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6171 with 20 processors, by luciano.siqueira Thu Dec 10 16:40:10 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           9.046e+02     1.000   9.046e+02
Objects:              3.000e+01     1.000   3.000e+01
Flop:                 5.790e+11     1.100   5.526e+11  1.105e+13
Flop/sec:             6.400e+08     1.100   6.109e+08  1.222e+10
MPI Messages:         1.102e+05     2.748   7.312e+04  1.462e+06
MPI Message Lengths:  4.583e+09     1.940   4.689e+04  6.857e+10
MPI Reductions:       1.505e+04     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 9.0463e+02 100.0%  1.1052e+13 100.0%  1.462e+06 100.0%  4.689e+04      100.0%  1.504e+04 100.0%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 4.6380e-0192.2 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  0  0  0  0  0   0  0  0  0  0     0
BuildTwoSidedF         5 1.0 4.6312e-01102.0 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatMult            10002 1.0 8.1740e+02 1.1 5.34e+11 1.1 1.5e+06 4.6e+04 0.0e+00 88 92100 98  0  88 92100 98  0 12478
MatAssemblyBegin       2 1.0 5.6201e-01 3.2 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatAssemblyEnd         2 1.0 3.2657e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  0  0  0  0  0   0  0  0  0  0    13
MatZeroEntries         3 1.0 1.2268e-01 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecDot             10001 1.0 4.8709e+01 8.1 8.50e+09 1.1 0.0e+00 0.0e+00 1.0e+04  3  1  0  0 66   3  1  0  0 66  3335
VecNorm             5002 1.0 2.9235e+00 1.0 4.25e+09 1.1 0.0e+00 0.0e+00 5.0e+03  0  1  0  0 33   0  1  0  0 33 27788
VecCopy                5 1.0 3.7205e-03 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet                 5 1.0 1.7759e-03 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY            15001 1.0 1.2667e+01 1.1 1.27e+10 1.1 0.0e+00 0.0e+00 0.0e+00  1  2  0  0  0   1  2  0  0  0 19233
VecWAXPY           20000 1.0 2.5649e+01 1.1 1.49e+10 1.1 0.0e+00 0.0e+00 0.0e+00  3  3  0  0  0   3  3  0  0  0 11081
VecAssemblyBegin       3 1.0 1.3007e-02 1.5 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAssemblyEnd         3 1.0 6.1308e-04 4.6 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecPointwiseMult   10003 1.0 1.2564e+01 1.1 4.25e+09 1.1 0.0e+00 0.0e+00 0.0e+00  1  1  0  0  0   1  1  0  0  0  6466
VecScatterBegin    10003 1.0 6.7059e+00 2.2 0.00e+00 0.0 1.5e+06 4.6e+04 0.0e+00  1  0100 98  0   1  0100 98  0     0
VecScatterEnd      10003 1.0 7.8459e+0160.6 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  4  0  0  0  0   4  0  0  0  0     0
SFSetGraph             2 1.0 4.9750e-04 1.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.1218e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFBcastOpBegin     10003 1.0 6.6863e+00 2.2 0.00e+00 0.0 1.5e+06 4.6e+04 0.0e+00  1  0100 98  0   1  0100 98  0     0
SFBcastOpEnd       10003 1.0 7.8438e+0161.5 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  4  0  0  0  0   4  0  0  0  0     0
SFPack             10003 1.0 6.4971e+00 2.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack           10003 1.0 6.7009e-03 1.6 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               1 1.0 3.7009e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSolve               1 1.0 8.7509e+02 1.0 5.79e+11 1.1 1.5e+06 4.6e+04 1.5e+04 97100100 98100  97100100 98100 12630
PCSetUp                1 1.0 1.0220e-06 5.6 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
PCApply            10003 1.0 1.2657e+01 1.1 4.25e+09 1.1 0.0e+00 0.0e+00 2.0e+00  1  1  0  0  0   1  1  0  0  0  6418
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     3              3    344047400     0.
           Index Set     4              4       304416     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    15             15     41400224     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     1              1         1600     0.
      Preconditioner     1              1          968     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 2.86e-08
Average time for MPI_Barrier(): 4.959e-06
Average time for zero size MPI_Send(): 3.3672e-06
#PETSc Option Table entries:
-d 3
-ksp_type cgs
-log_view
-mat_type aij
-n 100
-pc_type jacobi
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type cgs -pc_type sor -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 16:40:40 2020            |
| OS:             Linux                               |
| HostName:       sdumont6171                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.83443, Active time=2.89037                                       |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.4037      0.000008    0.4037      0.000008    13.97    13.97    |
| Ke                            50792      1.7656      0.000035    1.7656      0.000035    61.09    61.09    |
| elem init                     50792      0.7210      0.000014    0.7210      0.000014    24.95    24.95    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.8904                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 56.679686
Tempo total: 56.659350
Tempo total: 56.668743
Tempo total: 56.679694
Tempo total: 56.659550
Tempo total: 56.636102
Tempo total: 56.641961
Tempo total: 56.625287
Tempo total: 56.641961
Tempo total: 56.660528
Tempo total: 56.643600
Tempo total: 56.661185
Tempo total: 56.637403
Tempo total: 56.651289
Tempo total: 56.633626
Tempo total: 56.651018
Tempo total: 56.633683
Tempo total: 56.651237
Tempo total: 56.690198
Tempo total: 56.635019
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6171 with 20 processors, by luciano.siqueira Thu Dec 10 16:41:09 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           5.704e+01     1.000   5.704e+01
Objects:              2.900e+01     1.000   2.900e+01
Flop:                 1.471e+10     1.106   1.398e+10  2.796e+11
Flop/sec:             2.579e+08     1.106   2.451e+08  4.902e+09
MPI Messages:         1.592e+03     2.628   1.072e+03  2.144e+04
MPI Message Lengths:  1.444e+08     1.344   1.168e+05  2.504e+09
MPI Reductions:       2.450e+02     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 5.7039e+01 100.0%  2.7962e+11 100.0%  2.144e+04 100.0%  1.168e+05      100.0%  2.380e+02  97.1%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 4.3517e-01106.5 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  0  0  2  0  3   0  0  2  0  3     0
BuildTwoSidedF         5 1.0 4.3494e-01130.7 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  0  0  2  8  2   0  0  2  8  2     0
MatMult              133 1.0 1.0947e+01 1.1 7.11e+09 1.1 1.9e+04 4.6e+04 0.0e+00 19 49 91 36  0  19 49 91 36  0 12389
MatSOR               134 1.0 1.6380e+01 1.1 7.06e+09 1.1 0.0e+00 0.0e+00 0.0e+00 27 48  0  0  0  27 48  0  0  0  8155
MatAssemblyBegin       2 1.0 5.3693e-01 4.4 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  1  0  1  8  1   1  0  1  8  1     0
MatAssemblyEnd         2 1.0 3.2544e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  1  0  1  0  2   1  0  1  0  2    13
MatZeroEntries         3 1.0 1.1968e-01 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecDot               133 1.0 2.1317e+0025.6 1.13e+08 1.1 0.0e+00 0.0e+00 1.3e+02  2  1  0  0 54   2  1  0  0 56  1013
VecNorm               68 1.0 7.5243e-02 1.9 5.78e+07 1.1 0.0e+00 0.0e+00 6.8e+01  0  0  0  0 28   0  0  0  0 29 14678
VecCopy                5 1.0 3.7592e-03 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet                 5 1.0 1.7606e-03 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY              198 1.0 1.5633e-01 1.1 1.68e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 20571
VecWAXPY             262 1.0 3.4545e-01 1.1 1.95e+08 1.1 0.0e+00 0.0e+00 0.0e+00  1  1  0  0  0   1  1  0  0  0 10766
VecAssemblyBegin       3 1.0 9.0758e-03 1.0 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  1  0  1   0  0  1  0  1     0
VecAssemblyEnd         3 1.0 5.8485e-04 4.6 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecScatterBegin      134 1.0 9.3820e-02 2.1 0.00e+00 0.0 2.0e+04 4.6e+04 0.0e+00  0  0 91 36  0   0  0 91 36  0     0
VecScatterEnd        134 1.0 1.1299e+0063.7 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
SFSetGraph             2 1.0 4.9742e-04 1.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.1143e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  3  0  1   0  0  3  0  1     0
SFBcastOpBegin       134 1.0 9.3506e-02 2.1 0.00e+00 0.0 2.0e+04 4.6e+04 0.0e+00  0  0 91 36  0   0  0 91 36  0     0
SFBcastOpEnd         134 1.0 1.1296e+0064.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
SFPack               134 1.0 8.8531e-02 2.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack             134 1.0 8.2230e-05 1.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               1 1.0 3.7187e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSolve               1 1.0 2.7734e+01 1.0 1.47e+10 1.1 1.9e+04 4.6e+04 2.0e+02 49100 91 36 82  49100 91 36 84 10074
PCSetUp                1 1.0 2.5200e-07 1.6 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
PCApply              134 1.0 1.6380e+01 1.1 7.06e+09 1.1 0.0e+00 0.0e+00 0.0e+00 27 48  0  0  0  27 48  0  0  0  8155
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     3              3    354240752     0.
           Index Set     4              4       304416     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    14             14     38000744     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     1              1         1600     0.
      Preconditioner     1              1          968     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 2.89e-08
Average time for MPI_Barrier(): 5.141e-06
Average time for zero size MPI_Send(): 3.2518e-06
#PETSc Option Table entries:
-d 3
-ksp_type cgs
-log_view
-mat_type aij
-n 100
-pc_type sor
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type cgs -pc_type mg -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 16:41:40 2020            |
| OS:             Linux                               |
| HostName:       sdumont6171                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.84563, Active time=2.88729                                       |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.3992      0.000008    0.3992      0.000008    13.83    13.83    |
| Ke                            50792      1.7567      0.000035    1.7567      0.000035    60.84    60.84    |
| elem init                     50792      0.7314      0.000014    0.7314      0.000014    25.33    25.33    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.8873                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 156.327042
Tempo total: 156.262264
Tempo total: 156.259556
Tempo total: 156.262277
Tempo total: 156.305192
Tempo total: 156.263104
Tempo total: 156.293461
Tempo total: 156.271147
Tempo total: 156.248495
Tempo total: 156.249798
Tempo total: 156.271174
Tempo total: 156.248426
Tempo total: 156.268691
Tempo total: 156.237872
Tempo total: 156.267120
Tempo total: 156.236664
Tempo total: 156.226220
Tempo total: 156.241721
Tempo total: 156.258601
Tempo total: 156.338439
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6171 with 20 processors, by luciano.siqueira Thu Dec 10 16:43:49 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           1.566e+02     1.000   1.566e+02
Objects:              5.400e+01     1.000   5.400e+01
Flop:                 6.795e+10     1.106   6.459e+10  1.292e+12
Flop/sec:             4.338e+08     1.106   4.123e+08  8.246e+09
MPI Messages:         6.916e+03     2.721   4.605e+03  9.210e+04
MPI Message Lengths:  3.621e+08     1.661   6.237e+04  5.744e+09
MPI Reductions:       5.230e+02     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 1.5664e+02 100.0%  1.2917e+12 100.0%  9.210e+04 100.0%  6.237e+04      100.0%  5.160e+02  98.7%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 4.8715e-0199.3 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  0  0  0  0  1   0  0  0  0  1     0
BuildTwoSidedF         5 1.0 4.8592e-01144.9 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  0  0  0  4  1   0  0  0  4  1     0
MatMult              617 1.0 5.3828e+01 1.1 3.30e+10 1.1 9.0e+04 4.6e+04 0.0e+00 33 49 98 72  0  33 49 98 72  0 11689
MatSOR               619 1.0 7.4301e+01 1.1 3.26e+10 1.1 0.0e+00 0.0e+00 0.0e+00 45 48  0  0  0  45 48  0  0  0  8305
MatAssemblyBegin       2 1.0 5.5863e-01 3.0 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  0  0  0  4  0   0  0  0  4  0     0
MatAssemblyEnd         2 1.0 3.4299e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  0  0  0  0  1   0  0  0  0  1    13
MatZeroEntries         3 1.0 1.2179e-01 1.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecDot               303 1.0 5.4549e+0027.8 2.57e+08 1.1 0.0e+00 0.0e+00 3.0e+02  2  0  0  0 58   2  0  0  0 59   902
VecMDot               10 1.0 1.5164e-01 7.0 4.67e+07 1.1 0.0e+00 0.0e+00 1.0e+01  0  0  0  0  2   0  0  0  0  2  5891
VecNorm              164 1.0 1.5238e-01 1.6 1.39e+08 1.1 0.0e+00 0.0e+00 1.6e+02  0  0  0  0 31   0  0  0  0 32 17479
VecScale              11 1.0 3.4713e-03 1.3 4.67e+06 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 25733
VecCopy              614 1.0 3.9791e-01 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet               615 1.0 1.9248e-01 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY              454 1.0 3.5019e-01 1.1 3.86e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 21056
VecAYPX              608 1.0 6.8162e-01 1.1 3.87e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 10865
VecAXPBYCZ           304 1.0 4.0725e-01 1.1 6.46e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 30309
VecWAXPY             602 1.0 7.8210e-01 1.1 4.47e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 10933
VecMAXPY              11 1.0 3.5596e-02 1.1 5.52e+07 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 29657
VecAssemblyBegin       3 1.0 9.6748e-03 1.0 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  0  0  1   0  0  0  0  1     0
VecAssemblyEnd         3 1.0 6.0926e-04 4.6 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecScatterBegin      618 1.0 3.9669e-01 2.0 0.00e+00 0.0 9.0e+04 4.6e+04 0.0e+00  0  0 98 72  0   0  0 98 72  0     0
VecScatterEnd        618 1.0 8.6929e+0074.8 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  2  0  0  0  0   2  0  0  0  0     0
VecNormalize          11 1.0 3.5373e-02 3.5 1.40e+07 1.1 0.0e+00 0.0e+00 1.1e+01  0  0  0  0  2   0  0  0  0  2  7576
SFSetGraph             2 1.0 5.1886e-04 2.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.1682e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  1  0  0   0  0  1  0  0     0
SFBcastOpBegin       618 1.0 3.9522e-01 2.1 0.00e+00 0.0 9.0e+04 4.6e+04 0.0e+00  0  0 98 72  0   0  0 98 72  0     0
SFBcastOpEnd         618 1.0 8.6916e+0075.7 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  2  0  0  0  0   2  0  0  0  0     0
SFPack               618 1.0 3.8068e-01 2.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack             618 1.0 4.1119e-04 1.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               2 1.0 2.3266e+00 1.0 1.23e+09 1.1 1.5e+03 4.6e+04 2.3e+01  1  2  2  1  4   1  2  2  1  4 10059
KSPSolve               1 1.0 1.2704e+02 1.0 6.79e+10 1.1 9.0e+04 4.6e+04 4.8e+02 81100 98 72 92  81100 98 72 93 10166
KSPGMRESOrthog        10 1.0 1.7956e-01 3.5 9.34e+07 1.1 0.0e+00 0.0e+00 1.0e+01  0  0  0  0  2   0  0  0  0  2  9949
PCSetUp                1 1.0 2.3233e+00 1.0 1.23e+09 1.1 1.5e+03 4.6e+04 2.3e+01  1  2  2  1  4   1  2  2  1  4 10074
PCApply              315 1.0 1.0036e+02 1.1 4.99e+10 1.1 4.4e+04 4.6e+04 0.0e+00 63 73 48 35  0  63 73 48 35  0  9434
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     3              3    354240752     0.
           Index Set     4              4       304416     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    33             33    102590864     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     4              4        35144     0.
      Preconditioner     4              4         4256     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 2.89e-08
Average time for MPI_Barrier(): 4.9296e-06
Average time for zero size MPI_Send(): 3.32375e-06
#PETSc Option Table entries:
-d 3
-ksp_type cgs
-log_view
-mat_type aij
-n 100
-pc_type mg
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type bcgs -pc_type bjacobi -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 16:44:19 2020            |
| OS:             Linux                               |
| HostName:       sdumont6171                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.82708, Active time=2.87398                                       |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.3966      0.000008    0.3966      0.000008    13.80    13.80    |
| Ke                            50792      1.7539      0.000035    1.7539      0.000035    61.03    61.03    |
| elem init                     50792      0.7235      0.000014    0.7235      0.000014    25.17    25.17    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.8740                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 116.537036
Tempo total: 116.523993
Tempo total: 116.570583
Tempo total: 116.517911
Tempo total: 116.539165
Tempo total: 116.498185
Tempo total: 116.469877
Tempo total: 116.483603
Tempo total: 116.505029
Tempo total: 116.489739
Tempo total: 116.510233
Tempo total: 116.489725
Tempo total: 116.498993
Tempo total: 116.479347
Tempo total: 116.500520
Tempo total: 116.477124
Tempo total: 116.467038
Tempo total: 116.473553
Tempo total: 116.502289
Tempo total: 116.589037
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6171 with 20 processors, by luciano.siqueira Thu Dec 10 16:45:48 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           1.169e+02     1.000   1.169e+02
Objects:              3.600e+01     1.000   3.600e+01
Flop:                 5.839e+10     1.106   5.550e+10  1.110e+12
Flop/sec:             4.995e+08     1.106   4.748e+08  9.496e+09
MPI Messages:         5.816e+03     2.715   3.875e+03  7.750e+04
MPI Message Lengths:  3.171e+08     1.625   6.548e+04  5.075e+09
MPI Reductions:       1.078e+03     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 1.1688e+02 100.0%  1.1099e+12 100.0%  7.750e+04 100.0%  6.548e+04      100.0%  1.071e+03  99.4%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 4.3572e-01132.1 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  0  0  1  0  1   0  0  1  0  1     0
BuildTwoSidedF         5 1.0 4.3663e-01157.2 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  0  0  0  4  0   0  0  0  4  0     0
MatMult              517 1.0 4.2208e+01 1.1 2.76e+10 1.1 7.5e+04 4.6e+04 0.0e+00 35 47 97 68  0  35 47 97 68  0 12490
MatSolve             518 1.0 4.1158e+01 1.1 2.71e+10 1.1 0.0e+00 0.0e+00 0.0e+00 33 46  0  0  0  33 46  0  0  0 12444
MatLUFactorNum         1 1.0 2.4493e+00 1.1 1.27e+09 1.1 0.0e+00 0.0e+00 0.0e+00  2  2  0  0  0   2  2  0  0  0  9879
MatILUFactorSym        1 1.0 1.5334e-01 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatAssemblyBegin       2 1.0 5.5422e-01 2.9 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  0  0  0  4  0   0  0  0  4  0     0
MatAssemblyEnd         2 1.0 3.1052e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  0  0  0  0  0   0  0  0  0  0    14
MatGetRowIJ            1 1.0 3.8750e-06 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatGetOrdering         1 1.0 4.1605e-03 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatZeroEntries         3 1.0 1.2272e-01 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecDot               516 1.0 2.7794e+00 7.8 4.38e+08 1.1 0.0e+00 0.0e+00 5.2e+02  1  1  0  0 48   1  1  0  0 48  3015
VecDotNorm2          258 1.0 2.7756e+00 7.5 4.38e+08 1.1 0.0e+00 0.0e+00 2.6e+02  1  1  0  0 24   1  1  0  0 24  3019
VecNorm              260 1.0 2.8883e-01 1.9 2.21e+08 1.1 0.0e+00 0.0e+00 2.6e+02  0  0  0  0 24   0  0  0  0 24 14620
VecCopy                3 1.0 2.2055e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet               525 1.0 2.4356e-01 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY                1 1.0 5.3854e-04 1.3 8.49e+05 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 30158
VecAXPBYCZ           516 1.0 7.2080e-01 1.1 8.77e+08 1.1 0.0e+00 0.0e+00 0.0e+00  1  2  0  0  0   1  2  0  0  0 23253
VecWAXPY             516 1.0 6.3310e-01 1.1 4.38e+08 1.1 0.0e+00 0.0e+00 0.0e+00  1  1  0  0  0   1  1  0  0  0 13237
VecAssemblyBegin       3 1.0 8.5574e-03 1.0 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAssemblyEnd         3 1.0 5.5152e-04 4.6 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecScatterBegin      518 1.0 3.5476e-01 2.1 0.00e+00 0.0 7.6e+04 4.6e+04 0.0e+00  0  0 98 68  0   0  0 98 68  0     0
VecScatterEnd        518 1.0 4.2317e+0063.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  2  0  0  0  0   2  0  0  0  0     0
SFSetGraph             2 1.0 4.9225e-04 1.8 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.0815e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  1  0  0   0  0  1  0  0     0
SFBcastOpBegin       518 1.0 3.5352e-01 2.1 0.00e+00 0.0 7.6e+04 4.6e+04 0.0e+00  0  0 98 68  0   0  0 98 68  0     0
SFBcastOpEnd         518 1.0 4.2307e+0064.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  2  0  0  0  0   2  0  0  0  0     0
SFPack               518 1.0 3.4257e-01 2.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack             518 1.0 3.3979e-04 1.5 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               2 1.0 3.1625e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSolve               1 1.0 8.7611e+01 1.0 5.84e+10 1.1 7.5e+04 4.6e+04 1.0e+03 75100 97 68 96  75100 97 68 97 12666
PCSetUp                2 1.0 2.6145e+00 1.1 1.27e+09 1.1 0.0e+00 0.0e+00 0.0e+00  2  2  0  0  0   2  2  0  0  0  9255
PCSetUpOnBlocks        1 1.0 2.6068e+00 1.1 1.27e+09 1.1 0.0e+00 0.0e+00 0.0e+00  2  2  0  0  0   2  2  0  0  0  9282
PCApply              518 1.0 4.1405e+01 1.1 2.71e+10 1.1 0.0e+00 0.0e+00 0.0e+00 34 46  0  0  0  34 46  0  0  0 12369
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     4              4    666933972     0.
           Index Set     7              7      5403804     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    15             15     34604400     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     2              2         3024     0.
      Preconditioner     2              2         1944     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 2.82e-08
Average time for MPI_Barrier(): 5.0978e-06
Average time for zero size MPI_Send(): 3.32115e-06
#PETSc Option Table entries:
-d 3
-ksp_type bcgs
-log_view
-mat_type aij
-n 100
-pc_type bjacobi
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type bcgs -pc_type jacobi -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 16:46:19 2020            |
| OS:             Linux                               |
| HostName:       sdumont6171                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.8386, Active time=2.88006                                        |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.3984      0.000008    0.3984      0.000008    13.83    13.83    |
| Ke                            50792      1.7547      0.000035    1.7547      0.000035    60.93    60.93    |
| elem init                     50792      0.7270      0.000014    0.7270      0.000014    25.24    25.24    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.8801                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 63.619765
Tempo total: 63.579239
Tempo total: 63.595211
Tempo total: 63.584452
Tempo total: 63.583107
Tempo total: 63.574799
Tempo total: 63.571204
Tempo total: 63.573527
Tempo total: 63.570270
Tempo total: 63.547979
Tempo total: 63.529784
Tempo total: 63.566414
Tempo total: 63.567425
Tempo total: 63.547789
Tempo total: 63.565813
Tempo total: 63.543712
Tempo total: 63.566598
Tempo total: 63.546524
Tempo total: 63.531636
Tempo total: 63.609232
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6171 with 20 processors, by luciano.siqueira Thu Dec 10 16:46:55 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           6.397e+01     1.000   6.397e+01
Objects:              2.900e+01     1.000   2.900e+01
Flop:                 2.301e+10     1.100   2.196e+10  4.392e+11
Flop/sec:             3.597e+08     1.100   3.433e+08  6.867e+09
MPI Messages:         4.452e+03     2.705   2.970e+03  5.940e+04
MPI Message Lengths:  2.614e+08     1.566   7.146e+04  4.245e+09
MPI Reductions:       8.320e+02     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 6.3966e+01 100.0%  4.3923e+11 100.0%  5.940e+04 100.0%  7.146e+04      100.0%  8.250e+02  99.2%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 4.6491e-01114.1 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  0  0  1  0  1   0  0  1  0  1     0
BuildTwoSidedF         5 1.0 4.6329e-01131.1 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  0  0  1  5  1   0  0  1  5  1     0
MatMult              393 1.0 3.2256e+01 1.1 2.10e+10 1.1 5.7e+04 4.6e+04 0.0e+00 49 91 97 62  0  49 91 97 62  0 12424
MatAssemblyBegin       2 1.0 5.5996e-01 2.9 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  1  0  0  5  0   1  0  0  5  0     0
MatAssemblyEnd         2 1.0 3.3632e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  1  0  0  0  1   1  0  0  0  1    13
MatZeroEntries         3 1.0 1.2296e-01 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecDot               392 1.0 1.1589e+00 4.5 3.33e+08 1.1 0.0e+00 0.0e+00 3.9e+02  1  1  0  0 47   1  1  0  0 48  5494
VecDotNorm2          196 1.0 1.1638e+00 4.3 3.33e+08 1.1 0.0e+00 0.0e+00 2.0e+02  1  1  0  0 24   1  1  0  0 24  5470
VecNorm              198 1.0 1.8976e-01 1.7 1.68e+08 1.1 0.0e+00 0.0e+00 2.0e+02  0  1  0  0 24   0  1  0  0 24 16946
VecCopy                3 1.0 2.1896e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet                 7 1.0 2.8195e-03 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY                1 1.0 5.2906e-04 1.2 8.49e+05 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 30698
VecAXPBYCZ           392 1.0 5.4187e-01 1.1 6.66e+08 1.1 0.0e+00 0.0e+00 0.0e+00  1  3  0  0  0   1  3  0  0  0 23498
VecWAXPY             392 1.0 5.1714e-01 1.1 3.33e+08 1.1 0.0e+00 0.0e+00 0.0e+00  1  1  0  0  0   1  1  0  0  0 12311
VecAssemblyBegin       3 1.0 9.0494e-03 1.0 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAssemblyEnd         3 1.0 6.0105e-04 4.6 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecPointwiseMult     394 1.0 4.9056e-01 1.1 1.67e+08 1.1 0.0e+00 0.0e+00 0.0e+00  1  1  0  0  0   1  1  0  0  0  6522
VecScatterBegin      394 1.0 2.6751e-01 2.1 0.00e+00 0.0 5.8e+04 4.6e+04 0.0e+00  0  0 97 62  0   0  0 97 62  0     0
VecScatterEnd        394 1.0 3.2129e+0062.5 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  2  0  0  0  0   2  0  0  0  0     0
SFSetGraph             2 1.0 4.9681e-04 1.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.1381e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  1  0  0   0  0  1  0  0     0
SFBcastOpBegin       394 1.0 2.6680e-01 2.1 0.00e+00 0.0 5.8e+04 4.6e+04 0.0e+00  0  0 97 62  0   0  0 97 62  0     0
SFBcastOpEnd         394 1.0 3.2121e+0063.5 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  2  0  0  0  0   2  0  0  0  0     0
SFPack               394 1.0 2.5725e-01 2.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack             394 1.0 2.5027e-04 1.5 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               1 1.0 3.1618e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSolve               1 1.0 3.4473e+01 1.0 2.30e+10 1.1 5.7e+04 4.6e+04 7.9e+02 54100 97 62 95  54100 97 62 96 12735
PCSetUp                1 1.0 7.1500e-07 2.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
PCApply              394 1.0 5.6449e-01 1.1 1.67e+08 1.1 0.0e+00 0.0e+00 2.0e+00  1  1  0  0  0   1  1  0  0  0  5668
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     3              3    344047400     0.
           Index Set     4              4       304416     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    14             14     38000744     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     1              1         1608     0.
      Preconditioner     1              1          968     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 2.95e-08
Average time for MPI_Barrier(): 5.0216e-06
Average time for zero size MPI_Send(): 3.3744e-06
#PETSc Option Table entries:
-d 3
-ksp_type bcgs
-log_view
-mat_type aij
-n 100
-pc_type jacobi
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type bcgs -pc_type sor -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 16:47:26 2020            |
| OS:             Linux                               |
| HostName:       sdumont6171                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.87798, Active time=2.89243                                       |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.4014      0.000008    0.4014      0.000008    13.88    13.88    |
| Ke                            50792      1.7639      0.000035    1.7639      0.000035    60.98    60.98    |
| elem init                     50792      0.7272      0.000014    0.7272      0.000014    25.14    25.14    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.8924                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 152.629550
Tempo total: 152.662278
Tempo total: 152.669525
Tempo total: 152.625837
Tempo total: 152.680199
Tempo total: 152.614590
Tempo total: 152.674064
Tempo total: 152.621964
Tempo total: 152.594472
Tempo total: 152.624300
Tempo total: 152.616079
Tempo total: 152.606208
Tempo total: 152.609751
Tempo total: 152.613696
Tempo total: 152.623485
Tempo total: 152.608180
Tempo total: 152.624128
Tempo total: 152.613905
Tempo total: 152.621703
Tempo total: 152.744244
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6171 with 20 processors, by luciano.siqueira Thu Dec 10 16:49:31 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           1.530e+02     1.000   1.530e+02
Objects:              2.800e+01     1.000   2.800e+01
Flop:                 6.708e+10     1.106   6.376e+10  1.275e+12
Flop/sec:             4.384e+08     1.106   4.167e+08  8.335e+09
MPI Messages:         6.784e+03     2.720   4.517e+03  9.035e+04
MPI Message Lengths:  3.567e+08     1.657   6.269e+04  5.664e+09
MPI Reductions:       1.254e+03     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 1.5300e+02 100.0%  1.2752e+12 100.0%  9.035e+04 100.0%  6.269e+04      100.0%  1.247e+03  99.4%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 4.4351e-0192.4 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  0  0  0  0  1   0  0  0  0  1     0
BuildTwoSidedF         5 1.0 4.4200e-01103.4 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  0  0  0  4  0   0  0  0  4  0     0
MatMult              605 1.0 4.9426e+01 1.1 3.23e+10 1.1 8.8e+04 4.6e+04 0.0e+00 32 48 98 72  0  32 48 98 72  0 12482
MatSOR               606 1.0 7.2523e+01 1.1 3.19e+10 1.1 0.0e+00 0.0e+00 0.0e+00 45 47  0  0  0  45 47  0  0  0  8330
MatAssemblyBegin       2 1.0 5.4446e-01 3.6 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  0  0  0  4  0   0  0  0  4  0     0
MatAssemblyEnd         2 1.0 3.4551e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  0  0  0  0  0   0  0  0  0  0    12
MatZeroEntries         3 1.0 1.2231e-01 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecDot               604 1.0 4.2081e+0010.5 5.13e+08 1.1 0.0e+00 0.0e+00 6.0e+02  2  1  0  0 48   2  1  0  0 48  2331
VecDotNorm2          302 1.0 4.2543e+00 9.8 5.13e+08 1.1 0.0e+00 0.0e+00 3.0e+02  2  1  0  0 24   2  1  0  0 24  2306
VecNorm              304 1.0 2.7718e-01 1.5 2.58e+08 1.1 0.0e+00 0.0e+00 3.0e+02  0  0  0  0 24   0  0  0  0 24 17813
VecCopy                3 1.0 2.2792e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet                 7 1.0 2.8300e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY                1 1.0 5.8604e-04 1.4 8.49e+05 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 27713
VecAXPBYCZ           604 1.0 8.4153e-01 1.1 1.03e+09 1.1 0.0e+00 0.0e+00 0.0e+00  1  2  0  0  0   1  2  0  0  0 23314
VecWAXPY             604 1.0 7.7666e-01 1.1 5.13e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 12631
VecAssemblyBegin       3 1.0 9.6876e-03 1.0 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAssemblyEnd         3 1.0 5.6666e-04 4.7 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecScatterBegin      606 1.0 4.1779e-01 2.1 0.00e+00 0.0 8.8e+04 4.6e+04 0.0e+00  0  0 98 72  0   0  0 98 72  0     0
VecScatterEnd        606 1.0 4.6700e+0057.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
SFSetGraph             2 1.0 5.1629e-04 1.8 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.1760e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  1  0  0   0  0  1  0  0     0
SFBcastOpBegin       606 1.0 4.1667e-01 2.1 0.00e+00 0.0 8.8e+04 4.6e+04 0.0e+00  0  0 98 72  0   0  0 98 72  0     0
SFBcastOpEnd         606 1.0 4.6687e+0057.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
SFPack               606 1.0 4.0301e-01 2.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack             606 1.0 4.0716e-04 1.6 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               1 1.0 3.1812e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSolve               1 1.0 1.2364e+02 1.0 6.71e+10 1.1 8.8e+04 4.6e+04 1.2e+03 81100 98 72 96  81100 98 72 97 10313
PCSetUp                1 1.0 5.5800e-07 3.6 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
PCApply              606 1.0 7.2524e+01 1.1 3.19e+10 1.1 0.0e+00 0.0e+00 0.0e+00 45 47  0  0  0  45 47  0  0  0  8330
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     3              3    354240752     0.
           Index Set     4              4       304416     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    13             13     34601264     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     1              1         1608     0.
      Preconditioner     1              1          968     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 2.87e-08
Average time for MPI_Barrier(): 5.4242e-06
Average time for zero size MPI_Send(): 3.32225e-06
#PETSc Option Table entries:
-d 3
-ksp_type bcgs
-log_view
-mat_type aij
-n 100
-pc_type sor
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type bcgs -pc_type mg -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 16:50:01 2020            |
| OS:             Linux                               |
| HostName:       sdumont6171                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.82608, Active time=2.88484                                       |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.3980      0.000008    0.3980      0.000008    13.80    13.80    |
| Ke                            50792      1.7629      0.000035    1.7629      0.000035    61.11    61.11    |
| elem init                     50792      0.7239      0.000014    0.7239      0.000014    25.09    25.09    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.8848                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 168.526931
Tempo total: 168.532885
Tempo total: 168.533911
Tempo total: 168.515669
Tempo total: 168.535565
Tempo total: 168.509739
Tempo total: 168.527654
Tempo total: 168.508742
Tempo total: 168.486353
Tempo total: 168.503568
Tempo total: 168.526895
Tempo total: 168.504104
Tempo total: 168.525535
Tempo total: 168.493658
Tempo total: 168.515868
Tempo total: 168.494924
Tempo total: 168.475479
Tempo total: 168.483905
Tempo total: 168.515489
Tempo total: 168.525774
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6171 with 20 processors, by luciano.siqueira Thu Dec 10 16:52:22 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           1.689e+02     1.000   1.689e+02
Objects:              5.300e+01     1.000   5.300e+01
Flop:                 7.387e+10     1.106   7.022e+10  1.404e+12
Flop/sec:             4.374e+08     1.106   4.157e+08  8.315e+09
MPI Messages:         7.488e+03     2.723   4.985e+03  9.969e+04
MPI Message Lengths:  3.855e+08     1.677   6.111e+04  6.092e+09
MPI Reductions:       7.250e+02     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 1.6890e+02 100.0%  1.4043e+12 100.0%  9.969e+04 100.0%  6.111e+04      100.0%  7.180e+02  99.0%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 4.3170e-01118.4 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  0  0  0  0  1   0  0  0  0  1     0
BuildTwoSidedF         5 1.0 4.2942e-01130.4 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  0  0  0  3  1   0  0  0  3  1     0
MatMult              669 1.0 5.9501e+01 1.1 3.57e+10 1.1 9.8e+04 4.6e+04 0.0e+00 33 49 98 74  0  33 49 98 74  0 11465
MatSOR               671 1.0 8.2085e+01 1.1 3.53e+10 1.1 0.0e+00 0.0e+00 0.0e+00 45 48  0  0  0  45 48  0  0  0  8149
MatAssemblyBegin       2 1.0 5.5558e-01 5.9 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  0  0  0  3  0   0  0  0  3  0     0
MatAssemblyEnd         2 1.0 3.2489e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  0  0  0  0  1   0  0  0  0  1    13
MatZeroEntries         3 1.0 1.2088e-01 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecDot               328 1.0 3.8305e+0014.1 2.79e+08 1.1 0.0e+00 0.0e+00 3.3e+02  1  0  0  0 45   1  0  0  0 46  1391
VecDotNorm2          164 1.0 3.8585e+0013.8 2.79e+08 1.1 0.0e+00 0.0e+00 1.6e+02  1  0  0  0 23   1  0  0  0 23  1381
VecMDot               10 1.0 1.8087e-01 8.5 4.67e+07 1.1 0.0e+00 0.0e+00 1.0e+01  0  0  0  0  1   0  0  0  0  1  4939
VecNorm              177 1.0 2.0004e-01 1.8 1.50e+08 1.1 0.0e+00 0.0e+00 1.8e+02  0  0  0  0 24   0  0  0  0 25 14371
VecScale              11 1.0 3.4915e-03 1.3 4.67e+06 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 25584
VecCopy              664 1.0 4.3013e-01 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet               669 1.0 2.0364e-01 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY                2 1.0 1.4342e-03 1.2 1.70e+06 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 22648
VecAYPX              660 1.0 7.4365e-01 1.1 4.20e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 10811
VecAXPBYCZ           658 1.0 9.0142e-01 1.1 1.26e+09 1.1 0.0e+00 0.0e+00 0.0e+00  1  2  0  0  0   1  2  0  0  0 26684
VecWAXPY             328 1.0 4.0711e-01 1.1 2.79e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 13085
VecMAXPY              11 1.0 3.5717e-02 1.1 5.52e+07 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 29556
VecAssemblyBegin       3 1.0 9.0733e-03 1.0 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAssemblyEnd         3 1.0 5.5612e-04 4.6 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecScatterBegin      670 1.0 4.3177e-01 2.0 0.00e+00 0.0 9.8e+04 4.6e+04 0.0e+00  0  0 98 74  0   0  0 98 74  0     0
VecScatterEnd        670 1.0 1.0523e+0141.7 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  3  0  0  0  0   3  0  0  0  0     0
VecNormalize          11 1.0 3.2272e-02 3.4 1.40e+07 1.1 0.0e+00 0.0e+00 1.1e+01  0  0  0  0  2   0  0  0  0  2  8304
SFSetGraph             2 1.0 5.0118e-04 1.8 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.1147e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  1  0  0   0  0  1  0  0     0
SFBcastOpBegin       670 1.0 4.3032e-01 2.1 0.00e+00 0.0 9.8e+04 4.6e+04 0.0e+00  0  0 98 74  0   0  0 98 74  0     0
SFBcastOpEnd         670 1.0 1.0521e+0141.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  3  0  0  0  0   3  0  0  0  0     0
SFPack               670 1.0 4.1427e-01 2.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack             670 1.0 4.3420e-04 1.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               2 1.0 2.3533e+00 1.0 1.23e+09 1.1 1.5e+03 4.6e+04 2.3e+01  1  2  1  1  3   1  2  1  1  3  9945
KSPSolve               1 1.0 1.3967e+02 1.0 7.39e+10 1.1 9.8e+04 4.6e+04 6.8e+02 83100 98 74 94  83100 98 74 95 10053
KSPGMRESOrthog        10 1.0 2.0881e-01 4.1 9.34e+07 1.1 0.0e+00 0.0e+00 1.0e+01  0  0  0  0  1   0  0  0  0  1  8556
PCSetUp                1 1.0 2.3505e+00 1.0 1.23e+09 1.1 1.5e+03 4.6e+04 2.3e+01  1  2  1  1  3   1  2  1  1  3  9957
PCApply              341 1.0 1.1063e+02 1.1 5.41e+10 1.1 4.8e+04 4.6e+04 0.0e+00 63 73 48 36  0  63 73 48 36  0  9282
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     3              3    354240752     0.
           Index Set     4              4       304416     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    32             32     99191384     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     4              4        35152     0.
      Preconditioner     4              4         4256     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 2.88e-08
Average time for MPI_Barrier(): 5.0982e-06
Average time for zero size MPI_Send(): 3.61475e-06
#PETSc Option Table entries:
-d 3
-ksp_type bcgs
-log_view
-mat_type aij
-n 100
-pc_type mg
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type tfqmr -pc_type bjacobi -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 16:52:53 2020            |
| OS:             Linux                               |
| HostName:       sdumont6171                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.86294, Active time=2.88267                                       |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.3979      0.000008    0.3979      0.000008    13.80    13.80    |
| Ke                            50792      1.7606      0.000035    1.7606      0.000035    61.08    61.08    |
| elem init                     50792      0.7241      0.000014    0.7241      0.000014    25.12    25.12    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.8827                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 115.186124
Tempo total: 115.113341
Tempo total: 115.074997
Tempo total: 115.081718
Tempo total: 115.106938
Tempo total: 115.080975
Tempo total: 115.048665
Tempo total: 115.070782
Tempo total: 115.106484
Tempo total: 115.062621
Tempo total: 115.048094
Tempo total: 115.064127
Tempo total: 115.078190
Tempo total: 115.058688
Tempo total: 115.077710
Tempo total: 115.059774
Tempo total: 115.077217
Tempo total: 115.058323
Tempo total: 115.068972
Tempo total: 115.113439
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6171 with 20 processors, by luciano.siqueira Thu Dec 10 16:54:20 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           1.155e+02     1.000   1.155e+02
Objects:              3.900e+01     1.000   3.900e+01
Flop:                 5.694e+10     1.106   5.412e+10  1.082e+12
Flop/sec:             4.931e+08     1.106   4.687e+08  9.374e+09
MPI Messages:         5.640e+03     2.714   3.758e+03  7.516e+04
MPI Message Lengths:  3.099e+08     1.618   6.609e+04  4.968e+09
MPI Reductions:       7.960e+02     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 1.1546e+02 100.0%  1.0823e+12 100.0%  7.516e+04 100.0%  6.609e+04      100.0%  7.890e+02  99.1%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 4.7482e-01105.4 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  0  0  1  0  1   0  0  1  0  1     0
BuildTwoSidedF         5 1.0 4.7430e-01131.3 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  0  0  0  4  1   0  0  0  4  1     0
MatMult              501 1.0 4.0975e+01 1.1 2.68e+10 1.1 7.3e+04 4.6e+04 0.0e+00 35 47 97 68  0  35 47 97 68  0 12468
MatSolve             502 1.0 3.9931e+01 1.1 2.62e+10 1.1 0.0e+00 0.0e+00 0.0e+00 33 46  0  0  0  33 46  0  0  0 12430
MatLUFactorNum         1 1.0 2.4511e+00 1.1 1.27e+09 1.1 0.0e+00 0.0e+00 0.0e+00  2  2  0  0  0   2  2  0  0  0  9872
MatILUFactorSym        1 1.0 1.5392e-01 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatAssemblyBegin       2 1.0 5.5705e-01 2.9 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  0  0  0  4  0   0  0  0  4  0     0
MatAssemblyEnd         2 1.0 3.2657e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  0  0  0  0  1   0  0  0  0  1    13
MatGetRowIJ            1 1.0 3.7370e-06 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatGetOrdering         1 1.0 4.3006e-03 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatZeroEntries         3 1.0 1.2262e-01 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecDot               500 1.0 2.7882e+00 8.7 4.25e+08 1.1 0.0e+00 0.0e+00 5.0e+02  1  1  0  0 63   1  1  0  0 63  2912
VecNorm              252 1.0 2.6728e+0018.7 2.14e+08 1.1 0.0e+00 0.0e+00 2.5e+02  1  0  0  0 32   1  0  0  0 32  1531
VecCopy                6 1.0 4.4726e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet               508 1.0 2.3178e-01 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY              999 1.0 8.3401e-01 1.1 8.49e+08 1.1 0.0e+00 0.0e+00 0.0e+00  1  1  0  0  0   1  1  0  0  0 19454
VecAYPX              499 1.0 5.7921e-01 1.1 4.23e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 13964
VecWAXPY             998 1.0 1.2899e+00 1.1 7.42e+08 1.1 0.0e+00 0.0e+00 0.0e+00  1  1  0  0  0   1  1  0  0  0 10992
VecAssemblyBegin       3 1.0 9.2367e-03 1.0 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAssemblyEnd         3 1.0 6.1278e-04 4.6 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecScatterBegin      502 1.0 3.5542e-01 2.3 0.00e+00 0.0 7.3e+04 4.6e+04 0.0e+00  0  0 98 68  0   0  0 98 68  0     0
VecScatterEnd        502 1.0 4.1378e+0064.6 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  2  0  0  0  0   2  0  0  0  0     0
SFSetGraph             2 1.0 5.1213e-04 2.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.1400e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  1  0  0   0  0  1  0  0     0
SFBcastOpBegin       502 1.0 3.5422e-01 2.3 0.00e+00 0.0 7.3e+04 4.6e+04 0.0e+00  0  0 98 68  0   0  0 98 68  0     0
SFBcastOpEnd         502 1.0 4.1366e+0066.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  2  0  0  0  0   2  0  0  0  0     0
SFPack               502 1.0 3.4343e-01 2.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack             502 1.0 3.0722e-04 1.5 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               2 1.0 4.7304e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSolve               1 1.0 8.6060e+01 1.0 5.69e+10 1.1 7.3e+04 4.6e+04 7.5e+02 75100 97 68 94  75100 97 68 95 12574
PCSetUp                2 1.0 2.6169e+00 1.1 1.27e+09 1.1 0.0e+00 0.0e+00 0.0e+00  2  2  0  0  0   2  2  0  0  0  9246
PCSetUpOnBlocks        1 1.0 2.6094e+00 1.1 1.27e+09 1.1 0.0e+00 0.0e+00 0.0e+00  2  2  0  0  0   2  2  0  0  0  9273
PCApply              502 1.0 4.0167e+01 1.1 2.62e+10 1.1 0.0e+00 0.0e+00 0.0e+00 33 46  0  0  0  33 46  0  0  0 12357
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     4              4    666933972     0.
           Index Set     7              7      5403804     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    18             18     44802840     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     2              2         3016     0.
      Preconditioner     2              2         1944     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 2.88e-08
Average time for MPI_Barrier(): 5.1032e-06
Average time for zero size MPI_Send(): 3.3177e-06
#PETSc Option Table entries:
-d 3
-ksp_type tfqmr
-log_view
-mat_type aij
-n 100
-pc_type bjacobi
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type tfqmr -pc_type jacobi -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 16:54:51 2020            |
| OS:             Linux                               |
| HostName:       sdumont6171                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.87601, Active time=2.89969                                       |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.4012      0.000008    0.4012      0.000008    13.84    13.84    |
| Ke                            50792      1.7694      0.000035    1.7694      0.000035    61.02    61.02    |
| elem init                     50792      0.7291      0.000014    0.7291      0.000014    25.14    25.14    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.8997                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 920.259403
Tempo total: 920.173358
Tempo total: 920.198608
Tempo total: 920.136080
Tempo total: 920.129590
Tempo total: 920.136979
Tempo total: 920.111815
Tempo total: 920.129453
Tempo total: 920.142286
Tempo total: 920.127541
Tempo total: 920.145316
Tempo total: 920.127489
Tempo total: 920.142695
Tempo total: 920.118936
Tempo total: 920.139321
Tempo total: 920.117899
Tempo total: 920.136725
Tempo total: 920.113279
Tempo total: 920.135586
Tempo total: 920.247750
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6171 with 20 processors, by luciano.siqueira Thu Dec 10 17:09:43 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           9.206e+02     1.000   9.205e+02
Objects:              3.200e+01     1.000   3.200e+01
Flop:                 5.917e+11     1.100   5.648e+11  1.130e+13
Flop/sec:             6.428e+08     1.100   6.135e+08  1.227e+10
MPI Messages:         1.102e+05     2.748   7.312e+04  1.462e+06
MPI Message Lengths:  4.583e+09     1.940   4.689e+04  6.857e+10
MPI Reductions:       1.505e+04     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 9.2055e+02 100.0%  1.1296e+13 100.0%  1.462e+06 100.0%  4.689e+04      100.0%  1.504e+04 100.0%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 4.4297e-0135.5 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  0  0  0  0  0   0  0  0  0  0     0
BuildTwoSidedF         5 1.0 4.4154e-0158.8 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatMult            10002 1.0 8.1784e+02 1.1 5.34e+11 1.1 1.5e+06 4.6e+04 0.0e+00 87 90100 98  0  87 90100 98  0 12471
MatAssemblyBegin       2 1.0 5.4150e-01 4.2 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatAssemblyEnd         2 1.0 3.3311e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  0  0  0  0  0   0  0  0  0  0    13
MatZeroEntries         3 1.0 1.2225e-01 1.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecDot             10001 1.0 2.7450e+01 4.0 8.50e+09 1.1 0.0e+00 0.0e+00 1.0e+04  2  1  0  0 66   2  1  0  0 66  5917
VecNorm             5002 1.0 2.3155e+01 8.9 4.25e+09 1.1 0.0e+00 0.0e+00 5.0e+03  1  1  0  0 33   1  1  0  0 33  3508
VecCopy                6 1.0 4.4555e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet                 6 1.0 2.2278e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY            20001 1.0 1.7336e+01 1.1 1.70e+10 1.1 0.0e+00 0.0e+00 0.0e+00  2  3  0  0  0   2  3  0  0  0 18737
VecAYPX            10000 1.0 1.1268e+01 1.1 8.49e+09 1.1 0.0e+00 0.0e+00 0.0e+00  1  1  0  0  0   1  1  0  0  0 14412
VecWAXPY           20000 1.0 2.5687e+01 1.1 1.49e+10 1.1 0.0e+00 0.0e+00 0.0e+00  3  3  0  0  0   3  3  0  0  0 11063
VecAssemblyBegin       3 1.0 1.2993e-02 1.4 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAssemblyEnd         3 1.0 6.0492e-04 4.7 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecPointwiseMult   10003 1.0 1.2539e+01 1.1 4.25e+09 1.1 0.0e+00 0.0e+00 0.0e+00  1  1  0  0  0   1  1  0  0  0  6478
VecScatterBegin    10003 1.0 6.9057e+00 2.1 0.00e+00 0.0 1.5e+06 4.6e+04 0.0e+00  1  0100 98  0   1  0100 98  0     0
VecScatterEnd      10003 1.0 7.7566e+0155.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  4  0  0  0  0   4  0  0  0  0     0
SFSetGraph             2 1.0 5.0206e-04 1.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.1269e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFBcastOpBegin     10003 1.0 6.8862e+00 2.2 0.00e+00 0.0 1.5e+06 4.6e+04 0.0e+00  1  0100 98  0   1  0100 98  0     0
SFBcastOpEnd       10003 1.0 7.7545e+0156.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  4  0  0  0  0   4  0  0  0  0     0
SFPack             10003 1.0 6.6993e+00 2.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack           10003 1.0 7.2639e-03 1.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               1 1.0 4.7828e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSolve               1 1.0 8.9116e+02 1.0 5.92e+11 1.1 1.5e+06 4.6e+04 1.5e+04 97100100 98100  97100100 98100 12675
PCSetUp                1 1.0 7.6700e-07 4.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
PCApply            10003 1.0 1.2629e+01 1.1 4.25e+09 1.1 0.0e+00 0.0e+00 2.0e+00  1  1  0  0  0   1  1  0  0  0  6432
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     3              3    344047400     0.
           Index Set     4              4       304416     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    17             17     48199184     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     1              1         1600     0.
      Preconditioner     1              1          968     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 3.05e-08
Average time for MPI_Barrier(): 5.188e-06
Average time for zero size MPI_Send(): 3.4493e-06
#PETSc Option Table entries:
-d 3
-ksp_type tfqmr
-log_view
-mat_type aij
-n 100
-pc_type jacobi
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type tfqmr -pc_type sor -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 17:10:14 2020            |
| OS:             Linux                               |
| HostName:       sdumont6171                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.89412, Active time=2.91451                                       |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.4015      0.000008    0.4015      0.000008    13.77    13.77    |
| Ke                            50792      1.7781      0.000035    1.7781      0.000035    61.01    61.01    |
| elem init                     50792      0.7350      0.000014    0.7350      0.000014    25.22    25.22    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.9145                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 149.627007
Tempo total: 149.638155
Tempo total: 149.651971
Tempo total: 149.454514
Tempo total: 149.425588
Tempo total: 149.608394
Tempo total: 149.461887
Tempo total: 149.456471
Tempo total: 149.462235
Tempo total: 149.438015
Tempo total: 149.462360
Tempo total: 149.436082
Tempo total: 149.459241
Tempo total: 149.437083
Tempo total: 149.422669
Tempo total: 149.443572
Tempo total: 149.465806
Tempo total: 149.419036
Tempo total: 149.443800
Tempo total: 149.631144
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6171 with 20 processors, by luciano.siqueira Thu Dec 10 17:12:16 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           1.499e+02     1.000   1.499e+02
Objects:              3.100e+01     1.000   3.100e+01
Flop:                 6.501e+10     1.106   6.180e+10  1.236e+12
Flop/sec:             4.338e+08     1.106   4.123e+08  8.246e+09
MPI Messages:         6.542e+03     2.719   4.357e+03  8.714e+04
MPI Message Lengths:  3.468e+08     1.649   6.331e+04  5.516e+09
MPI Reductions:       9.190e+02     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 1.4988e+02 100.0%  1.2359e+12 100.0%  8.714e+04 100.0%  6.331e+04      100.0%  9.120e+02  99.2%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 5.1154e-0196.9 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  0  0  1  0  1   0  0  1  0  1     0
BuildTwoSidedF         5 1.0 5.0987e-01129.2 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  0  0  0  4  1   0  0  0  4  1     0
MatMult              583 1.0 4.7721e+01 1.1 3.11e+10 1.1 8.5e+04 4.6e+04 0.0e+00 31 48 98 71  0  31 48 98 71  0 12458
MatSOR               584 1.0 7.0253e+01 1.1 3.08e+10 1.1 0.0e+00 0.0e+00 0.0e+00 44 47  0  0  0  44 47  0  0  0  8287
MatAssemblyBegin       2 1.0 5.8359e-01 3.7 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  0  0  0  4  0   0  0  0  4  0     0
MatAssemblyEnd         2 1.0 3.4390e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  0  0  0  0  1   0  0  0  0  1    13
MatZeroEntries         3 1.0 1.2235e-01 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecDot               582 1.0 4.2279e+0011.2 4.94e+08 1.1 0.0e+00 0.0e+00 5.8e+02  2  1  0  0 63   2  1  0  0 64  2236
VecNorm              293 1.0 3.9703e+0023.7 2.49e+08 1.1 0.0e+00 0.0e+00 2.9e+02  1  0  0  0 32   1  0  0  0 32  1199
VecCopy                6 1.0 4.4391e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet                 6 1.0 2.2121e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY             1164 1.0 9.6847e-01 1.1 9.89e+08 1.1 0.0e+00 0.0e+00 0.0e+00  1  2  0  0  0   1  2  0  0  0 19520
VecAYPX              582 1.0 6.7790e-01 1.1 4.94e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 13920
VecWAXPY            1162 1.0 1.5046e+00 1.1 8.63e+08 1.1 0.0e+00 0.0e+00 0.0e+00  1  1  0  0  0   1  1  0  0  0 10972
VecAssemblyBegin       3 1.0 9.9792e-03 1.0 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAssemblyEnd         3 1.0 6.1487e-04 4.6 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecScatterBegin      584 1.0 3.9744e-01 2.2 0.00e+00 0.0 8.5e+04 4.6e+04 0.0e+00  0  0 98 71  0   0  0 98 71  0     0
VecScatterEnd        584 1.0 4.6576e+0049.8 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
SFSetGraph             2 1.0 5.2809e-04 2.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.2046e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  1  0  0   0  0  1  0  0     0
SFBcastOpBegin       584 1.0 3.9602e-01 2.2 0.00e+00 0.0 8.5e+04 4.6e+04 0.0e+00  0  0 98 71  0   0  0 98 71  0     0
SFBcastOpEnd         584 1.0 4.6562e+0050.5 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
SFPack               584 1.0 3.8209e-01 2.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack             584 1.0 4.9002e-04 2.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               1 1.0 4.8061e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSolve               1 1.0 1.2075e+02 1.0 6.50e+10 1.1 8.5e+04 4.6e+04 8.8e+02 81100 98 71 95  81100 98 71 96 10234
PCSetUp                1 1.0 3.1600e-07 2.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
PCApply              584 1.0 7.0254e+01 1.1 3.08e+10 1.1 0.0e+00 0.0e+00 0.0e+00 44 47  0  0  0  44 47  0  0  0  8287
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     3              3    354240752     0.
           Index Set     4              4       304416     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    16             16     44799704     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     1              1         1600     0.
      Preconditioner     1              1          968     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 3.03e-08
Average time for MPI_Barrier(): 4.7066e-06
Average time for zero size MPI_Send(): 3.2859e-06
#PETSc Option Table entries:
-d 3
-ksp_type tfqmr
-log_view
-mat_type aij
-n 100
-pc_type sor
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type tfqmr -pc_type mg -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 17:12:47 2020            |
| OS:             Linux                               |
| HostName:       sdumont6171                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.84991, Active time=2.8903                                        |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.4022      0.000008    0.4022      0.000008    13.92    13.92    |
| Ke                            50792      1.7604      0.000035    1.7604      0.000035    60.91    60.91    |
| elem init                     50792      0.7277      0.000014    0.7277      0.000014    25.18    25.18    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.8903                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 152.422398
Tempo total: 152.383098
Tempo total: 152.389244
Tempo total: 152.389904
Tempo total: 152.360904
Tempo total: 152.342289
Tempo total: 152.359636
Tempo total: 152.324745
Tempo total: 152.309512
Tempo total: 152.327976
Tempo total: 152.347708
Tempo total: 152.324368
Tempo total: 152.304071
Tempo total: 152.313251
Tempo total: 152.350712
Tempo total: 152.309262
Tempo total: 152.296364
Tempo total: 152.314536
Tempo total: 152.331772
Tempo total: 152.400074
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6171 with 20 processors, by luciano.siqueira Thu Dec 10 17:14:51 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           1.527e+02     1.000   1.527e+02
Objects:              5.600e+01     1.000   5.600e+01
Flop:                 6.613e+10     1.106   6.285e+10  1.257e+12
Flop/sec:             4.330e+08     1.106   4.115e+08  8.231e+09
MPI Messages:         6.696e+03     2.720   4.459e+03  8.918e+04
MPI Message Lengths:  3.531e+08     1.654   6.291e+04  5.610e+09
MPI Reductions:       5.070e+02     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 1.5272e+02 100.0%  1.2570e+12 100.0%  8.918e+04 100.0%  6.291e+04      100.0%  5.000e+02  98.6%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 4.5481e-01109.3 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  0  0  0  0  1   0  0  0  0  1     0
BuildTwoSidedF         5 1.0 4.5334e-01124.3 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  0  0  0  4  1   0  0  0  4  1     0
MatMult              597 1.0 5.2193e+01 1.1 3.19e+10 1.1 8.7e+04 4.6e+04 0.0e+00 32 48 98 71  0  32 48 98 71  0 11664
MatSOR               599 1.0 7.1983e+01 1.1 3.16e+10 1.1 0.0e+00 0.0e+00 0.0e+00 45 48  0  0  0  45 48  0  0  0  8295
MatAssemblyBegin       2 1.0 5.5112e-01 2.9 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  0  0  0  4  0   0  0  0  4  0     0
MatAssemblyEnd         2 1.0 3.2681e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  0  0  0  0  1   0  0  0  0  1    13
MatZeroEntries         3 1.0 1.2356e-01 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecDot               292 1.0 2.6721e+0014.0 2.48e+08 1.1 0.0e+00 0.0e+00 2.9e+02  1  0  0  0 58   1  0  0  0 58  1775
VecMDot               10 1.0 1.4821e-01 6.9 4.67e+07 1.1 0.0e+00 0.0e+00 1.0e+01  0  0  0  0  2   0  0  0  0  2  6027
VecNorm              159 1.0 2.5472e+0026.4 1.35e+08 1.1 0.0e+00 0.0e+00 1.6e+02  1  0  0  0 31   1  0  0  0 32  1014
VecScale              11 1.0 3.5244e-03 1.3 4.67e+06 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 25346
VecCopy              595 1.0 3.8413e-01 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet               596 1.0 1.8438e-01 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY              584 1.0 4.8021e-01 1.1 4.96e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 19751
VecAYPX              879 1.0 1.0022e+00 1.1 6.21e+08 1.1 0.0e+00 0.0e+00 0.0e+00  1  1  0  0  0   1  1  0  0  0 11846
VecAXPBYCZ           294 1.0 3.9878e-01 1.1 6.24e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 29935
VecWAXPY             582 1.0 7.6393e-01 1.1 4.32e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 10821
VecMAXPY              11 1.0 3.5927e-02 1.1 5.52e+07 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 29384
VecAssemblyBegin       3 1.0 9.2357e-03 1.0 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  0  0  1   0  0  0  0  1     0
VecAssemblyEnd         3 1.0 6.0961e-04 4.7 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecScatterBegin      598 1.0 3.9414e-01 2.1 0.00e+00 0.0 8.7e+04 4.6e+04 0.0e+00  0  0 98 71  0   0  0 98 71  0     0
VecScatterEnd        598 1.0 8.5793e+0079.5 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  2  0  0  0  0   2  0  0  0  0     0
VecNormalize          11 1.0 3.0117e-02 3.0 1.40e+07 1.1 0.0e+00 0.0e+00 1.1e+01  0  0  0  0  2   0  0  0  0  2  8898
SFSetGraph             2 1.0 4.9706e-04 1.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.1168e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  1  0  0   0  0  1  0  0     0
SFBcastOpBegin       598 1.0 3.9273e-01 2.1 0.00e+00 0.0 8.7e+04 4.6e+04 0.0e+00  0  0 98 71  0   0  0 98 71  0     0
SFBcastOpEnd         598 1.0 8.5779e+0080.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  2  0  0  0  0   2  0  0  0  0     0
SFPack               598 1.0 3.7904e-01 2.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack             598 1.0 4.2526e-04 1.6 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               2 1.0 2.3174e+00 1.0 1.23e+09 1.1 1.5e+03 4.6e+04 2.3e+01  2  2  2  1  5   2  2  2  1  5 10099
KSPSolve               1 1.0 1.2343e+02 1.0 6.61e+10 1.1 8.7e+04 4.6e+04 4.6e+02 81100 98 71 91  81100 98 71 93 10183
KSPGMRESOrthog        10 1.0 1.7602e-01 3.4 9.34e+07 1.1 0.0e+00 0.0e+00 1.0e+01  0  0  0  0  2   0  0  0  0  2 10149
PCSetUp                1 1.0 2.3130e+00 1.0 1.23e+09 1.1 1.5e+03 4.6e+04 2.3e+01  2  2  2  1  5   2  2  2  1  5 10118
PCApply              305 1.0 9.7138e+01 1.0 4.83e+10 1.1 4.3e+04 4.6e+04 0.0e+00 62 73 48 35  0  62 73 48 35  0  9430
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     3              3    354240752     0.
           Index Set     4              4       304416     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    35             35    109389824     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     4              4        35144     0.
      Preconditioner     4              4         4256     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 2.9e-08
Average time for MPI_Barrier(): 4.9544e-06
Average time for zero size MPI_Send(): 3.3195e-06
#PETSc Option Table entries:
-d 3
-ksp_type tfqmr
-log_view
-mat_type aij
-n 100
-pc_type mg
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type cr -pc_type bjacobi -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 17:15:22 2020            |
| OS:             Linux                               |
| HostName:       sdumont6171                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.86624, Active time=2.89935                                       |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.4011      0.000008    0.4011      0.000008    13.83    13.83    |
| Ke                            50792      1.7687      0.000035    1.7687      0.000035    61.00    61.00    |
| elem init                     50792      0.7296      0.000014    0.7296      0.000014    25.16    25.16    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.8994                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 97.417926
Tempo total: 97.395567
Tempo total: 97.359470
Tempo total: 97.315584
Tempo total: 97.339692
Tempo total: 97.314270
Tempo total: 97.340702
Tempo total: 97.317259
Tempo total: 97.292616
Tempo total: 97.294230
Tempo total: 97.291864
Tempo total: 97.294101
Tempo total: 97.315620
Tempo total: 97.297270
Tempo total: 97.317404
Tempo total: 97.293621
Tempo total: 97.280061
Tempo total: 97.287841
Tempo total: 97.280760
Tempo total: 97.402839
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6171 with 20 processors, by luciano.siqueira Thu Dec 10 17:16:32 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           9.771e+01     1.000   9.771e+01
Objects:              3.600e+01     1.000   3.600e+01
Flop:                 4.537e+10     1.106   4.312e+10  8.624e+11
Flop/sec:             4.643e+08     1.106   4.413e+08  8.827e+09
MPI Messages:         4.474e+03     2.705   2.984e+03  5.969e+04
MPI Message Lengths:  2.623e+08     1.567   7.134e+04  4.258e+09
MPI Reductions:       8.320e+02     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 9.7708e+01 100.0%  8.6245e+11 100.0%  5.969e+04 100.0%  7.134e+04      100.0%  8.250e+02  99.2%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 5.3255e-0145.7 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  0  0  1  0  1   0  0  1  0  1     0
BuildTwoSidedF         5 1.0 5.3098e-0183.4 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  0  0  1  5  1   0  0  1  5  1     0
MatMult              395 1.0 3.2361e+01 1.1 2.11e+10 1.1 5.8e+04 4.6e+04 0.0e+00 33 47 97 62  0  33 47 97 62  0 12447
MatSolve             395 1.0 3.1404e+01 1.1 2.06e+10 1.1 0.0e+00 0.0e+00 0.0e+00 30 45  0  0  0  30 45  0  0  0 12436
MatLUFactorNum         1 1.0 2.4456e+00 1.1 1.27e+09 1.1 0.0e+00 0.0e+00 0.0e+00  2  3  0  0  0   2  3  0  0  0  9894
MatILUFactorSym        1 1.0 1.5358e-01 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatAssemblyBegin       2 1.0 6.2790e-01 4.6 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  0  0  0  5  0   0  0  0  5  0     0
MatAssemblyEnd         2 1.0 3.4281e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  0  0  0  0  1   0  0  0  0  1    13
MatGetRowIJ            1 1.0 4.0260e-06 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatGetOrdering         1 1.0 4.2104e-03 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatZeroEntries         3 1.0 1.2348e-01 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecDot               393 1.0 3.4433e+0013.3 3.34e+08 1.1 0.0e+00 0.0e+00 3.9e+02  2  1  0  0 47   2  1  0  0 48  1854
VecNorm                1 1.0 8.4883e-0315.0 8.49e+05 1.1 0.0e+00 0.0e+00 1.0e+00  0  0  0  0  0   0  0  0  0  0  1913
VecCopy                3 1.0 2.1188e-03 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet               400 1.0 2.0170e-01 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY              786 1.0 6.8887e-01 1.1 6.68e+08 1.1 0.0e+00 0.0e+00 0.0e+00  1  1  0  0  0   1  1  0  0  0 18531
VecAYPX              785 1.0 8.8164e-01 1.1 6.66e+08 1.1 0.0e+00 0.0e+00 0.0e+00  1  1  0  0  0   1  1  0  0  0 14452
VecAssemblyBegin       3 1.0 9.6673e-03 1.0 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAssemblyEnd         3 1.0 6.3493e-04 5.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecScatterBegin      396 1.0 2.6917e-01 2.3 0.00e+00 0.0 5.8e+04 4.6e+04 0.0e+00  0  0 97 62  0   0  0 97 62  0     0
VecScatterEnd        396 1.0 3.3865e+0049.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
VecReduceArith       788 1.0 4.8100e-01 1.2 6.69e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 26607
VecReduceComm        394 1.0 1.5939e+00143.7 0.00e+00 0.0 0.0e+00 0.0e+00 3.9e+02  1  0  0  0 47   1  0  0  0 48     0
SFSetGraph             2 1.0 5.1707e-04 1.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.1712e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  1  0  0   0  0  1  0  0     0
SFBcastOpBegin       396 1.0 2.6813e-01 2.3 0.00e+00 0.0 5.8e+04 4.6e+04 0.0e+00  0  0 97 62  0   0  0 97 62  0     0
SFBcastOpEnd         396 1.0 3.3855e+0050.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
SFPack               396 1.0 2.5916e-01 2.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack             396 1.0 2.6824e-04 1.6 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               2 1.0 3.2131e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSolve               1 1.0 6.8785e+01 1.0 4.54e+10 1.1 5.8e+04 4.6e+04 7.9e+02 70100 97 62 95  70100 97 62 96 12535
PCSetUp                2 1.0 2.6109e+00 1.1 1.27e+09 1.1 0.0e+00 0.0e+00 0.0e+00  3  3  0  0  0   3  3  0  0  0  9267
PCSetUpOnBlocks        1 1.0 2.6035e+00 1.1 1.27e+09 1.1 0.0e+00 0.0e+00 0.0e+00  3  3  0  0  0   3  3  0  0  0  9294
PCApply              395 1.0 3.1609e+01 1.1 2.06e+10 1.1 0.0e+00 0.0e+00 0.0e+00 31 45  0  0  0  31 45  0  0  0 12356
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     4              4    666933972     0.
           Index Set     7              7      5403804     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    15             15     34604400     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     2              2         3016     0.
      Preconditioner     2              2         1944     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 2.98e-08
Average time for MPI_Barrier(): 5.191e-06
Average time for zero size MPI_Send(): 3.4335e-06
#PETSc Option Table entries:
-d 3
-ksp_type cr
-log_view
-mat_type aij
-n 100
-pc_type bjacobi
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type cr -pc_type jacobi -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 17:17:02 2020            |
| OS:             Linux                               |
| HostName:       sdumont6171                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.88731, Active time=2.91122                                       |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.4030      0.000008    0.4030      0.000008    13.84    13.84    |
| Ke                            50792      1.7801      0.000035    1.7801      0.000035    61.14    61.14    |
| elem init                     50792      0.7282      0.000014    0.7282      0.000014    25.01    25.01    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.9112                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 40.436857
Tempo total: 40.421558
Tempo total: 40.406162
Tempo total: 40.394627
Tempo total: 40.382451
Tempo total: 40.392060
Tempo total: 40.442361
Tempo total: 40.392626
Tempo total: 40.379976
Tempo total: 40.396529
Tempo total: 40.414573
Tempo total: 40.387630
Tempo total: 40.404325
Tempo total: 40.394385
Tempo total: 40.378487
Tempo total: 40.386960
Tempo total: 40.410547
Tempo total: 40.380931
Tempo total: 40.401733
Tempo total: 40.415888
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6171 with 20 processors, by luciano.siqueira Thu Dec 10 17:17:15 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           4.078e+01     1.000   4.078e+01
Objects:              2.900e+01     1.000   2.900e+01
Flop:                 8.192e+09     1.100   7.820e+09  1.564e+11
Flop/sec:             2.009e+08     1.100   1.918e+08  3.836e+09
MPI Messages:         1.636e+03     2.631   1.101e+03  2.202e+04
MPI Message Lengths:  1.462e+08     1.349   1.149e+05  2.531e+09
MPI Reductions:       3.180e+02     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 4.0776e+01 100.0%  1.5640e+11 100.0%  2.202e+04 100.0%  1.149e+05      100.0%  3.110e+02  97.8%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 4.4801e-0190.3 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  1  0  2  0  2   1  0  2  0  2     0
BuildTwoSidedF         5 1.0 4.4662e-01110.0 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  1  0  2  8  2   1  0  2  8  2     0
MatMult              137 1.0 1.1235e+01 1.1 7.32e+09 1.1 2.0e+04 4.6e+04 0.0e+00 27 89 91 36  0  27 89 91 36  0 12435
MatAssemblyBegin       2 1.0 5.4529e-01 3.6 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  1  0  1  8  1   1  0  1  8  1     0
MatAssemblyEnd         2 1.0 3.4187e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  1  0  1  0  2   1  0  1  0  2    13
MatZeroEntries         3 1.0 1.2193e-01 1.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecDot               135 1.0 1.4337e-01 1.5 1.15e+08 1.1 0.0e+00 0.0e+00 1.4e+02  0  1  0  0 42   0  1  0  0 43 15293
VecNorm                1 1.0 7.3540e-04 1.3 8.49e+05 1.1 0.0e+00 0.0e+00 1.0e+00  0  0  0  0  0   0  0  0  0  0 22085
VecCopy                3 1.0 2.1171e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet                 5 1.0 1.7316e-03 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY              270 1.0 2.1778e-01 1.1 2.29e+08 1.1 0.0e+00 0.0e+00 0.0e+00  1  3  0  0  0   1  3  0  0  0 20136
VecAYPX              269 1.0 3.0208e-01 1.1 2.28e+08 1.1 0.0e+00 0.0e+00 0.0e+00  1  3  0  0  0   1  3  0  0  0 14436
VecAssemblyBegin       3 1.0 9.6495e-03 1.0 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  1  0  1   0  0  1  0  1     0
VecAssemblyEnd         3 1.0 5.7718e-04 5.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecPointwiseMult     137 1.0 1.9578e-01 1.1 5.82e+07 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0  5683
VecScatterBegin      138 1.0 7.2980e-02 2.2 0.00e+00 0.0 2.0e+04 4.6e+04 0.0e+00  0  0 92 37  0   0  0 92 37  0     0
VecScatterEnd        138 1.0 1.1418e+0061.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
VecReduceArith       272 1.0 1.6151e-01 1.1 2.31e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  3  0  0  0   0  3  0  0  0 27352
VecReduceComm        136 1.0 5.7699e-01259.8 0.00e+00 0.0 0.0e+00 0.0e+00 1.4e+02  1  0  0  0 43   1  0  0  0 44     0
SFSetGraph             2 1.0 5.1580e-04 1.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.1216e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  3  0  1   0  0  3  0  1     0
SFBcastOpBegin       138 1.0 7.2657e-02 2.2 0.00e+00 0.0 2.0e+04 4.6e+04 0.0e+00  0  0 92 37  0   0  0 92 37  0     0
SFBcastOpEnd         138 1.0 1.1415e+0062.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
SFPack               138 1.0 6.8310e-02 2.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack             138 1.0 8.7094e-05 1.5 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               1 1.0 3.1765e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSolve               1 1.0 1.2270e+01 1.0 8.18e+09 1.1 2.0e+04 4.6e+04 2.7e+02 30100 91 36 86  30100 91 36 88 12730
PCSetUp                1 1.0 9.0700e-07 4.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
PCApply              137 1.0 2.6847e-01 1.1 5.82e+07 1.1 0.0e+00 0.0e+00 2.0e+00  1  1  0  0  1   1  1  0  0  1  4144
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     3              3    344047400     0.
           Index Set     4              4       304416     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    14             14     38000744     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     1              1         1600     0.
      Preconditioner     1              1          968     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 2.68e-08
Average time for MPI_Barrier(): 5.0604e-06
Average time for zero size MPI_Send(): 3.34375e-06
#PETSc Option Table entries:
-d 3
-ksp_type cr
-log_view
-mat_type aij
-n 100
-pc_type jacobi
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type cr -pc_type sor -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 17:17:46 2020            |
| OS:             Linux                               |
| HostName:       sdumont6171                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.85745, Active time=2.88108                                       |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.3982      0.000008    0.3982      0.000008    13.82    13.82    |
| Ke                            50792      1.7572      0.000035    1.7572      0.000035    60.99    60.99    |
| elem init                     50792      0.7257      0.000014    0.7257      0.000014    25.19    25.19    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.8811                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 120.557175
Tempo total: 120.536661
Tempo total: 120.564892
Tempo total: 120.531880
Tempo total: 120.539425
Tempo total: 120.507748
Tempo total: 120.540097
Tempo total: 120.507905
Tempo total: 120.495745
Tempo total: 120.508538
Tempo total: 120.501132
Tempo total: 120.508395
Tempo total: 120.529014
Tempo total: 120.506228
Tempo total: 120.492616
Tempo total: 120.502231
Tempo total: 120.486370
Tempo total: 120.498469
Tempo total: 120.525694
Tempo total: 120.540533
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6171 with 20 processors, by luciano.siqueira Thu Dec 10 17:19:19 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           1.209e+02     1.000   1.209e+02
Objects:              2.800e+01     1.000   2.800e+01
Flop:                 4.953e+10     1.106   4.708e+10  9.416e+11
Flop/sec:             4.095e+08     1.106   3.893e+08  7.786e+09
MPI Messages:         4.992e+03     2.710   3.327e+03  6.655e+04
MPI Message Lengths:  2.834e+08     1.592   6.871e+04  4.573e+09
MPI Reductions:       9.260e+02     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 1.2093e+02 100.0%  9.4159e+11 100.0%  6.655e+04 100.0%  6.871e+04      100.0%  9.190e+02  99.2%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 4.8166e-01136.6 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  0  0  1  0  1   0  0  1  0  1     0
BuildTwoSidedF         5 1.0 4.8121e-01144.4 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  0  0  1  5  1   0  0  1  5  1     0
MatMult              442 1.0 3.6162e+01 1.1 2.36e+10 1.1 6.5e+04 4.6e+04 0.0e+00 29 48 97 65  0  29 48 97 65  0 12464
MatSOR               442 1.0 5.3115e+01 1.1 2.33e+10 1.1 0.0e+00 0.0e+00 0.0e+00 42 47  0  0  0  42 47  0  0  0  8295
MatAssemblyBegin       2 1.0 5.5403e-01 3.2 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  0  0  0  5  0   0  0  0  5  0     0
MatAssemblyEnd         2 1.0 3.4067e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  0  0  0  0  1   0  0  0  0  1    13
MatZeroEntries         3 1.0 1.2322e-01 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecDot               440 1.0 6.1955e+0022.0 3.74e+08 1.1 0.0e+00 0.0e+00 4.4e+02  3  1  0  0 48   3  1  0  0 48  1153
VecNorm                1 1.0 1.4344e-0224.9 8.49e+05 1.1 0.0e+00 0.0e+00 1.0e+00  0  0  0  0  0   0  0  0  0  0  1132
VecCopy                3 1.0 2.1709e-03 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet                 5 1.0 1.7787e-03 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY              880 1.0 7.9751e-01 1.1 7.48e+08 1.1 0.0e+00 0.0e+00 0.0e+00  1  2  0  0  0   1  2  0  0  0 17921
VecAYPX              879 1.0 9.8601e-01 1.1 7.46e+08 1.1 0.0e+00 0.0e+00 0.0e+00  1  2  0  0  0   1  2  0  0  0 14470
VecAssemblyBegin       3 1.0 9.1105e-03 1.0 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAssemblyEnd         3 1.0 5.4012e-04 4.6 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecScatterBegin      443 1.0 2.9505e-01 2.2 0.00e+00 0.0 6.5e+04 4.6e+04 0.0e+00  0  0 97 65  0   0  0 97 65  0     0
VecScatterEnd        443 1.0 3.5623e+0060.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
VecReduceArith       882 1.0 5.3371e-01 1.1 7.49e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  2  0  0  0   0  2  0  0  0 26840
VecReduceComm        441 1.0 1.8335e+00238.1 0.00e+00 0.0 0.0e+00 0.0e+00 4.4e+02  1  0  0  0 48   1  0  0  0 48     0
SFSetGraph             2 1.0 5.1810e-04 1.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.1380e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  1  0  0   0  0  1  0  0     0
SFBcastOpBegin       443 1.0 2.9403e-01 2.2 0.00e+00 0.0 6.5e+04 4.6e+04 0.0e+00  0  0 97 65  0   0  0 97 65  0     0
SFBcastOpEnd         443 1.0 3.5613e+0061.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
SFPack               443 1.0 2.8287e-01 2.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack             443 1.0 3.2398e-04 1.7 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               1 1.0 3.1987e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSolve               1 1.0 9.1811e+01 1.0 4.95e+10 1.1 6.5e+04 4.6e+04 8.8e+02 76100 97 65 95  76100 97 65 96 10253
PCSetUp                1 1.0 5.5400e-07 3.8 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
PCApply              442 1.0 5.3116e+01 1.1 2.33e+10 1.1 0.0e+00 0.0e+00 0.0e+00 42 47  0  0  0  42 47  0  0  0  8295
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     3              3    354240752     0.
           Index Set     4              4       304416     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    13             13     34601264     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     1              1         1600     0.
      Preconditioner     1              1          968     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 3e-08
Average time for MPI_Barrier(): 4.8408e-06
Average time for zero size MPI_Send(): 3.2527e-06
#PETSc Option Table entries:
-d 3
-ksp_type cr
-log_view
-mat_type aij
-n 100
-pc_type sor
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type cr -pc_type mg -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 17:19:50 2020            |
| OS:             Linux                               |
| HostName:       sdumont6171                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.89203, Active time=2.91745                                       |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.4219      0.000008    0.4219      0.000008    14.46    14.46    |
| Ke                            50792      1.7661      0.000035    1.7661      0.000035    60.53    60.53    |
| elem init                     50792      0.7295      0.000014    0.7295      0.000014    25.01    25.01    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.9175                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 134.201620
Tempo total: 134.194151
Tempo total: 134.170648
Tempo total: 134.185629
Tempo total: 134.157575
Tempo total: 134.158435
Tempo total: 134.144560
Tempo total: 134.122019
Tempo total: 134.145301
Tempo total: 134.157255
Tempo total: 134.149385
Tempo total: 134.171620
Tempo total: 134.141487
Tempo total: 134.114640
Tempo total: 134.133554
Tempo total: 134.114388
Tempo total: 134.133579
Tempo total: 134.158042
Tempo total: 134.173717
Tempo total: 134.158196
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6171 with 20 processors, by luciano.siqueira Thu Dec 10 17:21:36 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           1.345e+02     1.000   1.345e+02
Objects:              5.300e+01     1.000   5.300e+01
Flop:                 5.573e+10     1.106   5.298e+10  1.060e+12
Flop/sec:             4.143e+08     1.106   3.938e+08  7.875e+09
MPI Messages:         5.652e+03     2.714   3.765e+03  7.531e+04
MPI Message Lengths:  3.104e+08     1.619   6.605e+04  4.974e+09
MPI Reductions:       5.570e+02     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 1.3454e+02 100.0%  1.0595e+12 100.0%  7.531e+04 100.0%  6.605e+04      100.0%  5.500e+02  98.7%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 4.3071e-0189.8 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  0  0  1  0  1   0  0  1  0  1     0
BuildTwoSidedF         5 1.0 4.2936e-01106.2 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  0  0  0  4  1   0  0  0  4  1     0
MatMult              502 1.0 4.4405e+01 1.1 2.68e+10 1.1 7.3e+04 4.6e+04 0.0e+00 31 48 97 68  0  31 48 97 68  0 11528
MatSOR               503 1.0 6.0682e+01 1.1 2.65e+10 1.1 0.0e+00 0.0e+00 0.0e+00 43 47  0  0  0  43 47  0  0  0  8263
MatAssemblyBegin       2 1.0 5.6040e-01 4.8 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  0  0  0  4  0   0  0  0  4  0     0
MatAssemblyEnd         2 1.0 3.4265e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  0  0  0  0  1   0  0  0  0  1    13
MatZeroEntries         3 1.0 1.2281e-01 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecDot               244 1.0 4.4895e+0022.4 2.07e+08 1.1 0.0e+00 0.0e+00 2.4e+02  2  0  0  0 44   2  0  0  0 44   883
VecMDot               10 1.0 1.5760e-01 7.4 4.67e+07 1.1 0.0e+00 0.0e+00 1.0e+01  0  0  0  0  2   0  0  0  0  2  5668
VecNorm               12 1.0 5.9496e-02 8.0 1.02e+07 1.1 0.0e+00 0.0e+00 1.2e+01  0  0  0  0  2   0  0  0  0  2  3276
VecScale              11 1.0 3.4318e-03 1.3 4.67e+06 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 26029
VecCopy              496 1.0 3.3950e-01 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet               499 1.0 2.2949e-01 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY              489 1.0 4.3054e-01 1.1 4.15e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 18447
VecAYPX              979 1.0 1.0976e+00 1.1 7.27e+08 1.1 0.0e+00 0.0e+00 0.0e+00  1  1  0  0  0   1  1  0  0  0 12658
VecAXPBYCZ           246 1.0 3.2776e-01 1.1 5.22e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 30474
VecMAXPY              11 1.0 3.6048e-02 1.1 5.52e+07 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 29285
VecAssemblyBegin       3 1.0 9.6249e-03 1.0 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  0  0  1   0  0  0  0  1     0
VecAssemblyEnd         3 1.0 6.0759e-04 4.6 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecScatterBegin      503 1.0 3.1852e-01 2.0 0.00e+00 0.0 7.3e+04 4.6e+04 0.0e+00  0  0 98 68  0   0  0 98 68  0     0
VecScatterEnd        503 1.0 7.4888e+0031.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  2  0  0  0  0   2  0  0  0  0     0
VecReduceArith       490 1.0 2.9860e-01 1.2 4.16e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 26652
VecReduceComm        245 1.0 9.3289e-01120.9 0.00e+00 0.0 0.0e+00 0.0e+00 2.4e+02  0  0  0  0 44   0  0  0  0 45     0
VecNormalize          11 1.0 3.9898e-02 4.0 1.40e+07 1.1 0.0e+00 0.0e+00 1.1e+01  0  0  0  0  2   0  0  0  0  2  6717
SFSetGraph             2 1.0 5.3364e-04 2.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.1718e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  1  0  0   0  0  1  0  0     0
SFBcastOpBegin       503 1.0 3.1728e-01 2.1 0.00e+00 0.0 7.3e+04 4.6e+04 0.0e+00  0  0 98 68  0   0  0 98 68  0     0
SFBcastOpEnd         503 1.0 7.4877e+0032.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  2  0  0  0  0   2  0  0  0  0     0
SFPack               503 1.0 3.0520e-01 2.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack             503 1.0 3.3616e-04 1.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               2 1.0 2.3300e+00 1.0 1.23e+09 1.1 1.5e+03 4.6e+04 2.3e+01  2  2  2  1  4   2  2  2  1  4 10044
KSPSolve               1 1.0 1.0451e+02 1.0 5.57e+10 1.1 7.3e+04 4.6e+04 5.1e+02 78100 97 68 92  78100 97 68 93 10135
KSPGMRESOrthog        10 1.0 1.8538e-01 3.6 9.34e+07 1.1 0.0e+00 0.0e+00 1.0e+01  0  0  0  0  2   0  0  0  0  2  9637
PCSetUp                1 1.0 2.3272e+00 1.0 1.23e+09 1.1 1.5e+03 4.6e+04 2.3e+01  2  2  2  1  4   2  2  2  1  4 10056
PCApply              257 1.0 8.1974e+01 1.1 4.05e+10 1.1 3.6e+04 4.6e+04 0.0e+00 59 73 48 33  0  59 73 48 33  0  9372
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     3              3    354240752     0.
           Index Set     4              4       304416     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    32             32     99191384     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     4              4        35144     0.
      Preconditioner     4              4         4256     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 2.88e-08
Average time for MPI_Barrier(): 4.823e-06
Average time for zero size MPI_Send(): 3.30575e-06
#PETSc Option Table entries:
-d 3
-ksp_type cr
-log_view
-mat_type aij
-n 100
-pc_type mg
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type gcr -pc_type bjacobi -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 17:22:06 2020            |
| OS:             Linux                               |
| HostName:       sdumont6171                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.75525, Active time=2.83419                                       |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.3946      0.000008    0.3946      0.000008    13.92    13.92    |
| Ke                            50792      1.7285      0.000034    1.7285      0.000034    60.99    60.99    |
| elem init                     50792      0.7111      0.000014    0.7111      0.000014    25.09    25.09    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.8342                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 131.846376
Tempo total: 131.834973
Tempo total: 131.885735
Tempo total: 131.861597
Tempo total: 131.846835
Tempo total: 131.844236
Tempo total: 131.865563
Tempo total: 131.844874
Tempo total: 131.824787
Tempo total: 131.841095
Tempo total: 131.812753
Tempo total: 131.829137
Tempo total: 131.857133
Tempo total: 131.833172
Tempo total: 131.845181
Tempo total: 131.825550
Tempo total: 131.853132
Tempo total: 131.829307
Tempo total: 131.860888
Tempo total: 131.896626
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6171 with 20 processors, by luciano.siqueira Thu Dec 10 17:23:51 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           1.323e+02     1.000   1.323e+02
Objects:              9.000e+01     1.000   9.000e+01
Flop:                 8.004e+10     1.103   7.619e+10  1.524e+12
Flop/sec:             6.052e+08     1.103   5.761e+08  1.152e+10
MPI Messages:         6.014e+03     2.717   4.006e+03  8.013e+04
MPI Message Lengths:  3.252e+08     1.632   6.484e+04  5.195e+09
MPI Reductions:       1.632e+03     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 1.3225e+02 100.0%  1.5238e+12 100.0%  8.013e+04 100.0%  6.484e+04      100.0%  1.625e+03  99.6%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 4.0297e-0182.2 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  0  0  1  0  0   0  0  1  0  0     0
BuildTwoSidedF         5 1.0 4.0179e-01124.0 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  0  0  0  4  0   0  0  0  4  0     0
MatMult              535 1.0 4.7872e+01 1.2 2.86e+10 1.1 7.8e+04 4.6e+04 0.0e+00 34 36 97 69  0  34 36 97 69  0 11396
MatSolve             534 1.0 4.2498e+01 1.1 2.79e+10 1.1 0.0e+00 0.0e+00 0.0e+00 30 35  0  0  0  30 35  0  0  0 12424
MatLUFactorNum         1 1.0 2.5411e+00 1.1 1.27e+09 1.1 0.0e+00 0.0e+00 0.0e+00  2  2  0  0  0   2  2  0  0  0  9522
MatILUFactorSym        1 1.0 1.5113e-01 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatAssemblyBegin       2 1.0 5.1481e-01 3.1 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  0  0  0  4  0   0  0  0  4  0     0
MatAssemblyEnd         2 1.0 3.4345e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  0  0  0  0  0   0  0  0  0  0    13
MatGetRowIJ            1 1.0 4.0830e-06 1.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatGetOrdering         1 1.0 4.3483e-03 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatZeroEntries         3 1.0 1.2072e-01 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecDotNorm2          534 1.0 1.5527e+00 2.0 9.07e+08 1.1 0.0e+00 0.0e+00 5.3e+02  1  1  0  0 33   1  1  0  0 33 11172
VecMDot              516 1.0 6.6363e+00 2.2 6.52e+09 1.1 0.0e+00 0.0e+00 5.2e+02  3  8  0  0 32   3  8  0  0 32 18773
VecNorm              536 1.0 4.4224e-01 1.4 4.55e+08 1.1 0.0e+00 0.0e+00 5.4e+02  0  1  0  0 33   0  1  0  0 33 19685
VecScale            1068 1.0 5.1289e-01 1.1 4.54e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 16910
VecCopy                1 1.0 8.2669e-04 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet               539 1.0 2.8035e-01 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY             1068 1.0 9.6342e-01 1.1 9.07e+08 1.1 0.0e+00 0.0e+00 0.0e+00  1  1  0  0  0   1  1  0  0  0 18004
VecAYPX                1 1.0 1.1297e-03 1.1 4.25e+05 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0  7188
VecMAXPY            1032 1.0 8.1868e+00 1.1 1.30e+10 1.1 0.0e+00 0.0e+00 0.0e+00  6 16  0  0  0   6 16  0  0  0 30436
VecAssemblyBegin       3 1.0 9.6712e-03 1.0 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAssemblyEnd         3 1.0 5.9804e-04 4.7 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecScatterBegin      536 1.0 3.0390e-01 2.2 0.00e+00 0.0 7.8e+04 4.6e+04 0.0e+00  0  0 98 69  0   0  0 98 69  0     0
VecScatterEnd        536 1.0 8.8409e+0078.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  3  0  0  0  0   3  0  0  0  0     0
SFSetGraph             2 1.0 5.1284e-04 2.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.1478e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  1  0  0   0  0  1  0  0     0
SFBcastOpBegin       536 1.0 3.0290e-01 2.2 0.00e+00 0.0 7.8e+04 4.6e+04 0.0e+00  0  0 98 69  0   0  0 98 69  0     0
SFBcastOpEnd         536 1.0 8.8396e+0079.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  3  0  0  0  0   3  0  0  0  0     0
SFPack               536 1.0 2.9225e-01 2.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack             536 1.0 4.2641e-04 2.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               2 1.0 6.3317e-02 2.1 0.00e+00 0.0 0.0e+00 0.0e+00 2.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSolve               1 1.0 1.0307e+02 1.0 8.00e+10 1.1 7.8e+04 4.6e+04 1.6e+03 78100 97 69 97  78100 97 69 98 14782
PCSetUp                2 1.0 2.6946e+00 1.1 1.27e+09 1.1 0.0e+00 0.0e+00 0.0e+00  2  2  0  0  0   2  2  0  0  0  8980
PCSetUpOnBlocks        1 1.0 2.6930e+00 1.1 1.27e+09 1.1 0.0e+00 0.0e+00 0.0e+00  2  2  0  0  0   2  2  0  0  0  8985
PCApply              534 1.0 4.2784e+01 1.1 2.79e+10 1.1 0.0e+00 0.0e+00 0.0e+00 31 35  0  0  0  31 35  0  0  0 12341
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     4              4    666933972     0.
           Index Set     7              7      5403804     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    69             69    218176320     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     2              2         3080     0.
      Preconditioner     2              2         1944     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 2.8e-08
Average time for MPI_Barrier(): 4.8988e-06
Average time for zero size MPI_Send(): 3.4735e-06
#PETSc Option Table entries:
-d 3
-ksp_type gcr
-log_view
-mat_type aij
-n 100
-pc_type bjacobi
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type gcr -pc_type jacobi -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 17:24:22 2020            |
| OS:             Linux                               |
| HostName:       sdumont6171                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.87139, Active time=2.90238                                       |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.4005      0.000008    0.4005      0.000008    13.80    13.80    |
| Ke                            50792      1.7699      0.000035    1.7699      0.000035    60.98    60.98    |
| elem init                     50792      0.7320      0.000014    0.7320      0.000014    25.22    25.22    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.9024                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 174.893636
Tempo total: 174.906268
Tempo total: 174.931445
Tempo total: 174.904686
Tempo total: 174.934257
Tempo total: 174.891715
Tempo total: 174.879228
Tempo total: 174.880356
Tempo total: 174.869588
Tempo total: 174.891515
Tempo total: 174.913784
Tempo total: 174.875746
Tempo total: 174.865057
Tempo total: 174.897810
Tempo total: 174.861625
Tempo total: 174.880429
Tempo total: 174.897731
Tempo total: 174.876636
Tempo total: 174.895694
Tempo total: 174.903158
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6171 with 20 processors, by luciano.siqueira Thu Dec 10 17:26:49 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           1.753e+02     1.000   1.753e+02
Objects:              8.300e+01     1.000   8.300e+01
Flop:                 1.276e+11     1.098   1.219e+11  2.438e+12
Flop/sec:             7.279e+08     1.098   6.952e+08  1.390e+10
MPI Messages:         1.480e+04     2.736   9.839e+03  1.968e+05
MPI Message Lengths:  6.846e+08     1.793   5.358e+04  1.054e+10
MPI Reductions:       4.004e+03     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 1.7532e+02 100.0%  2.4377e+12 100.0%  1.968e+05 100.0%  5.358e+04      100.0%  3.997e+03  99.8%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 4.7309e-01136.7 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  0  0  0  0  0   0  0  0  0  0     0
BuildTwoSidedF         5 1.0 4.7408e-01180.5 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  0  0  0  2  0   0  0  0  2  0     0
MatMult             1334 1.0 1.0883e+02 1.1 7.13e+10 1.1 1.9e+05 4.6e+04 0.0e+00 61 56 99 85  0  61 56 99 85  0 12500
MatAssemblyBegin       2 1.0 5.5167e-01 3.1 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  0  0  0  2  0   0  0  0  2  0     0
MatAssemblyEnd         2 1.0 3.2543e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  0  0  0  0  0   0  0  0  0  0    13
MatZeroEntries         3 1.0 1.2270e-01 1.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecDotNorm2         1333 1.0 3.8763e+00 1.9 2.26e+09 1.1 0.0e+00 0.0e+00 1.3e+03  2  2  0  0 33   2  2  0  0 33 11170
VecMDot             1288 1.0 1.3063e+01 1.7 1.63e+10 1.1 0.0e+00 0.0e+00 1.3e+03  6 13  0  0 32   6 13  0  0 32 23893
VecNorm             1335 1.0 1.1517e+00 1.4 1.13e+09 1.1 0.0e+00 0.0e+00 1.3e+03  1  1  0  0 33   1  1  0  0 33 18826
VecScale            2666 1.0 1.3041e+00 1.1 1.13e+09 1.1 0.0e+00 0.0e+00 0.0e+00  1  1  0  0  0   1  1  0  0  0 16601
VecCopy                1 1.0 8.0061e-04 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet                 5 1.0 1.7961e-03 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY             2666 1.0 2.3750e+00 1.1 2.26e+09 1.1 0.0e+00 0.0e+00 0.0e+00  1  2  0  0  0   1  2  0  0  0 18231
VecAYPX                1 1.0 1.1340e-03 1.1 4.25e+05 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0  7161
VecMAXPY            2576 1.0 2.0548e+01 1.1 3.26e+10 1.1 0.0e+00 0.0e+00 0.0e+00 11 26  0  0  0  11 26  0  0  0 30380
VecAssemblyBegin       3 1.0 9.0610e-03 1.0 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAssemblyEnd         3 1.0 5.6014e-04 4.5 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecPointwiseMult    1333 1.0 1.9076e+00 1.1 5.66e+08 1.1 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0  5675
VecScatterBegin     1335 1.0 9.2005e-01 2.1 0.00e+00 0.0 1.9e+05 4.6e+04 0.0e+00  0  0 99 85  0   0  0 99 85  0     0
VecScatterEnd       1335 1.0 9.2241e+0054.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  2  0  0  0  0   2  0  0  0  0     0
SFSetGraph             2 1.0 5.0290e-04 1.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.0949e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFBcastOpBegin      1335 1.0 9.1725e-01 2.1 0.00e+00 0.0 1.9e+05 4.6e+04 0.0e+00  0  0 99 85  0   0  0 99 85  0     0
SFBcastOpEnd        1335 1.0 9.2212e+0055.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  2  0  0  0  0   2  0  0  0  0     0
SFPack              1335 1.0 8.9219e-01 2.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack            1335 1.0 8.0231e-04 1.7 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               1 1.0 6.1628e-02 1.8 0.00e+00 0.0 0.0e+00 0.0e+00 2.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSolve               1 1.0 1.4558e+02 1.0 1.28e+11 1.1 1.9e+05 4.6e+04 4.0e+03 83100 99 85 99  83100 99 85 99 16742
PCSetUp                1 1.0 8.6000e-07 2.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
PCApply             1333 1.0 1.9791e+00 1.1 5.66e+08 1.1 0.0e+00 0.0e+00 2.0e+00  1  0  0  0  0   1  0  0  0  0  5469
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     3              3    344047400     0.
           Index Set     4              4       304416     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    68             68    221572664     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     1              1         1664     0.
      Preconditioner     1              1          968     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 2.75e-08
Average time for MPI_Barrier(): 4.7018e-06
Average time for zero size MPI_Send(): 3.25755e-06
#PETSc Option Table entries:
-d 3
-ksp_type gcr
-log_view
-mat_type aij
-n 100
-pc_type jacobi
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type gcr -pc_type sor -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

slurmstepd: error: *** JOB 801693 ON sdumont6171 CANCELLED AT 2020-12-10T17:27:15 DUE TO TIME LIMIT ***
mpirun: Forwarding signal 18 to job
[19]PETSC ERROR: ------------------------------------------------------------------------
[19]PETSC ERROR: Caught signal number 15 Terminate: Some process (or the batch system) has told this process to end
[19]PETSC ERROR: Try option -start_in_debugger or -on_error_attach_debugger
[19]PETSC ERROR: or see https://www.mcs.anl.gov/petsc/documentation/faq.html#valgrind
[19]PETSC ERROR: or try http://valgrind.org on GNU/linux and Apple Mac OS X to find memory corruption errors
[19]PETSC ERROR: configure using --with-debugging=yes, recompile, link, and run 
[19]PETSC ERROR: to get more information on the crash.
[19]PETSC ERROR: --------------------- Error Message --------------------------------------------------------------
[19]PETSC ERROR: Signal received
[0]PETSC ERROR: ------------------------------------------------------------------------
[0]PETSC ERROR: Caught signal number 15 Terminate: Some process (or the batch system) has told this process to end
[0]PETSC ERROR: Try option -start_in_debugger or -on_error_attach_debugger
[0]PETSC ERROR: or see https://www.mcs.anl.gov/petsc/documentation/faq.html#valgrind
[0]PETSC ERROR: or try http://valgrind.org on GNU/linux and Apple Mac OS X to find memory corruption errors
[0]PETSC ERROR: configure using --with-debugging=yes, recompile, link, and run 
[0]PETSC ERROR: to get more information on the crash.
[0]PETSC ERROR: --------------------- Error Message --------------------------------------------------------------
[0]PETSC ERROR: Signal received
[0]PETSC ERROR: See https://www.mcs.anl.gov/petsc/documentation/faq.html for trouble shooting.
[0]PETSC ERROR: Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500
[0]PETSC ERROR: /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6171 by luciano.siqueira Thu Dec 10 17:26:52 2020
[0]PETSC ERROR: Configure options --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
[0]PETSC ERROR: #1 User provided function() line 0 in  unknown file
[1]PETSC ERROR: ------------------------------------------------------------------------
[1]PETSC ERROR: Caught signal number 15 Terminate: Some process (or the batch system) has told this process to end
[1]PETSC ERROR: Try option -start_in_debugger or -on_error_attach_debugger
[1]PETSC ERROR: or see https://www.mcs.anl.gov/petsc/documentation/faq.html#valgrind
[1]PETSC ERROR: or try http://valgrind.org on GNU/linux and Apple Mac OS X to find memory corruption errors
[1]PETSC ERROR: configure using --with-debugging=yes, recompile, link, and run 
[1]PETSC ERROR: to get more information on the crash.
[1]PETSC ERROR: --------------------- Error Message --------------------------------------------------------------
[1]PETSC ERROR: Signal received
[1]PETSC ERROR: See https://www.mcs.anl.gov/petsc/documentation/faq.html for trouble shooting.
[1]PETSC ERROR: [2]PETSC ERROR: ------------------------------------------------------------------------
[2]PETSC ERROR: Caught signal number 15 Terminate: Some process (or the batch system) has told this process to end
[2]PETSC ERROR: Try option -start_in_debugger or -on_error_attach_debugger
[2]PETSC ERROR: or see https://www.mcs.anl.gov/petsc/documentation/faq.html#valgrind
[2]PETSC ERROR: or try http://valgrind.org on GNU/linux and Apple Mac OS X to find memory corruption errors
[2]PETSC ERROR: configure using --with-debugging=yes, recompile, link, and run 
[2]PETSC ERROR: [3]PETSC ERROR: ------------------------------------------------------------------------
[3]PETSC ERROR: Caught signal number 15 Terminate: Some process (or the batch system) has told this process to end
[3]PETSC ERROR: Try option -start_in_debugger or -on_error_attach_debugger
[3]PETSC ERROR: or see https://www.mcs.anl.gov/petsc/documentation/faq.html#valgrind
[3]PETSC ERROR: or try http://valgrind.org on GNU/linux and Apple Mac OS X to find memory corruption errors
[3]PETSC ERROR: configure using --with-debugging=yes, recompile, link, and run 
[3]PETSC ERROR: to get more information on the crash.
[3]PETSC ERROR: --------------------- Error Message --------------------------------------------------------------
[3]PETSC ERROR: Signal received
[3]PETSC ERROR: See https://www.mcs.anl.gov/petsc/documentation/faq.html for trouble shooting.
[4]PETSC ERROR: ------------------------------------------------------------------------
[4]PETSC ERROR: Caught signal number 15 Terminate: Some process (or the batch system) has told this process to end
[4]PETSC ERROR: Try option -start_in_debugger or -on_error_attach_debugger
[4]PETSC ERROR: or see https://www.mcs.anl.gov/petsc/documentation/faq.html#valgrind
[4]PETSC ERROR: or try http://valgrind.org on GNU/linux and Apple Mac OS X to find memory corruption errors
[4]PETSC ERROR: configure using --with-debugging=yes, recompile, link, and run 
[5]PETSC ERROR: ------------------------------------------------------------------------
[5]PETSC ERROR: Caught signal number 15 Terminate: Some process (or the batch system) has told this process to end
[5]PETSC ERROR: Try option -start_in_debugger or -on_error_attach_debugger
[5]PETSC ERROR: or see https://www.mcs.anl.gov/petsc/documentation/faq.html#valgrind
[5]PETSC ERROR: or try http://valgrind.org on GNU/linux and Apple Mac OS X to find memory corruption errors
[5]PETSC ERROR: configure using --with-debugging=yes, recompile, link, and run 
[5]PETSC ERROR: to get more information on the crash.
[5]PETSC ERROR: --------------------- Error Message --------------------------------------------------------------
[6]PETSC ERROR: ------------------------------------------------------------------------
[6]PETSC ERROR: Caught signal number 15 Terminate: Some process (or the batch system) has told this process to end
[6]PETSC ERROR: Try option -start_in_debugger or -on_error_attach_debugger
[6]PETSC ERROR: or see https://www.mcs.anl.gov/petsc/documentation/faq.html#valgrind
[6]PETSC ERROR: or try http://valgrind.org on GNU/linux and Apple Mac OS X to find memory corruption errors
[7]PETSC ERROR: ------------------------------------------------------------------------
[7]PETSC ERROR: Caught signal number 15 Terminate: Some process (or the batch system) has told this process to end
[7]PETSC ERROR: Try option -start_in_debugger or -on_error_attach_debugger
[7]PETSC ERROR: or see https://www.mcs.anl.gov/petsc/documentation/faq.html#valgrind
[7]PETSC ERROR: or try http://valgrind.org on GNU/linux and Apple Mac OS X to find memory corruption errors
[7]PETSC ERROR: configure using --with-debugging=yes, recompile, link, and run 
[7]PETSC ERROR: to get more information on the crash.
[7]PETSC ERROR: [8]PETSC ERROR: ------------------------------------------------------------------------
[8]PETSC ERROR: Caught signal number 15 Terminate: Some process (or the batch system) has told this process to end
[8]PETSC ERROR: Try option -start_in_debugger or -on_error_attach_debugger
[8]PETSC ERROR: or see https://www.mcs.anl.gov/petsc/documentation/faq.html#valgrind
[8]PETSC ERROR: or try http://valgrind.org on GNU/linux and Apple Mac OS X to find memory corruption errors
[8]PETSC ERROR: configure using --with-debugging=yes, recompile, link, and run 
[8]PETSC ERROR: to get more information on the crash.
[8]PETSC ERROR: --------------------- Error Message --------------------------------------------------------------
[8]PETSC ERROR: Signal received
[8]PETSC ERROR: See https://www.mcs.anl.gov/petsc/documentation/faq.html for trouble shooting.
[8]PETSC ERROR: Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500
[8]PETSC ERROR: /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6171 by luciano.siqueira Thu Dec 10 17:26:52 2020
[8]PETSC ERROR: Configure options --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
[8]PETSC ERROR: #1 User provided function() line 0 in  unknown file
[9]PETSC ERROR: ------------------------------------------------------------------------
[9]PETSC ERROR: Caught signal number 15 Terminate: Some process (or the batch system) has told this process to end
[9]PETSC ERROR: Try option -start_in_debugger or -on_error_attach_debugger
[9]PETSC ERROR: [10]PETSC ERROR: ------------------------------------------------------------------------
[10]PETSC ERROR: Caught signal number 15 Terminate: Some process (or the batch system) has told this process to end
[10]PETSC ERROR: Try option -start_in_debugger or -on_error_attach_debugger
[10]PETSC ERROR: or see https://www.mcs.anl.gov/petsc/documentation/faq.html#valgrind
[10]PETSC ERROR: or try http://valgrind.org on GNU/linux and Apple Mac OS X to find memory corruption errors
[10]PETSC ERROR: configure using --with-debugging=yes, recompile, link, and run 
[10]PETSC ERROR: [11]PETSC ERROR: ------------------------------------------------------------------------
[11]PETSC ERROR: Caught signal number 15 Terminate: Some process (or the batch system) has told this process to end
[11]PETSC ERROR: Try option -start_in_debugger or -on_error_attach_debugger
[11]PETSC ERROR: or see https://www.mcs.anl.gov/petsc/documentation/faq.html#valgrind
[11]PETSC ERROR: or try http://valgrind.org on GNU/linux and Apple Mac OS X to find memory corruption errors
[11]PETSC ERROR: configure using --with-debugging=yes, recompile, link, and run 
[11]PETSC ERROR: to get more information on the crash.
[11]PETSC ERROR: --------------------- Error Message --------------------------------------------------------------
[11]PETSC ERROR: Signal received
[11]PETSC ERROR: See https://www.mcs.anl.gov/petsc/documentation/faq.html for trouble shooting.
[11]PETSC ERROR: Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500
[12]PETSC ERROR: ------------------------------------------------------------------------
[13]PETSC ERROR: ------------------------------------------------------------------------
[13]PETSC ERROR: Caught signal number 15 Terminate: Some process (or the batch system) has told this process to end
[13]PETSC ERROR: Try option -start_in_debugger or -on_error_attach_debugger
[13]PETSC ERROR: or see https://www.mcs.anl.gov/petsc/documentation/faq.html#valgrind
[13]PETSC ERROR: or try http://valgrind.org on GNU/linux and Apple Mac OS X to find memory corruption errors
[13]PETSC ERROR: configure using --with-debugging=yes, recompile, link, and run 
[13]PETSC ERROR: to get more information on the crash.
[13]PETSC ERROR: --------------------- Error Message --------------------------------------------------------------
[13]PETSC ERROR: Signal received
[13]PETSC ERROR: See https://www.mcs.anl.gov/petsc/documentation/faq.html for trouble shooting.
[13]PETSC ERROR: Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500
[13]PETSC ERROR: /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6171 by luciano.siqueira Thu Dec 10 17:26:52 2020
[13]PETSC ERROR: Configure options --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
[13]PETSC ERROR: #1 User provided function() line 0 in  unknown file
[14]PETSC ERROR: ------------------------------------------------------------------------
[14]PETSC ERROR: [15]PETSC ERROR: ------------------------------------------------------------------------
[15]PETSC ERROR: Caught signal number 15 Terminate: Some process (or the batch system) has told this process to end
[15]PETSC ERROR: Try option -start_in_debugger or -on_error_attach_debugger
[15]PETSC ERROR: or see https://www.mcs.anl.gov/petsc/documentation/faq.html#valgrind
[15]PETSC ERROR: or try http://valgrind.org on GNU/linux and Apple Mac OS X to find memory corruption errors
[15]PETSC ERROR: configure using --with-debugging=yes, recompile, link, and run 
[15]PETSC ERROR: to get more information on the crash.
[15]PETSC ERROR: --------------------- Error Message --------------------------------------------------------------
[16]PETSC ERROR: [17]PETSC ERROR: ------------------------------------------------------------------------
[17]PETSC ERROR: Caught signal number 15 Terminate: Some process (or the batch system) has told this process to end
[17]PETSC ERROR: Try option -start_in_debugger or -on_error_attach_debugger
[17]PETSC ERROR: or see https://www.mcs.anl.gov/petsc/documentation/faq.html#valgrind
[17]PETSC ERROR: or try http://valgrind.org on GNU/linux and Apple Mac OS X to find memory corruption errors
[17]PETSC ERROR: configure using --with-debugging=yes, recompile, link, and run 
[17]PETSC ERROR: to get more information on the crash.
[17]PETSC ERROR: --------------------- Error Message --------------------------------------------------------------
[17]PETSC ERROR: [18]PETSC ERROR: 