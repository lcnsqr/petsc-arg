Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type cg -pc_type bjacobi -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 15:27:35 2020            |
| OS:             Linux                               |
| HostName:       sdumont6180                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.96617, Active time=2.99025                                       |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.4933      0.000010    0.4933      0.000010    16.50    16.50    |
| Ke                            50792      1.7726      0.000035    1.7726      0.000035    59.28    59.28    |
| elem init                     50792      0.7243      0.000014    0.7243      0.000014    24.22    24.22    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.9903                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 98.878364
Tempo total: 98.878338
Tempo total: 98.878382
Tempo total: 98.878249
Tempo total: 98.878218
Tempo total: 98.878371
Tempo total: 98.878211
Tempo total: 98.878131
Tempo total: 98.878221
Tempo total: 98.878299
Tempo total: 98.878239
Tempo total: 98.878093
Tempo total: 98.878376
Tempo total: 98.878375
Tempo total: 98.878031
Tempo total: 98.878014
Tempo total: 98.878157
Tempo total: 98.878274
Tempo total: 98.878222
Tempo total: 98.878190
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6180 with 20 processors, by luciano.siqueira Thu Dec 10 15:28:45 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           9.913e+01     1.000   9.913e+01
Objects:              3.300e+01     1.000   3.300e+01
Flop:                 4.587e+10     1.106   4.359e+10  8.719e+11
Flop/sec:             4.627e+08     1.106   4.398e+08  8.795e+09
MPI Messages:         4.552e+03     2.706   3.035e+03  6.071e+04
MPI Message Lengths:  2.654e+08     1.571   7.091e+04  4.305e+09
MPI Reductions:       1.249e+03     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 9.9131e+01 100.0%  8.7189e+11 100.0%  6.071e+04 100.0%  7.091e+04      100.0%  1.242e+03  99.4%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 4.5492e-01100.3 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  0  0  1  0  1   0  0  1  0  1     0
BuildTwoSidedF         5 1.0 4.5465e-01137.0 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  0  0  1  5  0   0  0  1  5  0     0
MatMult              402 1.0 3.2870e+01 1.0 2.15e+10 1.1 5.9e+04 4.6e+04 0.0e+00 33 47 97 63  0  33 47 97 63  0 12471
MatSolve             403 1.0 3.2059e+01 1.1 2.11e+10 1.1 0.0e+00 0.0e+00 0.0e+00 31 46  0  0  0  31 46  0  0  0 12429
MatLUFactorNum         1 1.0 2.4571e+00 1.1 1.27e+09 1.1 0.0e+00 0.0e+00 0.0e+00  2  3  0  0  0   2  3  0  0  0  9848
MatILUFactorSym        1 1.0 1.5581e-01 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatAssemblyBegin       2 1.0 5.4159e-01 8.4 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  0  0  0  5  0   0  0  0  5  0     0
MatAssemblyEnd         2 1.0 3.4244e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  0  0  0  0  0   0  0  0  0  0    13
MatGetRowIJ            1 1.0 4.0790e-06 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatGetOrdering         1 1.0 4.2576e-03 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatZeroEntries         3 1.0 1.2227e-01 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecTDot              802 1.0 1.7782e+00 3.6 6.81e+08 1.1 0.0e+00 0.0e+00 8.0e+02  1  1  0  0 64   1  1  0  0 65  7325
VecNorm              403 1.0 3.6989e+0016.6 3.42e+08 1.1 0.0e+00 0.0e+00 4.0e+02  2  1  0  0 32   2  1  0  0 32  1769
VecCopy                2 1.0 1.5846e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet               408 1.0 1.3825e-01 1.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY              802 1.0 6.9476e-01 1.1 6.81e+08 1.1 0.0e+00 0.0e+00 0.0e+00  1  1  0  0  0   1  1  0  0  0 18748
VecAYPX              401 1.0 4.3338e-01 1.1 3.40e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 15009
VecAssemblyBegin       3 1.0 9.6425e-03 1.0 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAssemblyEnd         3 1.0 6.1404e-04 4.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecScatterBegin      403 1.0 2.6461e-01 2.2 0.00e+00 0.0 5.9e+04 4.6e+04 0.0e+00  0  0 97 63  0   0  0 97 63  0     0
VecScatterEnd        403 1.0 3.2948e+0061.8 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
SFSetGraph             2 1.0 5.1345e-04 2.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.1555e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  1  0  0   0  0  1  0  0     0
SFBcastOpBegin       403 1.0 2.6364e-01 2.2 0.00e+00 0.0 5.9e+04 4.6e+04 0.0e+00  0  0 97 63  0   0  0 97 63  0     0
SFBcastOpEnd         403 1.0 3.2939e+0062.8 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
SFPack               403 1.0 2.5524e-01 2.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack             403 1.0 2.7790e-04 1.5 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               2 1.0 1.5780e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSolve               1 1.0 6.9481e+01 1.0 4.59e+10 1.1 5.9e+04 4.6e+04 1.2e+03 70100 97 63 96  70100 97 63 97 12546
PCSetUp                2 1.0 2.6250e+00 1.1 1.27e+09 1.1 0.0e+00 0.0e+00 0.0e+00  3  3  0  0  0   3  3  0  0  0  9218
PCSetUpOnBlocks        1 1.0 2.6172e+00 1.1 1.27e+09 1.1 0.0e+00 0.0e+00 0.0e+00  2  3  0  0  0   2  3  0  0  0  9245
PCApply              403 1.0 3.2200e+01 1.1 2.11e+10 1.1 0.0e+00 0.0e+00 0.0e+00 31 46  0  0  0  31 46  0  0  0 12374
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     4              4    666933972     0.
           Index Set     7              7      5403804     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    12             12     24405960     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     2              2         3088     0.
      Preconditioner     2              2         1944     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 2.91e-08
Average time for MPI_Barrier(): 4.9964e-06
Average time for zero size MPI_Send(): 3.38005e-06
#PETSc Option Table entries:
-d 3
-ksp_type cg
-log_view
-mat_type aij
-n 100
-pc_type bjacobi
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type cg -pc_type jacobi -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 15:29:16 2020            |
| OS:             Linux                               |
| HostName:       sdumont6180                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.85478, Active time=2.89061                                       |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.4102      0.000008    0.4102      0.000008    14.19    14.19    |
| Ke                            50792      1.7534      0.000035    1.7534      0.000035    60.66    60.66    |
| elem init                     50792      0.7270      0.000014    0.7270      0.000014    25.15    25.15    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.8906                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 40.811641
Tempo total: 40.835630
Tempo total: 40.779207
Tempo total: 40.798114
Tempo total: 40.777208
Tempo total: 40.794411
Tempo total: 40.776231
Tempo total: 40.789892
Tempo total: 40.749395
Tempo total: 40.784098
Tempo total: 40.749812
Tempo total: 40.791047
Tempo total: 40.752070
Tempo total: 40.727941
Tempo total: 40.761126
Tempo total: 40.739651
Tempo total: 40.756207
Tempo total: 40.735987
Tempo total: 40.755775
Tempo total: 40.811427
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6180 with 20 processors, by luciano.siqueira Thu Dec 10 15:29:29 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           4.115e+01     1.000   4.114e+01
Objects:              2.600e+01     1.000   2.600e+01
Flop:                 8.024e+09     1.100   7.659e+09  1.532e+11
Flop/sec:             1.950e+08     1.100   1.862e+08  3.723e+09
MPI Messages:         1.626e+03     2.630   1.094e+03  2.187e+04
MPI Message Lengths:  1.458e+08     1.348   1.154e+05  2.524e+09
MPI Reductions:       4.530e+02     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 4.1143e+01 100.0%  1.5319e+11 100.0%  2.187e+04 100.0%  1.154e+05      100.0%  4.460e+02  98.5%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 4.6133e-0192.5 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  1  0  2  0  2   1  0  2  0  2     0
BuildTwoSidedF         5 1.0 4.6130e-01111.4 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  1  0  2  8  1   1  0  2  8  1     0
MatMult              136 1.0 1.1085e+01 1.1 7.27e+09 1.1 2.0e+04 4.6e+04 0.0e+00 26 91 91 36  0  26 91 91 36  0 12511
MatAssemblyBegin       2 1.0 5.4405e-01 3.6 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  1  0  1  8  0   1  0  1  8  0     0
MatAssemblyEnd         2 1.0 3.4125e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  1  0  1  0  1   1  0  1  0  1    13
MatZeroEntries         3 1.0 1.2208e-01 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecTDot              270 1.0 6.9452e-01 4.1 2.29e+08 1.1 0.0e+00 0.0e+00 2.7e+02  1  3  0  0 60   1  3  0  0 61  6314
VecNorm              137 1.0 1.3059e-01 1.7 1.16e+08 1.1 0.0e+00 0.0e+00 1.4e+02  0  1  0  0 30   0  1  0  0 31 17038
VecCopy                2 1.0 1.5816e-03 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet                 5 1.0 1.7655e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY              270 1.0 2.4627e-01 1.2 2.29e+08 1.1 0.0e+00 0.0e+00 0.0e+00  1  3  0  0  0   1  3  0  0  0 17806
VecAYPX              135 1.0 1.4612e-01 1.1 1.14e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 14949
VecAssemblyBegin       3 1.0 9.6902e-03 1.0 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  1  0  1   0  0  1  0  1     0
VecAssemblyEnd         3 1.0 5.8991e-04 4.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecPointwiseMult     137 1.0 1.7557e-01 1.1 5.82e+07 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0  6337
VecScatterBegin      137 1.0 8.9555e-02 2.1 0.00e+00 0.0 2.0e+04 4.6e+04 0.0e+00  0  0 91 36  0   0  0 91 36  0     0
VecScatterEnd        137 1.0 1.0405e+0042.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
SFSetGraph             2 1.0 5.1616e-04 1.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.1698e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  3  0  0   0  0  3  0  0     0
SFBcastOpBegin       137 1.0 8.9307e-02 2.1 0.00e+00 0.0 2.0e+04 4.6e+04 0.0e+00  0  0 91 36  0   0  0 91 36  0     0
SFBcastOpEnd         137 1.0 1.0402e+0042.6 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
SFPack               137 1.0 8.5264e-02 2.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack             137 1.0 9.2675e-05 1.6 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               1 1.0 1.5871e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSolve               1 1.0 1.1974e+01 1.0 8.01e+09 1.1 2.0e+04 4.6e+04 4.1e+02 29100 91 36 90  29100 91 36 92 12776
PCSetUp                1 1.0 6.4400e-07 2.5 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
PCApply              137 1.0 2.4700e-01 1.1 5.82e+07 1.1 0.0e+00 0.0e+00 2.0e+00  1  1  0  0  0   1  1  0  0  0  4504
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     3              3    344047400     0.
           Index Set     4              4       304416     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    11             11     27802304     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     1              1         1672     0.
      Preconditioner     1              1          968     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 2.78e-08
Average time for MPI_Barrier(): 5.3272e-06
Average time for zero size MPI_Send(): 3.277e-06
#PETSc Option Table entries:
-d 3
-ksp_type cg
-log_view
-mat_type aij
-n 100
-pc_type jacobi
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type cg -pc_type sor -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 15:30:00 2020            |
| OS:             Linux                               |
| HostName:       sdumont6180                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.89832, Active time=2.91308                                       |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.4025      0.000008    0.4025      0.000008    13.82    13.82    |
| Ke                            50792      1.7772      0.000035    1.7772      0.000035    61.01    61.01    |
| elem init                     50792      0.7334      0.000014    0.7334      0.000014    25.18    25.18    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.9131                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 123.723707
Tempo total: 123.749428
Tempo total: 123.739224
Tempo total: 123.754219
Tempo total: 123.726157
Tempo total: 123.708749
Tempo total: 123.724336
Tempo total: 123.739345
Tempo total: 123.706162
Tempo total: 123.748668
Tempo total: 123.708149
Tempo total: 123.683573
Tempo total: 123.711348
Tempo total: 123.729786
Tempo total: 123.703052
Tempo total: 123.725572
Tempo total: 123.701746
Tempo total: 123.729712
Tempo total: 123.700619
Tempo total: 123.699387
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6180 with 20 processors, by luciano.siqueira Thu Dec 10 15:31:36 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           1.241e+02     1.000   1.241e+02
Objects:              2.500e+01     1.000   2.500e+01
Flop:                 5.110e+10     1.106   4.857e+10  9.715e+11
Flop/sec:             4.118e+08     1.106   3.915e+08  7.829e+09
MPI Messages:         5.178e+03     2.711   3.452e+03  6.903e+04
MPI Message Lengths:  2.910e+08     1.600   6.789e+04  4.686e+09
MPI Reductions:       1.420e+03     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 1.2408e+02 100.0%  9.7148e+11 100.0%  6.903e+04 100.0%  6.789e+04      100.0%  1.413e+03  99.5%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 4.8991e-01123.8 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  0  0  1  0  0   0  0  1  0  0     0
BuildTwoSidedF         5 1.0 4.8871e-01145.8 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  0  0  1  4  0   0  0  1  4  0     0
MatMult              459 1.0 3.7421e+01 1.1 2.45e+10 1.1 6.7e+04 4.6e+04 0.0e+00 30 48 97 66  0  30 48 97 66  0 12508
MatSOR               460 1.0 5.4923e+01 1.1 2.42e+10 1.1 0.0e+00 0.0e+00 0.0e+00 42 47  0  0  0  42 47  0  0  0  8349
MatAssemblyBegin       2 1.0 5.6419e-01 3.5 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  0  0  0  4  0   0  0  0  4  0     0
MatAssemblyEnd         2 1.0 3.2427e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  0  0  0  0  0   0  0  0  0  0    13
MatZeroEntries         3 1.0 1.2225e-01 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecTDot              916 1.0 2.3752e+00 4.1 7.78e+08 1.1 0.0e+00 0.0e+00 9.2e+02  1  2  0  0 65   1  2  0  0 65  6263
VecNorm              460 1.0 6.2034e+0023.8 3.91e+08 1.1 0.0e+00 0.0e+00 4.6e+02  3  1  0  0 32   3  1  0  0 33  1204
VecCopy                2 1.0 1.5094e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet                 5 1.0 1.7863e-03 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY              916 1.0 8.2750e-01 1.2 7.78e+08 1.1 0.0e+00 0.0e+00 0.0e+00  1  2  0  0  0   1  2  0  0  0 17978
VecAYPX              458 1.0 4.9643e-01 1.1 3.89e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 14968
VecAssemblyBegin       3 1.0 9.0660e-03 1.0 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAssemblyEnd         3 1.0 5.8188e-04 4.6 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecScatterBegin      460 1.0 2.9743e-01 2.1 0.00e+00 0.0 6.7e+04 4.6e+04 0.0e+00  0  0 97 66  0   0  0 97 66  0     0
VecScatterEnd        460 1.0 3.4673e+0058.5 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
SFSetGraph             2 1.0 4.9897e-04 1.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.1179e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  1  0  0   0  0  1  0  0     0
SFBcastOpBegin       460 1.0 2.9651e-01 2.1 0.00e+00 0.0 6.7e+04 4.6e+04 0.0e+00  0  0 97 66  0   0  0 97 66  0     0
SFBcastOpEnd         460 1.0 3.4664e+0059.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
SFPack               460 1.0 2.8600e-01 2.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack             460 1.0 4.2666e-04 2.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               1 1.0 1.5981e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSolve               1 1.0 9.4501e+01 1.0 5.11e+10 1.1 6.7e+04 4.6e+04 1.4e+03 76100 97 66 97  76100 97 66 97 10278
PCSetUp                1 1.0 6.6000e-07 5.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
PCApply              460 1.0 5.4924e+01 1.1 2.42e+10 1.1 0.0e+00 0.0e+00 0.0e+00 42 47  0  0  0  42 47  0  0  0  8349
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     3              3    354240752     0.
           Index Set     4              4       304416     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    10             10     24402824     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     1              1         1672     0.
      Preconditioner     1              1          968     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 2.86e-08
Average time for MPI_Barrier(): 4.8212e-06
Average time for zero size MPI_Send(): 3.314e-06
#PETSc Option Table entries:
-d 3
-ksp_type cg
-log_view
-mat_type aij
-n 100
-pc_type sor
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type cg -pc_type mg -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 15:32:07 2020            |
| OS:             Linux                               |
| HostName:       sdumont6180                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.81879, Active time=2.86796                                       |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.3948      0.000008    0.3948      0.000008    13.76    13.76    |
| Ke                            50792      1.7566      0.000035    1.7566      0.000035    61.25    61.25    |
| elem init                     50792      0.7166      0.000014    0.7166      0.000014    24.99    24.99    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.8680                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 134.084971
Tempo total: 134.041277
Tempo total: 134.081082
Tempo total: 134.070264
Tempo total: 134.070991
Tempo total: 134.064071
Tempo total: 134.061612
Tempo total: 134.037876
Tempo total: 134.050024
Tempo total: 134.011945
Tempo total: 134.048331
Tempo total: 134.064704
Tempo total: 134.037574
Tempo total: 134.016246
Tempo total: 134.045161
Tempo total: 134.059822
Tempo total: 134.052551
Tempo total: 134.060799
Tempo total: 134.024101
Tempo total: 134.102086
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6180 with 20 processors, by luciano.siqueira Thu Dec 10 15:33:53 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           1.344e+02     1.000   1.344e+02
Objects:              5.000e+01     1.000   5.000e+01
Flop:                 5.658e+10     1.106   5.378e+10  1.076e+12
Flop/sec:             4.209e+08     1.106   4.001e+08  8.001e+09
MPI Messages:         5.750e+03     2.715   3.831e+03  7.662e+04
MPI Message Lengths:  3.144e+08     1.622   6.570e+04  5.034e+09
MPI Reductions:       8.160e+02     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 1.3442e+02 100.0%  1.0755e+12 100.0%  7.662e+04 100.0%  6.570e+04      100.0%  8.090e+02  99.1%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 4.6316e-0184.5 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  0  0  1  0  1   0  0  1  0  1     0
BuildTwoSidedF         5 1.0 4.6207e-01123.5 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  0  0  0  4  1   0  0  0  4  1     0
MatMult              511 1.0 4.4654e+01 1.1 2.73e+10 1.1 7.5e+04 4.6e+04 0.0e+00 31 48 97 68  0  31 48 97 68  0 11669
MatSOR               513 1.0 6.1312e+01 1.1 2.70e+10 1.1 0.0e+00 0.0e+00 0.0e+00 43 48  0  0  0  43 48  0  0  0  8341
MatAssemblyBegin       2 1.0 5.9921e-01 3.3 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  0  0  0  4  0   0  0  0  4  0     0
MatAssemblyEnd         2 1.0 3.4212e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  0  0  0  0  1   0  0  0  0  1    13
MatZeroEntries         3 1.0 1.2088e-01 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecMDot               10 1.0 1.6310e-01 7.6 4.67e+07 1.1 0.0e+00 0.0e+00 1.0e+01  0  0  0  0  1   0  0  0  0  1  5477
VecTDot              498 1.0 1.2518e+00 4.1 4.23e+08 1.1 0.0e+00 0.0e+00 5.0e+02  1  1  0  0 61   1  1  0  0 62  6461
VecNorm              262 1.0 4.8624e+0029.7 2.23e+08 1.1 0.0e+00 0.0e+00 2.6e+02  2  0  0  0 32   2  0  0  0 32   875
VecScale              11 1.0 3.5005e-03 1.3 4.67e+06 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 25518
VecCopy              505 1.0 3.5284e-01 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet               509 1.0 1.5195e-01 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY              499 1.0 4.4415e-01 1.1 4.24e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 18247
VecAYPX              751 1.0 8.2745e-01 1.1 5.31e+08 1.1 0.0e+00 0.0e+00 0.0e+00  1  1  0  0  0   1  1  0  0  0 12267
VecAXPBYCZ           251 1.0 3.3478e-01 1.1 5.33e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 30442
VecMAXPY              11 1.0 3.5918e-02 1.1 5.52e+07 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 29391
VecAssemblyBegin       3 1.0 9.6414e-03 1.0 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAssemblyEnd         3 1.0 6.0937e-04 4.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecScatterBegin      512 1.0 3.2286e-01 2.0 0.00e+00 0.0 7.5e+04 4.6e+04 0.0e+00  0  0 98 68  0   0  0 98 68  0     0
VecScatterEnd        512 1.0 7.3942e+0097.5 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  2  0  0  0  0   2  0  0  0  0     0
VecNormalize          11 1.0 4.0861e-02 3.9 1.40e+07 1.1 0.0e+00 0.0e+00 1.1e+01  0  0  0  0  1   0  0  0  0  1  6558
SFSetGraph             2 1.0 5.2810e-04 2.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.1886e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  1  0  0   0  0  1  0  0     0
SFBcastOpBegin       512 1.0 3.2188e-01 2.0 0.00e+00 0.0 7.5e+04 4.6e+04 0.0e+00  0  0 98 68  0   0  0 98 68  0     0
SFBcastOpEnd         512 1.0 7.3931e+0099.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  2  0  0  0  0   2  0  0  0  0     0
SFPack               512 1.0 3.0923e-01 2.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack             512 1.0 3.3680e-04 1.5 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               2 1.0 2.3198e+00 1.0 1.23e+09 1.1 1.5e+03 4.6e+04 2.3e+01  2  2  2  1  3   2  2  2  1  3 10089
KSPSolve               1 1.0 1.0525e+02 1.0 5.66e+10 1.1 7.5e+04 4.6e+04 7.7e+02 78100 97 68 95  78100 97 68 95 10217
KSPGMRESOrthog        10 1.0 1.9082e-01 3.7 9.34e+07 1.1 0.0e+00 0.0e+00 1.0e+01  0  0  0  0  1   0  0  0  0  1  9362
PCSetUp                1 1.0 2.3186e+00 1.0 1.23e+09 1.1 1.5e+03 4.6e+04 2.3e+01  2  2  2  1  3   2  2  2  1  3 10094
PCApply              262 1.0 8.2776e+01 1.1 4.13e+10 1.1 3.7e+04 4.6e+04 0.0e+00 60 73 48 33  0  60 73 48 33  0  9467
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     3              3    354240752     0.
           Index Set     4              4       304416     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    29             29     88992944     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     4              4        35216     0.
      Preconditioner     4              4         4256     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 3.06e-08
Average time for MPI_Barrier(): 5.0232e-06
Average time for zero size MPI_Send(): 3.5033e-06
#PETSc Option Table entries:
-d 3
-ksp_type cg
-log_view
-mat_type aij
-n 100
-pc_type mg
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type gmres -pc_type bjacobi -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 15:34:23 2020            |
| OS:             Linux                               |
| HostName:       sdumont6180                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.7713, Active time=2.83393                                        |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.3913      0.000008    0.3913      0.000008    13.81    13.81    |
| Ke                            50792      1.7278      0.000034    1.7278      0.000034    60.97    60.97    |
| elem init                     50792      0.7148      0.000014    0.7148      0.000014    25.22    25.22    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.8339                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 165.177458
Tempo total: 165.162398
Tempo total: 165.191609
Tempo total: 165.205144
Tempo total: 165.167055
Tempo total: 165.221080
Tempo total: 165.165361
Tempo total: 165.192278
Tempo total: 165.161679
Tempo total: 165.191471
Tempo total: 165.178120
Tempo total: 165.185192
Tempo total: 165.175819
Tempo total: 165.145131
Tempo total: 165.166591
Tempo total: 165.136854
Tempo total: 165.152598
Tempo total: 165.134171
Tempo total: 165.158343
Tempo total: 165.209327
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6180 with 20 processors, by luciano.siqueira Thu Dec 10 15:36:41 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           1.656e+02     1.000   1.656e+02
Objects:              6.400e+01     1.000   6.400e+01
Flop:                 1.036e+11     1.104   9.855e+10  1.971e+12
Flop/sec:             6.256e+08     1.104   5.952e+08  1.190e+10
MPI Messages:         8.578e+03     2.726   5.707e+03  1.141e+05
MPI Message Lengths:  4.300e+08     1.703   5.918e+04  6.755e+09
MPI Reductions:       1.556e+03     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 1.6557e+02 100.0%  1.9710e+12 100.0%  1.141e+05 100.0%  5.918e+04      100.0%  1.549e+03  99.6%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 4.2269e-01115.8 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  0  0  0  0  0   0  0  0  0  0     0
BuildTwoSidedF         5 1.0 4.2260e-01128.3 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  0  0  0  3  0   0  0  0  3  0     0
MatMult              768 1.0 6.2474e+01 1.1 4.10e+10 1.1 1.1e+05 4.6e+04 0.0e+00 37 40 98 76  0  37 40 98 76  0 12536
MatSolve             769 1.0 6.1163e+01 1.1 4.02e+10 1.1 0.0e+00 0.0e+00 0.0e+00 35 39  0  0  0  35 39  0  0  0 12431
MatLUFactorNum         1 1.0 2.4403e+00 1.1 1.27e+09 1.1 0.0e+00 0.0e+00 0.0e+00  1  1  0  0  0   1  1  0  0  0  9915
MatILUFactorSym        1 1.0 1.5125e-01 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatAssemblyBegin       2 1.0 4.9653e-01 3.1 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  0  0  0  3  0   0  0  0  3  0     0
MatAssemblyEnd         2 1.0 3.0834e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  0  0  0  0  0   0  0  0  0  0    14
MatGetRowIJ            1 1.0 3.8560e-06 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatGetOrdering         1 1.0 4.1659e-03 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatZeroEntries         3 1.0 1.2161e-01 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecMDot              743 1.0 1.1510e+01 2.6 9.71e+09 1.1 0.0e+00 0.0e+00 7.4e+02  5  9  0  0 48   5  9  0  0 48 16137
VecNorm              769 1.0 1.2206e+00 2.6 6.53e+08 1.1 0.0e+00 0.0e+00 7.7e+02  0  1  0  0 49   0  1  0  0 50 10233
VecScale             768 1.0 1.9647e-01 1.1 3.26e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 31744
VecCopy               26 1.0 1.8166e-02 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet               799 1.0 3.7270e-01 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY               50 1.0 3.1224e-02 1.2 4.25e+07 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 26008
VecMAXPY             768 1.0 6.1793e+00 1.1 1.03e+10 1.1 0.0e+00 0.0e+00 0.0e+00  4 10  0  0  0   4 10  0  0  0 32010
VecAssemblyBegin       3 1.0 9.6137e-03 1.1 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAssemblyEnd         3 1.0 5.9814e-04 4.5 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecScatterBegin      769 1.0 3.5603e-01 2.6 0.00e+00 0.0 1.1e+05 4.6e+04 0.0e+00  0  0 98 76  0   0  0 98 76  0     0
VecScatterEnd        769 1.0 5.4693e+0052.5 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  2  0  0  0  0   2  0  0  0  0     0
VecNormalize         768 1.0 1.4061e+00 2.2 9.79e+08 1.1 0.0e+00 0.0e+00 7.7e+02  1  1  0  0 49   1  1  0  0 50 13306
SFSetGraph             2 1.0 4.8963e-04 1.8 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.0953e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  1  0  0   0  0  1  0  0     0
SFBcastOpBegin       769 1.0 3.5483e-01 2.6 0.00e+00 0.0 1.1e+05 4.6e+04 0.0e+00  0  0 98 76  0   0  0 98 76  0     0
SFBcastOpEnd         769 1.0 5.4673e+0053.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  2  0  0  0  0   2  0  0  0  0     0
SFPack               769 1.0 3.4096e-01 2.7 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack             769 1.0 5.4587e-04 1.7 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               2 1.0 2.6366e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSolve               1 1.0 1.3667e+02 1.0 1.04e+11 1.1 1.1e+05 4.6e+04 1.5e+03 83100 98 76 97  83100 98 76 98 14420
KSPGMRESOrthog       743 1.0 1.6852e+01 1.7 1.94e+10 1.1 0.0e+00 0.0e+00 7.4e+02  8 19  0  0 48   8 19  0  0 48 22043
PCSetUp                2 1.0 2.6037e+00 1.1 1.27e+09 1.1 0.0e+00 0.0e+00 0.0e+00  1  1  0  0  0   1  1  0  0  0  9293
PCSetUpOnBlocks        1 1.0 2.5958e+00 1.1 1.27e+09 1.1 0.0e+00 0.0e+00 0.0e+00  1  1  0  0  0   1  1  0  0  0  9321
PCApply              769 1.0 6.1530e+01 1.1 4.02e+10 1.1 0.0e+00 0.0e+00 0.0e+00 35 39  0  0  0  35 39  0  0  0 12357
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     4              4    666933972     0.
           Index Set     7              7      5403804     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    43             43    129789840     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     2              2        20072     0.
      Preconditioner     2              2         1944     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 2.86e-08
Average time for MPI_Barrier(): 4.8126e-06
Average time for zero size MPI_Send(): 3.34115e-06
#PETSc Option Table entries:
-d 3
-ksp_type gmres
-log_view
-mat_type aij
-n 100
-pc_type bjacobi
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type gmres -pc_type jacobi -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 15:37:12 2020            |
| OS:             Linux                               |
| HostName:       sdumont6180                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.85898, Active time=2.89466                                       |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.4001      0.000008    0.4001      0.000008    13.82    13.82    |
| Ke                            50792      1.7698      0.000035    1.7698      0.000035    61.14    61.14    |
| elem init                     50792      0.7248      0.000014    0.7248      0.000014    25.04    25.04    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.8947                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 194.518300
Tempo total: 194.543683
Tempo total: 194.499778
Tempo total: 194.557695
Tempo total: 194.515318
Tempo total: 194.538076
Tempo total: 194.503683
Tempo total: 194.535757
Tempo total: 194.501727
Tempo total: 194.541714
Tempo total: 194.497298
Tempo total: 194.537200
Tempo total: 194.493266
Tempo total: 194.465980
Tempo total: 194.505491
Tempo total: 194.522334
Tempo total: 194.497213
Tempo total: 194.518602
Tempo total: 194.489700
Tempo total: 194.551489
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6180 with 20 processors, by luciano.siqueira Thu Dec 10 15:39:59 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           1.949e+02     1.000   1.949e+02
Objects:              5.700e+01     1.000   5.700e+01
Flop:                 1.370e+11     1.098   1.308e+11  2.616e+12
Flop/sec:             7.029e+08     1.098   6.712e+08  1.342e+10
MPI Messages:         1.864e+04     2.739   1.239e+04  2.477e+05
MPI Message Lengths:  8.416e+08     1.823   5.199e+04  1.288e+10
MPI Reductions:       3.358e+03     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 1.9489e+02 100.0%  2.6161e+12 100.0%  2.477e+05 100.0%  5.199e+04      100.0%  3.351e+03  99.8%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 4.4440e-0187.8 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  0  0  0  0  0   0  0  0  0  0     0
BuildTwoSidedF         5 1.0 4.4419e-01101.0 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  0  0  0  2  0   0  0  0  2  0     0
MatMult             1683 1.0 1.3735e+02 1.1 8.99e+10 1.1 2.5e+05 4.6e+04 0.0e+00 69 66 99 87  0  69 66 99 87  0 12495
MatAssemblyBegin       2 1.0 5.2060e-01 3.3 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  0  0  0  2  0   0  0  0  2  0     0
MatAssemblyEnd         2 1.0 3.4361e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  0  0  0  0  0   0  0  0  0  0    13
MatZeroEntries         3 1.0 1.2206e-01 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecMDot             1628 1.0 1.7049e+01 1.7 2.14e+10 1.1 0.0e+00 0.0e+00 1.6e+03  7 16  0  0 48   7 16  0  0 49 23954
VecNorm             1684 1.0 2.4105e+00 2.3 1.43e+09 1.1 0.0e+00 0.0e+00 1.7e+03  1  1  0  0 50   1  1  0  0 50 11346
VecScale            1683 1.0 6.2287e-01 1.1 7.15e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 21942
VecCopy               56 1.0 3.9109e-02 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet                60 1.0 3.1234e-02 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY              110 1.0 6.8172e-02 1.3 9.34e+07 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 26206
VecMAXPY            1683 1.0 1.4310e+01 1.1 2.27e+10 1.1 0.0e+00 0.0e+00 0.0e+00  7 17  0  0  0   7 17  0  0  0 30387
VecAssemblyBegin       3 1.0 1.0188e-02 1.1 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAssemblyEnd         3 1.0 5.7151e-04 4.5 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecPointwiseMult    1684 1.0 2.2020e+00 1.2 7.15e+08 1.1 0.0e+00 0.0e+00 0.0e+00  1  1  0  0  0   1  1  0  0  0  6210
VecScatterBegin     1684 1.0 9.0057e-01 2.4 0.00e+00 0.0 2.5e+05 4.6e+04 0.0e+00  0  0 99 88  0   0  0 99 88  0     0
VecScatterEnd       1684 1.0 1.3036e+0147.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  3  0  0  0  0   3  0  0  0  0     0
VecNormalize        1683 1.0 2.9781e+00 1.8 2.14e+09 1.1 0.0e+00 0.0e+00 1.7e+03  1  2  0  0 50   1  2  0  0 50 13768
SFSetGraph             2 1.0 5.1736e-04 1.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.1523e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFBcastOpBegin      1684 1.0 8.9756e-01 2.4 0.00e+00 0.0 2.5e+05 4.6e+04 0.0e+00  0  0 99 88  0   0  0 99 88  0     0
SFBcastOpEnd        1684 1.0 1.3032e+0147.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  3  0  0  0  0   3  0  0  0  0     0
SFPack              1684 1.0 8.6815e-01 2.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack            1684 1.0 1.0484e-03 1.6 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               1 1.0 2.6590e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSolve               1 1.0 1.6581e+02 1.0 1.37e+11 1.1 2.5e+05 4.6e+04 3.3e+03 85100 99 87 99  85100 99 87 99 15777
KSPGMRESOrthog      1628 1.0 2.9988e+01 1.3 4.27e+10 1.1 0.0e+00 0.0e+00 1.6e+03 13 31  0  0 48  13 31  0  0 49 27237
PCSetUp                1 1.0 1.0350e-06 3.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
PCApply             1684 1.0 2.2776e+00 1.2 7.15e+08 1.1 0.0e+00 0.0e+00 2.0e+00  1  1  0  0  0   1  1  0  0  0  6004
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     3              3    344047400     0.
           Index Set     4              4       304416     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    42             42    133186184     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     1              1        18656     0.
      Preconditioner     1              1          968     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 2.89e-08
Average time for MPI_Barrier(): 4.9476e-06
Average time for zero size MPI_Send(): 3.4829e-06
#PETSc Option Table entries:
-d 3
-ksp_type gmres
-log_view
-mat_type aij
-n 100
-pc_type jacobi
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type gmres -pc_type sor -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 15:40:30 2020            |
| OS:             Linux                               |
| HostName:       sdumont6180                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.82505, Active time=2.87925                                       |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.4001      0.000008    0.4001      0.000008    13.90    13.90    |
| Ke                            50792      1.7594      0.000035    1.7594      0.000035    61.11    61.11    |
| elem init                     50792      0.7198      0.000014    0.7198      0.000014    25.00    25.00    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.8793                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 249.622144
Tempo total: 249.611245
Tempo total: 249.583875
Tempo total: 249.611254
Tempo total: 249.603958
Tempo total: 249.557847
Tempo total: 249.586639
Tempo total: 249.597512
Tempo total: 249.564403
Tempo total: 249.596408
Tempo total: 249.564914
Tempo total: 249.579476
Tempo total: 249.559880
Tempo total: 249.580253
Tempo total: 249.567291
Tempo total: 249.578911
Tempo total: 249.555826
Tempo total: 249.576064
Tempo total: 249.550553
Tempo total: 249.635290
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6180 with 20 processors, by luciano.siqueira Thu Dec 10 15:44:12 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           2.500e+02     1.000   2.500e+02
Objects:              5.600e+01     1.000   5.600e+01
Flop:                 1.363e+11     1.104   1.296e+11  2.593e+12
Flop/sec:             5.451e+08     1.104   5.186e+08  1.037e+10
MPI Messages:         1.134e+04     2.732   7.540e+03  1.508e+05
MPI Message Lengths:  5.429e+08     1.752   5.594e+04  8.435e+09
MPI Reductions:       2.050e+03     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 2.4996e+02 100.0%  2.5928e+12 100.0%  1.508e+05 100.0%  5.594e+04      100.0%  2.043e+03  99.7%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 6.7218e-0199.3 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  0  0  0  0  0   0  0  0  0  0     0
BuildTwoSidedF         5 1.0 6.7058e-01140.6 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  0  0  0  2  0   0  0  0  2  0     0
MatMult             1019 1.0 8.3317e+01 1.1 5.44e+10 1.1 1.5e+05 4.6e+04 0.0e+00 33 40 99 81  0  33 40 99 81  0 12472
MatSOR              1020 1.0 1.2334e+02 1.1 5.37e+10 1.1 0.0e+00 0.0e+00 0.0e+00 46 39  0  0  0  46 39  0  0  0  8244
MatAssemblyBegin       2 1.0 7.9542e-01 4.0 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  0  0  0  2  0   0  0  0  2  0     0
MatAssemblyEnd         2 1.0 3.3083e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  0  0  0  0  0   0  0  0  0  0    13
MatZeroEntries         3 1.0 1.2169e-01 1.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecMDot              986 1.0 2.0802e+01 3.7 1.29e+10 1.1 0.0e+00 0.0e+00 9.9e+02  5 10  0  0 48   5 10  0  0 48 11892
VecNorm             1020 1.0 1.7386e+00 2.7 8.66e+08 1.1 0.0e+00 0.0e+00 1.0e+03  0  1  0  0 50   0  1  0  0 50  9528
VecScale            1019 1.0 3.0339e-01 1.2 4.33e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 27274
VecCopy               34 1.0 2.3006e-02 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet                38 1.0 1.9386e-02 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY               66 1.0 3.9418e-02 1.2 5.61e+07 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 27194
VecMAXPY            1019 1.0 8.2839e+00 1.1 1.38e+10 1.1 0.0e+00 0.0e+00 0.0e+00  3 10  0  0  0   3 10  0  0  0 31795
VecAssemblyBegin       3 1.0 1.0351e-02 1.2 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAssemblyEnd         3 1.0 6.0539e-04 4.8 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecScatterBegin     1020 1.0 5.0969e-01 2.7 0.00e+00 0.0 1.5e+05 4.6e+04 0.0e+00  0  0 99 81  0   0  0 99 81  0     0
VecScatterEnd       1020 1.0 7.8843e+0056.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
VecNormalize        1019 1.0 1.9843e+00 2.2 1.30e+09 1.1 0.0e+00 0.0e+00 1.0e+03  1  1  0  0 50   1  1  0  0 50 12511
SFSetGraph             2 1.0 5.0654e-04 1.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.1256e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFBcastOpBegin      1020 1.0 5.0743e-01 2.8 0.00e+00 0.0 1.5e+05 4.6e+04 0.0e+00  0  0 99 81  0   0  0 99 81  0     0
SFBcastOpEnd        1020 1.0 7.8819e+0057.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
SFPack              1020 1.0 4.8523e-01 2.8 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack            1020 1.0 7.7393e-04 2.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               1 1.0 2.6477e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSolve               1 1.0 2.1996e+02 1.0 1.36e+11 1.1 1.5e+05 4.6e+04 2.0e+03 88100 99 81 98  88100 99 81 98 11786
KSPGMRESOrthog       986 1.0 2.7974e+01 2.1 2.59e+10 1.1 0.0e+00 0.0e+00 9.9e+02  8 19  0  0 48   8 19  0  0 48 17686
PCSetUp                1 1.0 5.2300e-07 3.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
PCApply             1020 1.0 1.2335e+02 1.1 5.37e+10 1.1 0.0e+00 0.0e+00 0.0e+00 46 39  0  0  0  46 39  0  0  0  8243
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     3              3    354240752     0.
           Index Set     4              4       304416     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    41             41    129786704     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     1              1        18656     0.
      Preconditioner     1              1          968     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 2.79e-08
Average time for MPI_Barrier(): 4.9454e-06
Average time for zero size MPI_Send(): 3.3906e-06
#PETSc Option Table entries:
-d 3
-ksp_type gmres
-log_view
-mat_type aij
-n 100
-pc_type sor
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type gmres -pc_type mg -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 15:44:43 2020            |
| OS:             Linux                               |
| HostName:       sdumont6180                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.84787, Active time=2.88119                                       |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.3971      0.000008    0.3971      0.000008    13.78    13.78    |
| Ke                            50792      1.7577      0.000035    1.7577      0.000035    61.00    61.00    |
| elem init                     50792      0.7264      0.000014    0.7264      0.000014    25.21    25.21    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.8812                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 187.911457
Tempo total: 187.925834
Tempo total: 187.859033
Tempo total: 187.924591
Tempo total: 187.850820
Tempo total: 187.863446
Tempo total: 187.868684
Tempo total: 187.869656
Tempo total: 187.814623
Tempo total: 187.856770
Tempo total: 187.824709
Tempo total: 187.806163
Tempo total: 187.826070
Tempo total: 187.845325
Tempo total: 187.817305
Tempo total: 187.796158
Tempo total: 187.817750
Tempo total: 187.797229
Tempo total: 187.823586
Tempo total: 187.826598
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6180 with 20 processors, by luciano.siqueira Thu Dec 10 15:47:23 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           1.882e+02     1.000   1.882e+02
Objects:              8.100e+01     1.000   8.100e+01
Flop:                 9.162e+10     1.105   8.713e+10  1.743e+12
Flop/sec:             4.867e+08     1.105   4.629e+08  9.258e+09
MPI Messages:         8.412e+03     2.726   5.598e+03  1.120e+05
MPI Message Lengths:  4.233e+08     1.699   5.944e+04  6.654e+09
MPI Reductions:       7.980e+02     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 1.8824e+02 100.0%  1.7426e+12 100.0%  1.120e+05 100.0%  5.944e+04      100.0%  7.910e+02  99.1%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 4.6924e-01102.3 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  0  0  0  0  1   0  0  0  0  1     0
BuildTwoSidedF         5 1.0 4.6966e-01111.3 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  0  0  0  3  1   0  0  0  3  1     0
MatMult              753 1.0 6.5979e+01 1.1 4.02e+10 1.1 1.1e+05 4.6e+04 0.0e+00 33 44 98 76  0  33 44 98 76  0 11638
MatSOR               755 1.0 9.0532e+01 1.1 3.98e+10 1.1 0.0e+00 0.0e+00 0.0e+00 45 43  0  0  0  45 43  0  0  0  8313
MatAssemblyBegin       2 1.0 5.4570e-01 3.0 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  0  0  0  3  0   0  0  0  3  0     0
MatAssemblyEnd         2 1.0 3.3383e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  0  0  0  0  1   0  0  0  0  1    13
MatZeroEntries         3 1.0 1.2219e-01 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecMDot              369 1.0 8.4181e+00 4.2 4.76e+09 1.1 0.0e+00 0.0e+00 3.7e+02  3  5  0  0 46   3  5  0  0 47 10814
VecNorm              383 1.0 6.5412e-01 3.0 3.25e+08 1.1 0.0e+00 0.0e+00 3.8e+02  0  0  0  0 48   0  0  0  0 48  9510
VecScale             382 1.0 1.0487e-01 1.4 1.62e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 29581
VecCopy              758 1.0 5.0121e-01 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet               763 1.0 2.3436e-01 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY               25 1.0 1.6896e-02 1.3 2.12e+07 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 24031
VecAYPX              744 1.0 8.3452e-01 1.1 4.74e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 10860
VecAXPBYCZ           372 1.0 5.0065e-01 1.1 7.90e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 30169
VecMAXPY             382 1.0 3.0279e+00 1.1 5.07e+09 1.1 0.0e+00 0.0e+00 0.0e+00  2  6  0  0  0   2  6  0  0  0 32044
VecAssemblyBegin       3 1.0 1.0213e-02 1.1 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAssemblyEnd         3 1.0 5.6568e-04 4.8 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecScatterBegin      754 1.0 4.1549e-01 2.3 0.00e+00 0.0 1.1e+05 4.6e+04 0.0e+00  0  0 98 76  0   0  0 98 76  0     0
VecScatterEnd        754 1.0 1.1020e+0185.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  3  0  0  0  0   3  0  0  0  0     0
VecNormalize         382 1.0 7.4683e-01 2.6 4.87e+08 1.1 0.0e+00 0.0e+00 3.8e+02  0  1  0  0 48   0  1  0  0 48 12461
SFSetGraph             2 1.0 4.9783e-04 1.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.1097e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  1  0  0   0  0  1  0  0     0
SFBcastOpBegin       754 1.0 4.1407e-01 2.3 0.00e+00 0.0 1.1e+05 4.6e+04 0.0e+00  0  0 98 76  0   0  0 98 76  0     0
SFBcastOpEnd         754 1.0 1.1018e+0187.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  3  0  0  0  0   3  0  0  0  0     0
SFPack               754 1.0 3.9788e-01 2.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack             754 1.0 6.0102e-04 1.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               2 1.0 2.3139e+00 1.0 1.23e+09 1.1 1.5e+03 4.6e+04 2.3e+01  1  1  1  1  3   1  1  1  1  3 10114
KSPSolve               1 1.0 1.5871e+02 1.0 9.16e+10 1.1 1.1e+05 4.6e+04 7.5e+02 84100 98 76 94  84100 98 76 95 10979
KSPGMRESOrthog       369 1.0 1.1049e+01 2.3 9.52e+09 1.1 0.0e+00 0.0e+00 3.7e+02  4 10  0  0 46   4 10  0  0 47 16477
PCSetUp                1 1.0 2.3117e+00 1.0 1.23e+09 1.1 1.5e+03 4.6e+04 2.3e+01  1  1  1  1  3   1  1  1  1  3 10124
PCApply              383 1.0 1.2238e+02 1.0 6.09e+10 1.1 5.4e+04 4.6e+04 0.0e+00 63 66 49 37  0  63 66 49 37  0  9447
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     3              3    354240752     0.
           Index Set     4              4       304416     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    60             60    194376824     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     4              4        52200     0.
      Preconditioner     4              4         4256     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 2.77e-08
Average time for MPI_Barrier(): 4.8532e-06
Average time for zero size MPI_Send(): 3.2629e-06
#PETSc Option Table entries:
-d 3
-ksp_type gmres
-log_view
-mat_type aij
-n 100
-pc_type mg
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type fcg -pc_type bjacobi -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 15:47:53 2020            |
| OS:             Linux                               |
| HostName:       sdumont6180                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.88134, Active time=2.91415                                       |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.4199      0.000008    0.4199      0.000008    14.41    14.41    |
| Ke                            50792      1.7652      0.000035    1.7652      0.000035    60.57    60.57    |
| elem init                     50792      0.7291      0.000014    0.7291      0.000014    25.02    25.02    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.9142                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 104.508198
Tempo total: 104.451317
Tempo total: 104.486366
Tempo total: 104.465639
Tempo total: 104.492333
Tempo total: 104.442996
Tempo total: 104.469125
Tempo total: 104.452222
Tempo total: 104.467922
Tempo total: 104.441489
Tempo total: 104.414560
Tempo total: 104.439013
Tempo total: 104.415111
Tempo total: 104.443108
Tempo total: 104.464207
Tempo total: 104.429795
Tempo total: 104.463856
Tempo total: 104.432356
Tempo total: 104.504911
Tempo total: 104.486340
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6180 with 20 processors, by luciano.siqueira Thu Dec 10 15:49:10 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           1.049e+02     1.000   1.049e+02
Objects:              9.400e+01     1.000   9.400e+01
Flop:                 5.619e+10     1.104   5.346e+10  1.069e+12
Flop/sec:             5.358e+08     1.104   5.098e+08  1.020e+10
MPI Messages:         4.562e+03     2.706   3.043e+03  6.086e+04
MPI Message Lengths:  2.659e+08     1.572   7.085e+04  4.311e+09
MPI Reductions:       1.653e+03     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 1.0487e+02 100.0%  1.0692e+12 100.0%  6.086e+04 100.0%  7.085e+04      100.0%  1.646e+03  99.6%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 4.8207e-0198.5 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  0  0  1  0  0   0  0  1  0  0     0
BuildTwoSidedF         5 1.0 4.8055e-01118.9 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  0  0  1  5  0   0  0  1  5  0     0
MatMult              403 1.0 3.2887e+01 1.0 2.15e+10 1.1 5.9e+04 4.6e+04 0.0e+00 31 38 97 63  0  31 38 97 63  0 12496
MatSolve             404 1.0 3.2097e+01 1.1 2.11e+10 1.1 0.0e+00 0.0e+00 0.0e+00 29 37  0  0  0  29 37  0  0  0 12445
MatLUFactorNum         1 1.0 2.4400e+00 1.1 1.27e+09 1.1 0.0e+00 0.0e+00 0.0e+00  2  2  0  0  0   2  2  0  0  0  9917
MatILUFactorSym        1 1.0 1.5365e-01 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatAssemblyBegin       2 1.0 5.5266e-01 3.9 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  0  0  0  5  0   0  0  0  5  0     0
MatAssemblyEnd         2 1.0 3.4084e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  0  0  0  0  0   0  0  0  0  0    13
MatGetRowIJ            1 1.0 4.2330e-06 1.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatGetOrdering         1 1.0 4.1427e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatZeroEntries         3 1.0 1.2276e-01 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecTDot              804 1.0 2.1773e+00 3.9 6.83e+08 1.1 0.0e+00 0.0e+00 8.0e+02  1  1  0  0 49   1  1  0  0 49  5997
VecMTDot             401 1.0 2.5558e+00 1.0 5.19e+09 1.1 0.0e+00 0.0e+00 4.0e+02  2  9  0  0 24   2  9  0  0 24 38833
VecNorm              404 1.0 3.6324e+0016.4 3.43e+08 1.1 0.0e+00 0.0e+00 4.0e+02  2  1  0  0 24   2  1  0  0 25  1806
VecScale             401 1.0 2.4638e-01 1.1 1.70e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 13217
VecCopy              403 1.0 2.6998e-01 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet               409 1.0 2.0596e-01 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY              804 1.0 7.4208e-01 1.1 6.83e+08 1.1 0.0e+00 0.0e+00 0.0e+00  1  1  0  0  0   1  1  0  0  0 17596
VecAYPX                1 1.0 1.1423e-03 1.1 4.25e+05 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0  7109
VecMAXPY             401 1.0 3.3275e+00 1.1 5.19e+09 1.1 0.0e+00 0.0e+00 0.0e+00  3  9  0  0  0   3  9  0  0  0 29827
VecAssemblyBegin       3 1.0 9.6304e-03 1.0 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAssemblyEnd         3 1.0 6.0671e-04 4.7 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecScatterBegin      404 1.0 2.6365e-01 2.1 0.00e+00 0.0 5.9e+04 4.6e+04 0.0e+00  0  0 97 63  0   0  0 97 63  0     0
VecScatterEnd        404 1.0 3.3370e+0064.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
SFSetGraph             2 1.0 5.1562e-04 1.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.1444e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  1  0  0   0  0  1  0  0     0
SFBcastOpBegin       404 1.0 2.6293e-01 2.1 0.00e+00 0.0 5.9e+04 4.6e+04 0.0e+00  0  0 97 63  0   0  0 97 63  0     0
SFBcastOpEnd         404 1.0 3.3361e+0065.5 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
SFPack               404 1.0 2.5570e-01 2.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack             404 1.0 2.3924e-04 1.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               2 1.0 1.5242e-02 1.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSolve               1 1.0 7.5663e+01 1.0 5.62e+10 1.1 5.9e+04 4.6e+04 1.6e+03 72100 97 63 97  72100 97 63 98 14129
PCSetUp                2 1.0 2.6049e+00 1.1 1.27e+09 1.1 0.0e+00 0.0e+00 0.0e+00  2  2  0  0  0   2  2  0  0  0  9289
PCSetUpOnBlocks        1 1.0 2.5978e+00 1.1 1.27e+09 1.1 0.0e+00 0.0e+00 0.0e+00  2  2  0  0  0   2  2  0  0  0  9314
PCApply              404 1.0 3.2303e+01 1.1 2.11e+10 1.1 0.0e+00 0.0e+00 0.0e+00 29 37  0  0  0  29 37  0  0  0 12365
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     4              4    666933972     0.
           Index Set     7              7      5403804     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    73             73    231774240     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     2              2         4264     0.
      Preconditioner     2              2         1944     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 2.92e-08
Average time for MPI_Barrier(): 5.2116e-06
Average time for zero size MPI_Send(): 3.3846e-06
#PETSc Option Table entries:
-d 3
-ksp_type fcg
-log_view
-mat_type aij
-n 100
-pc_type bjacobi
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type fcg -pc_type jacobi -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 15:49:40 2020            |
| OS:             Linux                               |
| HostName:       sdumont6180                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.8527, Active time=2.88643                                        |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.4007      0.000008    0.4007      0.000008    13.88    13.88    |
| Ke                            50792      1.7624      0.000035    1.7624      0.000035    61.06    61.06    |
| elem init                     50792      0.7234      0.000014    0.7234      0.000014    25.06    25.06    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.8864                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 42.095638
Tempo total: 42.072443
Tempo total: 42.035082
Tempo total: 42.072078
Tempo total: 42.007259
Tempo total: 42.032249
Tempo total: 42.007882
Tempo total: 41.977767
Tempo total: 41.996622
Tempo total: 42.029481
Tempo total: 42.007608
Tempo total: 41.980192
Tempo total: 42.000480
Tempo total: 41.966003
Tempo total: 41.990590
Tempo total: 42.023657
Tempo total: 41.998593
Tempo total: 41.972535
Tempo total: 41.992004
Tempo total: 42.067422
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6180 with 20 processors, by luciano.siqueira Thu Dec 10 15:49:55 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           4.242e+01     1.000   4.242e+01
Objects:              8.700e+01     1.000   8.700e+01
Flop:                 1.131e+10     1.098   1.080e+10  2.159e+11
Flop/sec:             2.665e+08     1.098   2.545e+08  5.090e+09
MPI Messages:         1.626e+03     2.630   1.094e+03  2.187e+04
MPI Message Lengths:  1.458e+08     1.348   1.154e+05  2.524e+09
MPI Reductions:       5.870e+02     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 4.2418e+01 100.0%  2.1593e+11 100.0%  2.187e+04 100.0%  1.154e+05      100.0%  5.800e+02  98.8%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 4.2143e-01179.9 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  0  0  2  0  1   0  0  2  0  1     0
BuildTwoSidedF         5 1.0 4.2006e-012920.7 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  0  0  2  8  1   0  0  2  8  1     0
MatMult              136 1.0 1.1099e+01 1.1 7.27e+09 1.1 2.0e+04 4.6e+04 0.0e+00 26 64 91 36  0  26 64 91 36  0 12495
MatAssemblyBegin       2 1.0 5.1524e-01 4.2 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  1  0  1  8  0   1  0  1  8  0     0
MatAssemblyEnd         2 1.0 3.4064e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  1  0  1  0  1   1  0  1  0  1    13
MatZeroEntries         3 1.0 1.2084e-01 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecTDot              270 1.0 7.7237e-01 3.8 2.29e+08 1.1 0.0e+00 0.0e+00 2.7e+02  1  2  0  0 46   1  2  0  0 47  5677
VecMTDot             134 1.0 8.7262e-01 1.0 1.67e+09 1.1 0.0e+00 0.0e+00 1.3e+02  2 15  0  0 23   2 15  0  0 23 36572
VecNorm              137 1.0 1.3150e-01 1.6 1.16e+08 1.1 0.0e+00 0.0e+00 1.4e+02  0  1  0  0 23   0  1  0  0 24 16920
VecScale             134 1.0 7.3149e-02 1.1 5.69e+07 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 14876
VecCopy              136 1.0 1.0899e-01 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet                 5 1.0 1.7739e-03 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY              270 1.0 2.4557e-01 1.1 2.29e+08 1.1 0.0e+00 0.0e+00 0.0e+00  1  2  0  0  0   1  2  0  0  0 17857
VecAYPX                1 1.0 1.1378e-03 1.1 4.25e+05 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0  7137
VecMAXPY             134 1.0 1.0550e+00 1.1 1.67e+09 1.1 0.0e+00 0.0e+00 0.0e+00  2 15  0  0  0   2 15  0  0  0 30251
VecAssemblyBegin       3 1.0 9.7393e-03 1.0 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  1  0  1   0  0  1  0  1     0
VecAssemblyEnd         3 1.0 5.4539e-04 4.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecPointwiseMult     137 1.0 1.9079e-01 1.1 5.82e+07 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0  5831
VecScatterBegin      137 1.0 8.5398e-02 2.1 0.00e+00 0.0 2.0e+04 4.6e+04 0.0e+00  0  0 91 36  0   0  0 91 36  0     0
VecScatterEnd        137 1.0 1.0298e+0057.6 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
SFSetGraph             2 1.0 5.4694e-04 2.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.2065e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  3  0  0   0  0  3  0  0     0
SFBcastOpBegin       137 1.0 8.5150e-02 2.1 0.00e+00 0.0 2.0e+04 4.6e+04 0.0e+00  0  0 91 36  0   0  0 91 36  0     0
SFBcastOpEnd         137 1.0 1.0295e+0058.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
SFPack               137 1.0 8.1440e-02 2.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack             137 1.0 7.9613e-05 1.6 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               1 1.0 1.2492e-02 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSolve               1 1.0 1.4006e+01 1.0 1.13e+10 1.1 2.0e+04 4.6e+04 5.4e+02 33100 91 36 93  33100 91 36 94 15401
PCSetUp                1 1.0 1.1590e-06 5.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
PCApply              137 1.0 2.6213e-01 1.1 5.82e+07 1.1 0.0e+00 0.0e+00 2.0e+00  1  1  0  0  0   1  1  0  0  0  4244
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     3              3    344047400     0.
           Index Set     4              4       304416     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    72             72    235170584     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     1              1         2848     0.
      Preconditioner     1              1          968     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 2.86e-08
Average time for MPI_Barrier(): 5.2584e-06
Average time for zero size MPI_Send(): 3.278e-06
#PETSc Option Table entries:
-d 3
-ksp_type fcg
-log_view
-mat_type aij
-n 100
-pc_type jacobi
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type fcg -pc_type sor -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 15:50:26 2020            |
| OS:             Linux                               |
| HostName:       sdumont6180                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.79759, Active time=2.86882                                       |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.3969      0.000008    0.3969      0.000008    13.84    13.84    |
| Ke                            50792      1.7503      0.000034    1.7503      0.000034    61.01    61.01    |
| elem init                     50792      0.7216      0.000014    0.7216      0.000014    25.15    25.15    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.8688                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 131.890076
Tempo total: 131.859927
Tempo total: 131.875709
Tempo total: 131.855837
Tempo total: 131.854252
Tempo total: 131.840863
Tempo total: 131.853883
Tempo total: 131.841102
Tempo total: 131.851245
Tempo total: 131.887575
Tempo total: 131.877236
Tempo total: 131.885926
Tempo total: 131.849837
Tempo total: 131.880654
Tempo total: 131.855929
Tempo total: 131.869365
Tempo total: 131.853018
Tempo total: 131.868683
Tempo total: 131.846975
Tempo total: 131.905480
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6180 with 20 processors, by luciano.siqueira Thu Dec 10 15:52:10 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           1.323e+02     1.000   1.323e+02
Objects:              8.600e+01     1.000   8.600e+01
Flop:                 6.293e+10     1.104   5.988e+10  1.198e+12
Flop/sec:             4.758e+08     1.104   4.527e+08  9.054e+09
MPI Messages:         5.190e+03     2.711   3.459e+03  6.918e+04
MPI Message Lengths:  2.915e+08     1.600   6.784e+04  4.693e+09
MPI Reductions:       1.881e+03     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 1.3227e+02 100.0%  1.1976e+12 100.0%  6.918e+04 100.0%  6.784e+04      100.0%  1.874e+03  99.6%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 3.8637e-0182.8 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  0  0  1  0  0   0  0  1  0  0     0
BuildTwoSidedF         5 1.0 3.8535e-01112.0 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  0  0  1  4  0   0  0  1  4  0     0
MatMult              460 1.0 3.7629e+01 1.1 2.46e+10 1.1 6.7e+04 4.6e+04 0.0e+00 28 39 97 66  0  28 39 97 66  0 12466
MatSOR               461 1.0 5.5659e+01 1.1 2.43e+10 1.1 0.0e+00 0.0e+00 0.0e+00 39 38  0  0  0  39 38  0  0  0  8257
MatAssemblyBegin       2 1.0 5.1594e-01 3.1 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  0  0  0  4  0   0  0  0  4  0     0
MatAssemblyEnd         2 1.0 3.4206e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  0  0  0  0  0   0  0  0  0  0    13
MatZeroEntries         3 1.0 1.1998e-01 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecTDot              918 1.0 2.7659e+00 3.8 7.80e+08 1.1 0.0e+00 0.0e+00 9.2e+02  1  1  0  0 49   1  1  0  0 49  5390
VecMTDot             458 1.0 3.3143e+00 1.0 5.96e+09 1.1 0.0e+00 0.0e+00 4.6e+02  2 10  0  0 24   2 10  0  0 24 34356
VecNorm              461 1.0 6.6891e+0025.8 3.92e+08 1.1 0.0e+00 0.0e+00 4.6e+02  3  1  0  0 25   3  1  0  0 25  1119
VecScale             458 1.0 2.7718e-01 1.1 1.95e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 13418
VecCopy              460 1.0 3.3314e-01 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet                 5 1.0 1.7675e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY              918 1.0 8.5562e-01 1.2 7.80e+08 1.1 0.0e+00 0.0e+00 0.0e+00  1  1  0  0  0   1  1  0  0  0 17425
VecAYPX                1 1.0 1.2061e-03 1.2 4.25e+05 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0  6733
VecMAXPY             458 1.0 3.8523e+00 1.1 5.96e+09 1.1 0.0e+00 0.0e+00 0.0e+00  3 10  0  0  0   3 10  0  0  0 29558
VecAssemblyBegin       3 1.0 9.6496e-03 1.0 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAssemblyEnd         3 1.0 5.6231e-04 4.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecScatterBegin      461 1.0 2.9563e-01 2.1 0.00e+00 0.0 6.7e+04 4.6e+04 0.0e+00  0  0 97 66  0   0  0 97 66  0     0
VecScatterEnd        461 1.0 3.6108e+0062.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
SFSetGraph             2 1.0 5.3431e-04 2.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.1717e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  1  0  0   0  0  1  0  0     0
SFBcastOpBegin       461 1.0 2.9480e-01 2.1 0.00e+00 0.0 6.7e+04 4.6e+04 0.0e+00  0  0 97 66  0   0  0 97 66  0     0
SFBcastOpEnd         461 1.0 3.6098e+0063.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
SFPack               461 1.0 2.8679e-01 2.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack             461 1.0 3.0173e-04 1.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               1 1.0 1.5852e-02 1.5 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSolve               1 1.0 1.0276e+02 1.0 6.29e+10 1.1 6.7e+04 4.6e+04 1.8e+03 78100 97 66 98  78100 97 66 98 11652
PCSetUp                1 1.0 5.2000e-07 3.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
PCApply              461 1.0 5.5660e+01 1.1 2.43e+10 1.1 0.0e+00 0.0e+00 0.0e+00 39 38  0  0  0  39 38  0  0  0  8256
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     3              3    354240752     0.
           Index Set     4              4       304416     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    71             71    231771104     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     1              1         2848     0.
      Preconditioner     1              1          968     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 2.82e-08
Average time for MPI_Barrier(): 4.923e-06
Average time for zero size MPI_Send(): 3.38585e-06
#PETSc Option Table entries:
-d 3
-ksp_type fcg
-log_view
-mat_type aij
-n 100
-pc_type sor
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type fcg -pc_type mg -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 15:52:42 2020            |
| OS:             Linux                               |
| HostName:       sdumont6180                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.87132, Active time=2.89914                                       |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.4032      0.000008    0.4032      0.000008    13.91    13.91    |
| Ke                            50792      1.7673      0.000035    1.7673      0.000035    60.96    60.96    |
| elem init                     50792      0.7286      0.000014    0.7286      0.000014    25.13    25.13    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.8991                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 138.649226
Tempo total: 138.669892
Tempo total: 138.645458
Tempo total: 138.670956
Tempo total: 138.642764
Tempo total: 138.669663
Tempo total: 138.649509
Tempo total: 138.613971
Tempo total: 138.631897
Tempo total: 138.667493
Tempo total: 138.637929
Tempo total: 138.652779
Tempo total: 138.641312
Tempo total: 138.653427
Tempo total: 138.635070
Tempo total: 138.657322
Tempo total: 138.627262
Tempo total: 138.599877
Tempo total: 138.624426
Tempo total: 138.661893
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6180 with 20 processors, by luciano.siqueira Thu Dec 10 15:54:32 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           1.390e+02     1.000   1.390e+02
Objects:              1.110e+02     1.000   1.110e+02
Flop:                 6.285e+10     1.105   5.977e+10  1.195e+12
Flop/sec:             4.521e+08     1.105   4.299e+08  8.598e+09
MPI Messages:         5.750e+03     2.715   3.831e+03  7.662e+04
MPI Message Lengths:  3.144e+08     1.622   6.570e+04  5.034e+09
MPI Reductions:       1.064e+03     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 1.3904e+02 100.0%  1.1955e+12 100.0%  7.662e+04 100.0%  6.570e+04      100.0%  1.057e+03  99.3%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 4.8194e-01113.0 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  0  0  1  0  1   0  0  1  0  1     0
BuildTwoSidedF         5 1.0 4.7925e-01173.8 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  0  0  0  4  0   0  0  0  4  0     0
MatMult              511 1.0 4.4482e+01 1.1 2.73e+10 1.1 7.5e+04 4.6e+04 0.0e+00 30 44 97 68  0  30 44 97 68  0 11714
MatSOR               513 1.0 6.1000e+01 1.1 2.70e+10 1.1 0.0e+00 0.0e+00 0.0e+00 42 43  0  0  0  42 43  0  0  0  8383
MatAssemblyBegin       2 1.0 5.9568e-01 3.4 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  0  0  0  4  0   0  0  0  4  0     0
MatAssemblyEnd         2 1.0 3.4150e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  0  0  0  0  0   0  0  0  0  0    13
MatZeroEntries         3 1.0 1.2141e-01 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecMDot               10 1.0 1.5165e-01 6.9 4.67e+07 1.1 0.0e+00 0.0e+00 1.0e+01  0  0  0  0  1   0  0  0  0  1  5890
VecTDot              498 1.0 1.3356e+00 3.6 4.23e+08 1.1 0.0e+00 0.0e+00 5.0e+02  1  1  0  0 47   1  1  0  0 47  6056
VecMTDot             248 1.0 1.5595e+00 1.0 3.19e+09 1.1 0.0e+00 0.0e+00 2.5e+02  1  5  0  0 23   1  5  0  0 23 39117
VecNorm              262 1.0 3.8062e+0016.3 2.23e+08 1.1 0.0e+00 0.0e+00 2.6e+02  1  0  0  0 25   1  0  0  0 25  1118
VecScale             259 1.0 1.6327e-01 1.1 1.10e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 12882
VecCopy              753 1.0 5.2600e-01 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet               509 1.0 2.4010e-01 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY              499 1.0 4.5355e-01 1.1 4.24e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 17869
VecAYPX              503 1.0 5.6159e-01 1.1 3.20e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 10903
VecAXPBYCZ           251 1.0 3.3368e-01 1.1 5.33e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 30542
VecMAXPY             259 1.0 2.0838e+00 1.1 3.25e+09 1.1 0.0e+00 0.0e+00 0.0e+00  1  5  0  0  0   1  5  0  0  0 29781
VecAssemblyBegin       3 1.0 9.6321e-03 1.0 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAssemblyEnd         3 1.0 6.1431e-04 4.7 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecScatterBegin      512 1.0 3.2323e-01 2.1 0.00e+00 0.0 7.5e+04 4.6e+04 0.0e+00  0  0 98 68  0   0  0 98 68  0     0
VecScatterEnd        512 1.0 7.1157e+0035.8 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  2  0  0  0  0   2  0  0  0  0     0
VecNormalize          11 1.0 3.8013e-02 3.7 1.40e+07 1.1 0.0e+00 0.0e+00 1.1e+01  0  0  0  0  1   0  0  0  0  1  7050
SFSetGraph             2 1.0 5.2196e-04 2.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.1221e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  1  0  0   0  0  1  0  0     0
SFBcastOpBegin       512 1.0 3.2221e-01 2.1 0.00e+00 0.0 7.5e+04 4.6e+04 0.0e+00  0  0 98 68  0   0  0 98 68  0     0
SFBcastOpEnd         512 1.0 7.1146e+0035.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  2  0  0  0  0   2  0  0  0  0     0
SFPack               512 1.0 3.1053e-01 2.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack             512 1.0 3.5106e-04 1.7 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               2 1.0 2.3521e+00 1.0 1.23e+09 1.1 1.5e+03 4.6e+04 2.3e+01  2  2  2  1  2   2  2  2  1  2  9950
KSPSolve               1 1.0 1.0906e+02 1.0 6.28e+10 1.1 7.5e+04 4.6e+04 1.0e+03 78100 97 68 96  78100 97 68 96 10960
KSPGMRESOrthog        10 1.0 1.7975e-01 3.5 9.34e+07 1.1 0.0e+00 0.0e+00 1.0e+01  0  0  0  0  1   0  0  0  0  1  9939
PCSetUp                1 1.0 2.3413e+00 1.0 1.23e+09 1.1 1.5e+03 4.6e+04 2.3e+01  2  2  2  1  2   2  2  2  1  2  9996
PCApply              262 1.0 8.2649e+01 1.0 4.13e+10 1.1 3.7e+04 4.6e+04 0.0e+00 58 66 48 33  0  58 66 48 33  0  9482
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     3              3    354240752     0.
           Index Set     4              4       304416     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    90             90    296361224     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     4              4        36392     0.
      Preconditioner     4              4         4256     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 2.9e-08
Average time for MPI_Barrier(): 4.7328e-06
Average time for zero size MPI_Send(): 3.2656e-06
#PETSc Option Table entries:
-d 3
-ksp_type fcg
-log_view
-mat_type aij
-n 100
-pc_type mg
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type tcqmr -pc_type bjacobi -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 15:55:03 2020            |
| OS:             Linux                               |
| HostName:       sdumont6180                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.88768, Active time=2.91259                                       |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.4032      0.000008    0.4032      0.000008    13.84    13.84    |
| Ke                            50792      1.7793      0.000035    1.7793      0.000035    61.09    61.09    |
| elem init                     50792      0.7301      0.000014    0.7301      0.000014    25.07    25.07    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.9126                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 326.149700
Tempo total: 326.193198
Tempo total: 326.115263
Tempo total: 326.158842
Tempo total: 326.122530
Tempo total: 326.151673
Tempo total: 326.118642
Tempo total: 326.093922
Tempo total: 326.118837
Tempo total: 326.067569
Tempo total: 326.088584
Tempo total: 326.126197
Tempo total: 326.100389
Tempo total: 326.116820
Tempo total: 326.100842
Tempo total: 326.067980
Tempo total: 326.099266
Tempo total: 326.114337
Tempo total: 326.098644
Tempo total: 326.187421
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6180 with 20 processors, by luciano.siqueira Thu Dec 10 16:00:01 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           3.265e+02     1.000   3.265e+02
Objects:              4.800e+01     1.000   4.800e+01
Flop:                 1.967e+11     1.106   1.870e+11  3.740e+12
Flop/sec:             6.026e+08     1.106   5.728e+08  1.146e+10
MPI Messages:         1.958e+04     2.740   1.301e+04  2.601e+05
MPI Message Lengths:  8.798e+08     1.829   5.170e+04  1.345e+10
MPI Reductions:       2.992e+03     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 3.2649e+02 100.0%  3.7400e+12 100.0%  2.601e+05 100.0%  5.170e+04      100.0%  2.985e+03  99.8%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 4.5703e-0184.5 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  0  0  0  0  0   0  0  0  0  0     0
BuildTwoSidedF         5 1.0 4.5587e-0198.2 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  0  0  0  2  0   0  0  0  2  0     0
MatMult             1768 1.0 1.4464e+02 1.1 9.45e+10 1.1 2.6e+05 4.6e+04 0.0e+00 43 48 99 88  0  43 48 99 88  0 12465
MatSolve            1770 1.0 1.4107e+02 1.1 9.25e+10 1.1 0.0e+00 0.0e+00 0.0e+00 41 47  0  0  0  41 47  0  0  0 12405
MatLUFactorNum         1 1.0 2.4491e+00 1.1 1.27e+09 1.1 0.0e+00 0.0e+00 0.0e+00  1  1  0  0  0   1  1  0  0  0  9880
MatILUFactorSym        1 1.0 1.5255e-01 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatAssemblyBegin       2 1.0 5.3968e-01 3.7 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  0  0  0  2  0   0  0  0  2  0     0
MatAssemblyEnd         2 1.0 3.4142e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  0  0  0  0  0   0  0  0  0  0    13
MatGetRowIJ            1 1.0 4.1330e-06 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatGetOrdering         1 1.0 4.2075e-03 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatZeroEntries         3 1.0 1.2118e-01 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecDot              1767 1.0 7.2875e+00 6.0 1.50e+09 1.1 0.0e+00 0.0e+00 1.8e+03  1  1  0  0 59   1  1  0  0 59  3938
VecNorm             1181 1.0 1.2780e+0120.4 1.00e+09 1.1 0.0e+00 0.0e+00 1.2e+03  2  1  0  0 39   2  1  0  0 40  1501
VecScale            2357 1.0 8.6718e-01 1.2 1.00e+09 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 22072
VecCopy             5306 1.0 4.2717e+00 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
VecSet              1780 1.0 8.2803e-01 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY             5299 1.0 3.6457e+00 1.2 4.50e+09 1.1 0.0e+00 0.0e+00 0.0e+00  1  2  0  0  0   1  2  0  0  0 23607
VecAYPX              589 1.0 6.7782e-01 1.1 5.00e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 14113
VecAssemblyBegin       3 1.0 1.0253e-02 1.1 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAssemblyEnd         3 1.0 5.6500e-04 4.5 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecScatterBegin     1769 1.0 1.2326e+00 2.1 0.00e+00 0.0 2.6e+05 4.6e+04 0.0e+00  0  0 99 88  0   0  0 99 88  0     0
VecScatterEnd       1769 1.0 1.4221e+0158.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  2  0  0  0  0   2  0  0  0  0     0
SFSetGraph             2 1.0 5.1703e-04 1.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.1803e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFBcastOpBegin      1769 1.0 1.2276e+00 2.1 0.00e+00 0.0 2.6e+05 4.6e+04 0.0e+00  0  0 99 88  0   0  0 99 88  0     0
SFBcastOpEnd        1769 1.0 1.4217e+0159.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  2  0  0  0  0   2  0  0  0  0     0
SFPack              1769 1.0 1.1886e+00 2.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack            1769 1.0 1.1870e-03 1.5 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               2 1.0 1.0043e-02 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSolve               1 1.0 2.9727e+02 1.0 1.97e+11 1.1 2.6e+05 4.6e+04 2.9e+03 91100 99 88 99  91100 99 88 99 12580
PCSetUp                2 1.0 2.6135e+00 1.1 1.27e+09 1.1 0.0e+00 0.0e+00 0.0e+00  1  1  0  0  0   1  1  0  0  0  9258
PCSetUpOnBlocks        1 1.0 2.6059e+00 1.1 1.27e+09 1.1 0.0e+00 0.0e+00 0.0e+00  1  1  0  0  0   1  1  0  0  0  9285
PCApply             1770 1.0 1.4192e+02 1.1 9.25e+10 1.1 0.0e+00 0.0e+00 0.0e+00 41 47  0  0  0  41 47  0  0  0 12331
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     4              4    666933972     0.
           Index Set     7              7      5403804     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    27             27     75398160     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     2              2         3016     0.
      Preconditioner     2              2         1944     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 2.78e-08
Average time for MPI_Barrier(): 5.09e-06
Average time for zero size MPI_Send(): 3.3871e-06
#PETSc Option Table entries:
-d 3
-ksp_type tcqmr
-log_view
-mat_type aij
-n 100
-pc_type bjacobi
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type tcqmr -pc_type jacobi -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 16:00:33 2020            |
| OS:             Linux                               |
| HostName:       sdumont6180                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.82619, Active time=2.87551                                       |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.3998      0.000008    0.3998      0.000008    13.91    13.91    |
| Ke                            50792      1.7564      0.000035    1.7564      0.000035    61.08    61.08    |
| elem init                     50792      0.7193      0.000014    0.7193      0.000014    25.01    25.01    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.8755                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 1088.232768
Tempo total: 1088.265570
Tempo total: 1088.231097
Tempo total: 1088.273055
Tempo total: 1088.238260
Tempo total: 1088.276085
Tempo total: 1088.223285
Tempo total: 1088.257011
Tempo total: 1088.202929
Tempo total: 1088.252184
Tempo total: 1088.222476
Tempo total: 1088.242506
Tempo total: 1088.203253
Tempo total: 1088.177683
Tempo total: 1088.202636
Tempo total: 1088.235699
Tempo total: 1088.201546
Tempo total: 1088.176484
Tempo total: 1088.213365
Tempo total: 1088.316987
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6180 with 20 processors, by luciano.siqueira Thu Dec 10 16:18:13 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           1.089e+03     1.000   1.089e+03
Objects:              4.100e+01     1.000   4.100e+01
Flop:                 6.966e+11     1.100   6.649e+11  1.330e+13
Flop/sec:             6.398e+08     1.100   6.107e+08  1.221e+10
MPI Messages:         1.307e+05     2.748   8.678e+04  1.736e+06
MPI Message Lengths:  5.425e+09     1.944   4.673e+04  8.110e+10
MPI Reductions:       1.984e+04     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 1.0888e+03 100.0%  1.3298e+13 100.0%  1.736e+06 100.0%  4.673e+04      100.0%  1.983e+04 100.0%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 5.9029e-01143.5 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  0  0  0  0  0   0  0  0  0  0     0
BuildTwoSidedF         5 1.0 5.8742e-01164.2 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatMult            11874 1.0 9.7253e+02 1.1 6.34e+11 1.1 1.7e+06 4.6e+04 0.0e+00 87 91100 98  0  87 91100 98  0 12450
MatAssemblyBegin       2 1.0 6.6112e-01 4.1 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatAssemblyEnd         2 1.0 3.2727e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  0  0  0  0  0   0  0  0  0  0    13
MatZeroEntries         3 1.0 1.2092e-01 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecDot             11874 1.0 2.3907e+01 2.9 1.01e+10 1.1 0.0e+00 0.0e+00 1.2e+04  1  1  0  0 60   1  1  0  0 60  8067
VecNorm             7918 1.0 3.6646e+01 9.1 6.73e+09 1.1 0.0e+00 0.0e+00 7.9e+03  2  1  0  0 40   2  1  0  0 40  3509
VecScale           15829 1.0 6.4188e+00 1.4 6.72e+09 1.1 0.0e+00 0.0e+00 0.0e+00  1  1  0  0  0   1  1  0  0  0 20026
VecCopy            35620 1.0 2.8275e+01 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  3  0  0  0  0   3  0  0  0  0     0
VecSet                10 1.0 4.4209e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY            35613 1.0 2.4944e+01 1.2 3.03e+10 1.1 0.0e+00 0.0e+00 0.0e+00  2  4  0  0  0   2  4  0  0  0 23188
VecAYPX             3957 1.0 4.5823e+00 1.1 3.36e+09 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 14025
VecAssemblyBegin       3 1.0 9.0834e-03 1.0 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAssemblyEnd         3 1.0 5.6320e-04 4.5 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecPointwiseMult   11876 1.0 1.5019e+01 1.1 5.04e+09 1.1 0.0e+00 0.0e+00 0.0e+00  1  1  0  0  0   1  1  0  0  0  6421
VecScatterBegin    11875 1.0 8.3490e+00 2.1 0.00e+00 0.0 1.7e+06 4.6e+04 0.0e+00  1  0100 98  0   1  0100 98  0     0
VecScatterEnd      11875 1.0 9.6272e+0157.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  4  0  0  0  0   4  0  0  0  0     0
SFSetGraph             2 1.0 4.9623e-04 1.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.1309e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFBcastOpBegin     11875 1.0 8.3192e+00 2.1 0.00e+00 0.0 1.7e+06 4.6e+04 0.0e+00  1  0100 98  0   1  0100 98  0     0
SFBcastOpEnd       11875 1.0 9.6245e+0158.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  4  0  0  0  0   4  0  0  0  0     0
SFPack             11875 1.0 8.0760e+00 2.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
SFUnpack           11875 1.0 6.6289e-03 1.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               1 1.0 1.0646e-02 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSolve               1 1.0 1.0587e+03 1.0 6.97e+11 1.1 1.7e+06 4.6e+04 2.0e+04 97100100 98100  97100100 98100 12560
PCSetUp                1 1.0 9.8000e-07 4.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
PCApply            11876 1.0 1.5113e+01 1.1 5.04e+09 1.1 0.0e+00 0.0e+00 2.0e+00  1  1  0  0  0   1  1  0  0  0  6381
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     3              3    344047400     0.
           Index Set     4              4       304416     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    26             26     78794504     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     1              1         1600     0.
      Preconditioner     1              1          968     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 2.84e-08
Average time for MPI_Barrier(): 4.9962e-06
Average time for zero size MPI_Send(): 3.37865e-06
#PETSc Option Table entries:
-d 3
-ksp_type tcqmr
-log_view
-mat_type aij
-n 100
-pc_type jacobi
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type tcqmr -pc_type sor -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 16:18:44 2020            |
| OS:             Linux                               |
| HostName:       sdumont6180                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.82519, Active time=2.87712                                       |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.3998      0.000008    0.3998      0.000008    13.89    13.89    |
| Ke                            50792      1.7574      0.000035    1.7574      0.000035    61.08    61.08    |
| elem init                     50792      0.7200      0.000014    0.7200      0.000014    25.02    25.02    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.8771                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 3111.560273
Tempo total: 3111.587716
Tempo total: 3111.572499
Tempo total: 3111.594529
Tempo total: 3111.536499
Tempo total: 3111.568617
Tempo total: 3111.535967
Tempo total: 3111.550305
Tempo total: 3111.536108
Tempo total: 3111.502708
Tempo total: 3111.524987
Tempo total: 3111.548834
Tempo total: 3111.512041
Tempo total: 3111.537780
Tempo total: 3111.514405
Tempo total: 3111.534833
Tempo total: 3111.512840
Tempo total: 3111.537020
Tempo total: 3111.513767
Tempo total: 3111.592495
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6180 with 20 processors, by luciano.siqueira Thu Dec 10 17:10:08 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           3.112e+03     1.000   3.112e+03
Objects:              4.000e+01     1.000   4.000e+01
Flop:                 1.664e+12     1.106   1.582e+12  3.163e+13
Flop/sec:             5.347e+08     1.106   5.083e+08  1.017e+10
MPI Messages:         1.651e+05     2.749   1.096e+05  2.192e+06
MPI Message Lengths:  6.832e+09     1.949   4.654e+04  1.020e+11
MPI Reductions:       2.505e+04     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 3.1119e+03 100.0%  3.1633e+13 100.0%  2.192e+06 100.0%  4.654e+04      100.0%  2.504e+04 100.0%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 4.0116e-0185.0 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  0  0  0  0  0   0  0  0  0  0     0
BuildTwoSidedF         5 1.0 3.9860e-0190.9 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatMult            15001 1.0 1.2261e+03 1.1 8.01e+11 1.1 2.2e+06 4.6e+04 0.0e+00 39 48100 98  0  39 48100 98  0 12476
MatSOR             15003 1.0 1.7868e+03 1.1 7.90e+11 1.1 0.0e+00 0.0e+00 0.0e+00 54 47  0  0  0  54 47  0  0  0  8370
MatAssemblyBegin       2 1.0 5.2199e-01 3.3 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatAssemblyEnd         2 1.0 3.4320e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  0  0  0  0  0   0  0  0  0  0    13
MatZeroEntries         3 1.0 1.2102e-01 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecDot             15000 1.0 7.5735e+01 7.5 1.27e+10 1.1 0.0e+00 0.0e+00 1.5e+04  1  1  0  0 60   1  1  0  0 60  3217
VecNorm            10003 1.0 1.3780e+0226.2 8.50e+09 1.1 0.0e+00 0.0e+00 1.0e+04  2  1  0  0 40   2  1  0  0 40  1179
VecScale           20001 1.0 6.9533e+00 1.1 8.49e+09 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 23359
VecCopy            45005 1.0 3.5601e+01 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
VecSet                10 1.0 4.4352e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY            44998 1.0 3.0253e+01 1.1 3.82e+10 1.1 0.0e+00 0.0e+00 0.0e+00  1  2  0  0  0   1  2  0  0  0 24157
VecAYPX             5000 1.0 5.7046e+00 1.1 4.25e+09 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 14235
VecAssemblyBegin       3 1.0 1.0329e-02 1.1 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAssemblyEnd         3 1.0 6.2141e-04 4.7 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecScatterBegin    15002 1.0 1.0551e+01 2.1 0.00e+00 0.0 2.2e+06 4.6e+04 0.0e+00  0  0100 98  0   0  0100 98  0     0
VecScatterEnd      15002 1.0 1.1456e+0254.6 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  2  0  0  0  0   2  0  0  0  0     0
SFSetGraph             2 1.0 5.1428e-04 1.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.1461e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFBcastOpBegin     15002 1.0 1.0514e+01 2.1 0.00e+00 0.0 2.2e+06 4.6e+04 0.0e+00  0  0100 98  0   0  0100 98  0     0
SFBcastOpEnd       15002 1.0 1.1452e+0255.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  2  0  0  0  0   2  0  0  0  0     0
SFPack             15002 1.0 1.0211e+01 2.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack           15002 1.0 9.4498e-03 1.5 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               1 1.0 9.5342e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSolve               1 1.0 3.0825e+03 1.0 1.66e+12 1.1 2.2e+06 4.6e+04 2.5e+04 99100100 98100  99100100 98100 10262
PCSetUp                1 1.0 3.7300e-07 2.6 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
PCApply            15003 1.0 1.7869e+03 1.1 7.90e+11 1.1 0.0e+00 0.0e+00 0.0e+00 54 47  0  0  0  54 47  0  0  0  8370
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     3              3    354240752     0.
           Index Set     4              4       304416     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    25             25     75395024     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     1              1         1600     0.
      Preconditioner     1              1          968     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 2.77e-08
Average time for MPI_Barrier(): 4.8146e-06
Average time for zero size MPI_Send(): 3.3768e-06
#PETSc Option Table entries:
-d 3
-ksp_type tcqmr
-log_view
-mat_type aij
-n 100
-pc_type sor
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type tcqmr -pc_type mg -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 17:10:38 2020            |
| OS:             Linux                               |
| HostName:       sdumont6180                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.84789, Active time=2.88302                                       |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.3980      0.000008    0.3980      0.000008    13.80    13.80    |
| Ke                            50792      1.7643      0.000035    1.7643      0.000035    61.20    61.20    |
| elem init                     50792      0.7207      0.000014    0.7207      0.000014    25.00    25.00    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.8830                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 360.821836
Tempo total: 360.779465
Tempo total: 360.819623
Tempo total: 360.778949
Tempo total: 360.796227
Tempo total: 360.839302
Tempo total: 360.806113
Tempo total: 360.842104
Tempo total: 360.783419
Tempo total: 360.825045
Tempo total: 360.781992
Tempo total: 360.807155
Tempo total: 360.782874
Tempo total: 360.810742
Tempo total: 360.779104
Tempo total: 360.810956
Tempo total: 360.776847
Tempo total: 360.796159
Tempo total: 360.798364
Tempo total: 360.839047
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6180 with 20 processors, by luciano.siqueira Thu Dec 10 17:16:11 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           3.612e+02     1.000   3.612e+02
Objects:              6.500e+01     1.000   6.500e+01
Flop:                 1.783e+11     1.106   1.695e+11  3.390e+12
Flop/sec:             4.938e+08     1.106   4.693e+08  9.386e+09
MPI Messages:         1.791e+04     2.739   1.190e+04  2.380e+05
MPI Message Lengths:  8.115e+08     1.818   5.224e+04  1.243e+10
MPI Reductions:       1.405e+03     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 3.6120e+02 100.0%  3.3902e+12 100.0%  2.380e+05 100.0%  5.224e+04      100.0%  1.398e+03  99.5%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 4.0667e-0161.2 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  0  0  0  0  0   0  0  0  0  1     0
BuildTwoSidedF         5 1.0 4.0445e-0198.5 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  0  0  0  2  0   0  0  0  2  0     0
MatMult             1616 1.0 1.4045e+02 1.1 8.63e+10 1.1 2.4e+05 4.6e+04 0.0e+00 37 49 99 87  0  37 49 99 87  0 11733
MatSOR              1619 1.0 1.9309e+02 1.1 8.53e+10 1.1 0.0e+00 0.0e+00 0.0e+00 51 48  0  0  0  51 48  0  0  0  8358
MatAssemblyBegin       2 1.0 5.7819e-01 6.5 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  0  0  0  2  0   0  0  0  2  0     0
MatAssemblyEnd         2 1.0 3.4265e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  0  0  0  0  0   0  0  0  0  0    13
MatZeroEntries         3 1.0 1.2212e-01 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecDot               801 1.0 4.8061e+00 8.3 6.80e+08 1.1 0.0e+00 0.0e+00 8.0e+02  1  0  0  0 57   1  0  0  0 57  2707
VecMDot               10 1.0 1.4523e-01 6.7 4.67e+07 1.1 0.0e+00 0.0e+00 1.0e+01  0  0  0  0  1   0  0  0  0  1  6151
VecNorm              548 1.0 8.8439e+0027.4 4.65e+08 1.1 0.0e+00 0.0e+00 5.5e+02  1  0  0  0 39   1  0  0  0 39  1006
VecScale            1080 1.0 4.2102e-01 1.3 4.59e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 20831
VecCopy             4017 1.0 2.9500e+00 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
VecSet              1620 1.0 5.0686e-01 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY             2402 1.0 1.5695e+00 1.1 2.04e+09 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 24856
VecAYPX             1875 1.0 2.1114e+00 1.1 1.25e+09 1.1 0.0e+00 0.0e+00 0.0e+00  1  1  0  0  0   1  1  0  0  0 11330
VecAXPBYCZ           804 1.0 1.0865e+00 1.1 1.71e+09 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 30046
VecMAXPY              11 1.0 3.6397e-02 1.1 5.52e+07 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 29005
VecAssemblyBegin       3 1.0 1.0160e-02 1.1 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAssemblyEnd         3 1.0 6.2193e-04 4.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecScatterBegin     1617 1.0 1.0533e+00 2.1 0.00e+00 0.0 2.4e+05 4.6e+04 0.0e+00  0  0 99 87  0   0  0 99 87  0     0
VecScatterEnd       1617 1.0 2.2530e+0171.6 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  3  0  0  0  0   3  0  0  0  0     0
VecNormalize          11 1.0 3.1135e-02 2.9 1.40e+07 1.1 0.0e+00 0.0e+00 1.1e+01  0  0  0  0  1   0  0  0  0  1  8607
SFSetGraph             2 1.0 5.1557e-04 1.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.1530e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFBcastOpBegin      1617 1.0 1.0492e+00 2.1 0.00e+00 0.0 2.4e+05 4.6e+04 0.0e+00  0  0 99 87  0   0  0 99 87  0     0
SFBcastOpEnd        1617 1.0 2.2526e+0172.5 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  3  0  0  0  0   3  0  0  0  0     0
SFPack              1617 1.0 1.0139e+00 2.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack            1617 1.0 1.1363e-03 1.6 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               2 1.0 2.3420e+00 1.0 1.23e+09 1.1 1.5e+03 4.6e+04 2.3e+01  1  1  1  1  2   1  1  1  1  2  9993
KSPSolve               1 1.0 3.3199e+02 1.0 1.78e+11 1.1 2.4e+05 4.6e+04 1.4e+03 92100 99 87 97  92100 99 87 97 10211
KSPGMRESOrthog        10 1.0 1.7317e-01 3.3 9.34e+07 1.1 0.0e+00 0.0e+00 1.0e+01  0  0  0  0  1   0  0  0  0  1 10317
PCSetUp                1 1.0 2.3337e+00 1.0 1.23e+09 1.1 1.5e+03 4.6e+04 2.3e+01  1  1  1  1  2   1  1  1  1  2 10029
PCApply              815 1.0 2.6184e+02 1.0 1.31e+11 1.1 1.2e+05 4.6e+04 0.0e+00 71 73 49 43  0  71 73 49 43  0  9494
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     3              3    354240752     0.
           Index Set     4              4       304416     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    44             44    139985144     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     4              4        35144     0.
      Preconditioner     4              4         4256     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 2.78e-08
Average time for MPI_Barrier(): 4.925e-06
Average time for zero size MPI_Send(): 3.50935e-06
#PETSc Option Table entries:
-d 3
-ksp_type tcqmr
-log_view
-mat_type aij
-n 100
-pc_type mg
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type cgs -pc_type bjacobi -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 17:16:43 2020            |
| OS:             Linux                               |
| HostName:       sdumont6180                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.88046, Active time=2.90468                                       |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.4014      0.000008    0.4014      0.000008    13.82    13.82    |
| Ke                            50792      1.7715      0.000035    1.7715      0.000035    60.99    60.99    |
| elem init                     50792      0.7317      0.000014    0.7317      0.000014    25.19    25.19    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.9047                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 39.817909
Tempo total: 39.777406
Tempo total: 39.809828
Tempo total: 39.781197
Tempo total: 39.811999
Tempo total: 39.777474
Tempo total: 39.828745
Tempo total: 39.782436
Tempo total: 39.809848
Tempo total: 39.777448
Tempo total: 39.805794
Tempo total: 39.778388
Tempo total: 39.796060
Tempo total: 39.825113
Tempo total: 39.840133
Tempo total: 39.827401
Tempo total: 39.847550
Tempo total: 39.793035
Tempo total: 39.824563
Tempo total: 39.786752
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6180 with 20 processors, by luciano.siqueira Thu Dec 10 17:16:54 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           4.018e+01     1.000   4.018e+01
Objects:              3.700e+01     1.000   3.700e+01
Flop:                 6.272e+09     1.107   5.959e+09  1.192e+11
Flop/sec:             1.561e+08     1.107   1.483e+08  2.966e+09
MPI Messages:         6.245e+02     2.459   4.294e+02  8.587e+03
MPI Message Lengths:  1.048e+08     1.200   2.230e+05  1.915e+09
MPI Reductions:       1.130e+02     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 4.0182e+01 100.0%  1.1919e+11 100.0%  8.587e+03 100.0%  2.230e+05      100.0%  1.060e+02  93.8%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 4.9316e-01108.7 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  1  0  5  0  6   1  0  5  0  7     0
BuildTwoSidedF         5 1.0 4.9212e-01137.8 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  1  0  4 11  4   1  0  4 11  5     0
MatMult               45 1.0 3.8998e+00 1.1 2.40e+09 1.1 6.6e+03 4.6e+04 0.0e+00  9 39 77 16  0   9 39 77 16  0 11767
MatSolve              46 1.0 3.6627e+00 1.1 2.40e+09 1.1 0.0e+00 0.0e+00 0.0e+00  9 38  0  0  0   9 38  0  0  0 12417
MatLUFactorNum         1 1.0 2.4448e+00 1.1 1.27e+09 1.1 0.0e+00 0.0e+00 0.0e+00  6 20  0  0  0   6 20  0  0  0  9897
MatILUFactorSym        1 1.0 1.5500e-01 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatAssemblyBegin       2 1.0 5.9558e-01 3.6 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  1  0  2 11  2   1  0  2 11  2     0
MatAssemblyEnd         2 1.0 3.4146e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  1  0  3  0  4   1  0  3  0  5    13
MatGetRowIJ            1 1.0 4.2140e-06 1.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatGetOrdering         1 1.0 4.1549e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatZeroEntries         3 1.0 1.2139e-01 1.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecDot                45 1.0 4.5918e-0116.6 3.82e+07 1.1 0.0e+00 0.0e+00 4.5e+01  1  1  0  0 40   1  1  0  0 42  1592
VecNorm               24 1.0 9.0217e-02 6.5 2.04e+07 1.1 0.0e+00 0.0e+00 2.4e+01  0  0  0  0 21   0  0  0  0 23  4321
VecCopy                5 1.0 3.7179e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet                51 1.0 2.2931e-02 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY               66 1.0 5.2841e-02 1.1 5.61e+07 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 20286
VecWAXPY              86 1.0 1.1377e-01 1.1 6.37e+07 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 10707
VecAssemblyBegin       3 1.0 9.6503e-03 1.0 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  3  0  3   0  0  3  0  3     0
VecAssemblyEnd         3 1.0 5.6756e-04 3.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecScatterBegin       46 1.0 3.1501e-02 2.0 0.00e+00 0.0 6.7e+03 4.6e+04 0.0e+00  0  0 78 16  0   0  0 78 16  0     0
VecScatterEnd         46 1.0 6.1215e-0195.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
SFSetGraph             2 1.0 5.1326e-04 2.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.1490e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  7  0  2   0  0  7  0  2     0
SFBcastOpBegin        46 1.0 3.1379e-02 2.1 0.00e+00 0.0 6.7e+03 4.6e+04 0.0e+00  0  0 78 16  0   0  0 78 16  0     0
SFBcastOpEnd          46 1.0 6.1204e-0196.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
SFPack                46 1.0 2.9745e-02 2.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack              46 1.0 3.3172e-05 1.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               2 1.0 3.7620e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSolve               1 1.0 1.0113e+01 1.0 6.26e+09 1.1 6.6e+03 4.6e+04 6.9e+01 25100 77 16 61  25100 77 16 65 11765
PCSetUp                2 1.0 2.6120e+00 1.1 1.27e+09 1.1 0.0e+00 0.0e+00 0.0e+00  6 20  0  0  0   6 20  0  0  0  9264
PCSetUpOnBlocks        1 1.0 2.6041e+00 1.1 1.27e+09 1.1 0.0e+00 0.0e+00 0.0e+00  6 20  0  0  0   6 20  0  0  0  9292
PCApply               46 1.0 3.6845e+00 1.1 2.40e+09 1.1 0.0e+00 0.0e+00 0.0e+00  9 38  0  0  0   9 38  0  0  0 12344
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     4              4    666933972     0.
           Index Set     7              7      5403804     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    16             16     38003880     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     2              2         3016     0.
      Preconditioner     2              2         1944     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 2.88e-08
Average time for MPI_Barrier(): 4.6272e-06
Average time for zero size MPI_Send(): 3.31925e-06
#PETSc Option Table entries:
-d 3
-ksp_type cgs
-log_view
-mat_type aij
-n 100
-pc_type bjacobi
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type cgs -pc_type jacobi -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 17:17:25 2020            |
| OS:             Linux                               |
| HostName:       sdumont6180                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.82758, Active time=2.86949                                       |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.4006      0.000008    0.4006      0.000008    13.96    13.96    |
| Ke                            50792      1.7487      0.000034    1.7487      0.000034    60.94    60.94    |
| elem init                     50792      0.7202      0.000014    0.7202      0.000014    25.10    25.10    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.8695                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 111.139808
Tempo total: 111.068617
Tempo total: 111.081681
Tempo total: 111.131279
Tempo total: 111.079364
Tempo total: 111.100862
Tempo total: 111.064332
Tempo total: 111.047749
Tempo total: 111.075563
Tempo total: 111.093694
Tempo total: 111.067626
Tempo total: 111.100043
Tempo total: 111.056102
Tempo total: 111.038146
Tempo total: 111.050497
Tempo total: 111.083052
Tempo total: 111.055924
Tempo total: 111.034163
Tempo total: 111.058819
Tempo total: 111.074523
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6180 with 20 processors, by luciano.siqueira Thu Dec 10 17:18:49 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           1.114e+02     1.000   1.114e+02
Objects:              3.000e+01     1.000   3.000e+01
Flop:                 5.413e+10     1.100   5.167e+10  1.033e+12
Flop/sec:             4.857e+08     1.100   4.636e+08  9.272e+09
MPI Messages:         1.041e+04     2.731   6.926e+03  1.385e+05
MPI Message Lengths:  5.051e+08     1.738   5.683e+04  7.873e+09
MPI Reductions:       1.450e+03     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 1.1145e+02 100.0%  1.0333e+12 100.0%  1.385e+05 100.0%  5.683e+04      100.0%  1.443e+03  99.5%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 4.5176e-0189.3 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  0  0  0  0  0   0  0  0  0  0     0
BuildTwoSidedF         5 1.0 4.5030e-01107.8 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  0  0  0  3  0   0  0  0  3  0     0
MatMult              935 1.0 7.6471e+01 1.1 5.00e+10 1.1 1.4e+05 4.6e+04 0.0e+00 67 92 99 80  0  67 92 99 80  0 12468
MatAssemblyBegin       2 1.0 5.2573e-01 3.2 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  0  0  0  3  0   0  0  0  3  0     0
MatAssemblyEnd         2 1.0 3.4104e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  0  0  0  0  0   0  0  0  0  0    13
MatZeroEntries         3 1.0 1.2195e-01 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecDot               935 1.0 4.5738e+00 8.1 7.94e+08 1.1 0.0e+00 0.0e+00 9.4e+02  2  1  0  0 64   2  1  0  0 65  3320
VecNorm              469 1.0 2.8006e-01 1.0 3.98e+08 1.1 0.0e+00 0.0e+00 4.7e+02  0  1  0  0 32   0  1  0  0 33 27198
VecCopy                5 1.0 3.8870e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet                 5 1.0 1.8064e-03 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY             1401 1.0 1.2153e+00 1.2 1.19e+09 1.1 0.0e+00 0.0e+00 0.0e+00  1  2  0  0  0   1  2  0  0  0 18723
VecWAXPY            1866 1.0 2.4190e+00 1.1 1.39e+09 1.1 0.0e+00 0.0e+00 0.0e+00  2  3  0  0  0   2  3  0  0  0 10961
VecAssemblyBegin       3 1.0 9.6911e-03 1.0 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAssemblyEnd         3 1.0 5.9223e-04 4.5 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecPointwiseMult     936 1.0 1.1866e+00 1.1 3.98e+08 1.1 0.0e+00 0.0e+00 0.0e+00  1  1  0  0  0   1  1  0  0  0  6406
VecScatterBegin      936 1.0 6.1988e-01 2.0 0.00e+00 0.0 1.4e+05 4.6e+04 0.0e+00  0  0 99 80  0   0  0 99 80  0     0
VecScatterEnd        936 1.0 7.4589e+0061.7 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  3  0  0  0  0   3  0  0  0  0     0
SFSetGraph             2 1.0 5.1680e-04 1.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.1700e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFBcastOpBegin       936 1.0 6.1790e-01 2.1 0.00e+00 0.0 1.4e+05 4.6e+04 0.0e+00  0  0 99 80  0   0  0 99 80  0     0
SFBcastOpEnd         936 1.0 7.4568e+0062.7 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  3  0  0  0  0   3  0  0  0  0     0
SFPack               936 1.0 5.9841e-01 2.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack             936 1.0 5.8396e-04 1.6 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               1 1.0 3.7106e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSolve               1 1.0 8.1942e+01 1.0 5.41e+10 1.1 1.4e+05 4.6e+04 1.4e+03 74100 99 80 97  74100 99 80 97 12608
PCSetUp                1 1.0 6.1200e-07 2.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
PCApply              936 1.0 1.2609e+00 1.1 3.98e+08 1.1 0.0e+00 0.0e+00 2.0e+00  1  1  0  0  0   1  1  0  0  0  6028
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     3              3    344047400     0.
           Index Set     4              4       304416     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    15             15     41400224     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     1              1         1600     0.
      Preconditioner     1              1          968     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 2.86e-08
Average time for MPI_Barrier(): 5.24e-06
Average time for zero size MPI_Send(): 3.3646e-06
#PETSc Option Table entries:
-d 3
-ksp_type cgs
-log_view
-mat_type aij
-n 100
-pc_type jacobi
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type cgs -pc_type sor -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 17:19:19 2020            |
| OS:             Linux                               |
| HostName:       sdumont6180                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.86895, Active time=2.90092                                       |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.4015      0.000008    0.4015      0.000008    13.84    13.84    |
| Ke                            50792      1.7655      0.000035    1.7655      0.000035    60.86    60.86    |
| elem init                     50792      0.7339      0.000014    0.7339      0.000014    25.30    25.30    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.9009                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 56.598874
Tempo total: 56.578229
Tempo total: 56.529924
Tempo total: 56.588055
Tempo total: 56.532775
Tempo total: 56.565254
Tempo total: 56.534711
Tempo total: 56.568350
Tempo total: 56.529104
Tempo total: 56.533943
Tempo total: 56.507311
Tempo total: 56.538281
Tempo total: 56.507198
Tempo total: 56.538604
Tempo total: 56.513583
Tempo total: 56.542259
Tempo total: 56.512572
Tempo total: 56.490896
Tempo total: 56.507063
Tempo total: 56.621444
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6180 with 20 processors, by luciano.siqueira Thu Dec 10 17:19:48 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           5.691e+01     1.000   5.691e+01
Objects:              2.900e+01     1.000   2.900e+01
Flop:                 1.471e+10     1.106   1.398e+10  2.796e+11
Flop/sec:             2.585e+08     1.106   2.457e+08  4.913e+09
MPI Messages:         1.592e+03     2.628   1.072e+03  2.144e+04
MPI Message Lengths:  1.444e+08     1.344   1.168e+05  2.504e+09
MPI Reductions:       2.450e+02     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 5.6911e+01 100.0%  2.7962e+11 100.0%  2.144e+04 100.0%  1.168e+05      100.0%  2.380e+02  97.1%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 4.6362e-01113.6 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  0  0  2  0  3   0  0  2  0  3     0
BuildTwoSidedF         5 1.0 4.6379e-01133.2 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  0  0  2  8  2   0  0  2  8  2     0
MatMult              133 1.0 1.0866e+01 1.0 7.11e+09 1.1 1.9e+04 4.6e+04 0.0e+00 19 49 91 36  0  19 49 91 36  0 12481
MatSOR               134 1.0 1.6172e+01 1.1 7.06e+09 1.1 0.0e+00 0.0e+00 0.0e+00 27 48  0  0  0  27 48  0  0  0  8260
MatAssemblyBegin       2 1.0 5.6221e-01 3.5 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  1  0  1  8  1   1  0  1  8  1     0
MatAssemblyEnd         2 1.0 3.2530e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  1  0  1  0  2   1  0  1  0  2    13
MatZeroEntries         3 1.0 1.2119e-01 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecDot               133 1.0 1.9639e+0023.7 1.13e+08 1.1 0.0e+00 0.0e+00 1.3e+02  2  1  0  0 54   2  1  0  0 56  1100
VecNorm               68 1.0 7.1646e-02 1.8 5.78e+07 1.1 0.0e+00 0.0e+00 6.8e+01  0  0  0  0 28   0  0  0  0 29 15415
VecCopy                5 1.0 3.8177e-03 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet                 5 1.0 1.7770e-03 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY              198 1.0 1.5688e-01 1.1 1.68e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 20499
VecWAXPY             262 1.0 3.4476e-01 1.1 1.95e+08 1.1 0.0e+00 0.0e+00 0.0e+00  1  1  0  0  0   1  1  0  0  0 10788
VecAssemblyBegin       3 1.0 9.0609e-03 1.0 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  1  0  1   0  0  1  0  1     0
VecAssemblyEnd         3 1.0 5.7524e-04 4.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecScatterBegin      134 1.0 9.3673e-02 2.1 0.00e+00 0.0 2.0e+04 4.6e+04 0.0e+00  0  0 91 36  0   0  0 91 36  0     0
VecScatterEnd        134 1.0 1.0091e+0054.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
SFSetGraph             2 1.0 5.0675e-04 1.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.1341e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  3  0  1   0  0  3  0  1     0
SFBcastOpBegin       134 1.0 9.3381e-02 2.1 0.00e+00 0.0 2.0e+04 4.6e+04 0.0e+00  0  0 91 36  0   0  0 91 36  0     0
SFBcastOpEnd         134 1.0 1.0088e+0055.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
SFPack               134 1.0 8.8802e-02 2.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack             134 1.0 9.0738e-05 1.7 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               1 1.0 3.6931e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSolve               1 1.0 2.7489e+01 1.0 1.47e+10 1.1 1.9e+04 4.6e+04 2.0e+02 48100 91 36 82  48100 91 36 84 10164
PCSetUp                1 1.0 4.5000e-07 3.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
PCApply              134 1.0 1.6172e+01 1.1 7.06e+09 1.1 0.0e+00 0.0e+00 0.0e+00 27 48  0  0  0  27 48  0  0  0  8260
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     3              3    354240752     0.
           Index Set     4              4       304416     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    14             14     38000744     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     1              1         1600     0.
      Preconditioner     1              1          968     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 2.95e-08
Average time for MPI_Barrier(): 4.7426e-06
Average time for zero size MPI_Send(): 3.3717e-06
#PETSc Option Table entries:
-d 3
-ksp_type cgs
-log_view
-mat_type aij
-n 100
-pc_type sor
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type cgs -pc_type mg -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 17:20:19 2020            |
| OS:             Linux                               |
| HostName:       sdumont6180                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.85792, Active time=2.89278                                       |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.3987      0.000008    0.3987      0.000008    13.78    13.78    |
| Ke                            50792      1.7610      0.000035    1.7610      0.000035    60.87    60.87    |
| elem init                     50792      0.7332      0.000014    0.7332      0.000014    25.34    25.34    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.8928                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 155.839616
Tempo total: 155.877717
Tempo total: 155.838312
Tempo total: 155.787047
Tempo total: 155.829374
Tempo total: 155.736712
Tempo total: 155.826530
Tempo total: 155.752799
Tempo total: 155.814126
Tempo total: 155.734773
Tempo total: 155.755309
Tempo total: 155.720535
Tempo total: 155.760101
Tempo total: 155.774776
Tempo total: 155.752318
Tempo total: 155.771333
Tempo total: 155.746379
Tempo total: 155.773414
Tempo total: 155.758024
Tempo total: 155.914238
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6180 with 20 processors, by luciano.siqueira Thu Dec 10 17:22:27 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           1.562e+02     1.000   1.562e+02
Objects:              5.400e+01     1.000   5.400e+01
Flop:                 6.795e+10     1.106   6.459e+10  1.292e+12
Flop/sec:             4.352e+08     1.106   4.136e+08  8.272e+09
MPI Messages:         6.916e+03     2.721   4.605e+03  9.210e+04
MPI Message Lengths:  3.621e+08     1.661   6.237e+04  5.744e+09
MPI Reductions:       5.230e+02     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 1.5615e+02 100.0%  1.2917e+12 100.0%  9.210e+04 100.0%  6.237e+04      100.0%  5.160e+02  98.7%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 4.4652e-0151.5 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  0  0  0  0  1   0  0  0  0  1     0
BuildTwoSidedF         5 1.0 4.4492e-0179.1 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  0  0  0  4  1   0  0  0  4  1     0
MatMult              617 1.0 5.3837e+01 1.1 3.30e+10 1.1 9.0e+04 4.6e+04 0.0e+00 33 49 98 72  0  33 49 98 72  0 11686
MatSOR               619 1.0 7.3931e+01 1.1 3.26e+10 1.1 0.0e+00 0.0e+00 0.0e+00 45 48  0  0  0  45 48  0  0  0  8346
MatAssemblyBegin       2 1.0 5.2859e-01 3.4 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  0  0  0  4  0   0  0  0  4  0     0
MatAssemblyEnd         2 1.0 3.4196e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  0  0  0  0  1   0  0  0  0  1    13
MatZeroEntries         3 1.0 1.2248e-01 1.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecDot               303 1.0 4.8618e+0015.0 2.57e+08 1.1 0.0e+00 0.0e+00 3.0e+02  1  0  0  0 58   1  0  0  0 59  1012
VecMDot               10 1.0 1.6375e-01 7.3 4.67e+07 1.1 0.0e+00 0.0e+00 1.0e+01  0  0  0  0  2   0  0  0  0  2  5455
VecNorm              164 1.0 1.6120e-01 1.7 1.39e+08 1.1 0.0e+00 0.0e+00 1.6e+02  0  0  0  0 31   0  0  0  0 32 16524
VecScale              11 1.0 3.5020e-03 1.3 4.67e+06 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 25507
VecCopy              614 1.0 4.0216e-01 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet               615 1.0 1.9220e-01 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY              454 1.0 3.6194e-01 1.1 3.86e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 20372
VecAYPX              608 1.0 6.8330e-01 1.1 3.87e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 10839
VecAXPBYCZ           304 1.0 4.1358e-01 1.1 6.46e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 29845
VecWAXPY             602 1.0 8.1120e-01 1.1 4.47e+08 1.1 0.0e+00 0.0e+00 0.0e+00  0  1  0  0  0   0  1  0  0  0 10541
VecMAXPY              11 1.0 3.6014e-02 1.1 5.52e+07 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 29313
VecAssemblyBegin       3 1.0 9.6446e-03 1.0 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  0  0  1   0  0  0  0  1     0
VecAssemblyEnd         3 1.0 6.1024e-04 4.7 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecScatterBegin      618 1.0 3.9799e-01 2.0 0.00e+00 0.0 9.0e+04 4.6e+04 0.0e+00  0  0 98 72  0   0  0 98 72  0     0
VecScatterEnd        618 1.0 8.7244e+0026.7 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  3  0  0  0  0   3  0  0  0  0     0
VecNormalize          11 1.0 3.8415e-02 3.7 1.40e+07 1.1 0.0e+00 0.0e+00 1.1e+01  0  0  0  0  2   0  0  0  0  2  6976
SFSetGraph             2 1.0 5.2015e-04 1.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.1409e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  1  0  0   0  0  1  0  0     0
SFBcastOpBegin       618 1.0 3.9655e-01 2.0 0.00e+00 0.0 9.0e+04 4.6e+04 0.0e+00  0  0 98 72  0   0  0 98 72  0     0
SFBcastOpEnd         618 1.0 8.7230e+0026.8 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  3  0  0  0  0   3  0  0  0  0     0
SFPack               618 1.0 3.8209e-01 2.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack             618 1.0 4.0139e-04 1.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               2 1.0 2.3374e+00 1.0 1.23e+09 1.1 1.5e+03 4.6e+04 2.3e+01  1  2  2  1  4   1  2  2  1  4 10013
KSPSolve               1 1.0 1.2709e+02 1.0 6.79e+10 1.1 9.0e+04 4.6e+04 4.8e+02 81100 98 72 92  81100 98 72 93 10162
KSPGMRESOrthog        10 1.0 1.9165e-01 3.6 9.34e+07 1.1 0.0e+00 0.0e+00 1.0e+01  0  0  0  0  2   0  0  0  0  2  9322
PCSetUp                1 1.0 2.3340e+00 1.0 1.23e+09 1.1 1.5e+03 4.6e+04 2.3e+01  1  2  2  1  4   1  2  2  1  4 10027
PCApply              315 1.0 1.0012e+02 1.0 4.99e+10 1.1 4.4e+04 4.6e+04 0.0e+00 63 73 48 35  0  63 73 48 35  0  9457
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     3              3    354240752     0.
           Index Set     4              4       304416     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    33             33    102590864     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     4              4        35144     0.
      Preconditioner     4              4         4256     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 2.79e-08
Average time for MPI_Barrier(): 4.6946e-06
Average time for zero size MPI_Send(): 3.3741e-06
#PETSc Option Table entries:
-d 3
-ksp_type cgs
-log_view
-mat_type aij
-n 100
-pc_type mg
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type bcgs -pc_type bjacobi -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 17:22:59 2020            |
| OS:             Linux                               |
| HostName:       sdumont6180                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.83615, Active time=2.88271                                       |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.3992      0.000008    0.3992      0.000008    13.85    13.85    |
| Ke                            50792      1.7583      0.000035    1.7583      0.000035    60.99    60.99    |
| elem init                     50792      0.7253      0.000014    0.7253      0.000014    25.16    25.16    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.8827                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 117.315309
Tempo total: 117.361198
Tempo total: 117.321253
Tempo total: 117.282628
Tempo total: 117.300172
Tempo total: 117.333494
Tempo total: 117.305052
Tempo total: 117.328217
Tempo total: 117.306225
Tempo total: 117.327882
Tempo total: 117.306574
Tempo total: 117.338347
Tempo total: 117.294939
Tempo total: 117.328495
Tempo total: 117.295712
Tempo total: 117.327080
Tempo total: 117.313405
Tempo total: 117.274282
Tempo total: 117.301674
Tempo total: 117.362428
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6180 with 20 processors, by luciano.siqueira Thu Dec 10 17:24:28 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           1.177e+02     1.000   1.177e+02
Objects:              3.600e+01     1.000   3.600e+01
Flop:                 5.817e+10     1.106   5.529e+10  1.106e+12
Flop/sec:             4.942e+08     1.106   4.697e+08  9.395e+09
MPI Messages:         5.794e+03     2.715   3.860e+03  7.721e+04
MPI Message Lengths:  3.162e+08     1.624   6.555e+04  5.061e+09
MPI Reductions:       1.074e+03     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 1.1769e+02 100.0%  1.1057e+12 100.0%  7.721e+04 100.0%  6.555e+04      100.0%  1.067e+03  99.3%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 4.0261e-0181.1 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  0  0  1  0  1   0  0  1  0  1     0
BuildTwoSidedF         5 1.0 4.0111e-01100.6 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  0  0  0  4  0   0  0  0  4  0     0
MatMult              515 1.0 4.2111e+01 1.1 2.75e+10 1.1 7.5e+04 4.6e+04 0.0e+00 35 47 97 68  0  35 47 97 68  0 12471
MatSolve             516 1.0 4.1088e+01 1.1 2.70e+10 1.1 0.0e+00 0.0e+00 0.0e+00 33 46  0  0  0  33 46  0  0  0 12417
MatLUFactorNum         1 1.0 2.4529e+00 1.1 1.27e+09 1.1 0.0e+00 0.0e+00 0.0e+00  2  2  0  0  0   2  2  0  0  0  9864
MatILUFactorSym        1 1.0 1.5277e-01 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatAssemblyBegin       2 1.0 5.2711e-01 3.5 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  0  0  0  4  0   0  0  0  4  0     0
MatAssemblyEnd         2 1.0 3.4136e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  0  0  0  0  0   0  0  0  0  0    13
MatGetRowIJ            1 1.0 3.6350e-06 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatGetOrdering         1 1.0 4.1347e-03 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatZeroEntries         3 1.0 1.2203e-01 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecDot               514 1.0 2.9056e+00 8.0 4.37e+08 1.1 0.0e+00 0.0e+00 5.1e+02  1  1  0  0 48   1  1  0  0 48  2873
VecDotNorm2          257 1.0 2.9176e+00 7.9 4.37e+08 1.1 0.0e+00 0.0e+00 2.6e+02  1  1  0  0 24   1  1  0  0 24  2861
VecNorm              259 1.0 2.9632e-01 1.9 2.20e+08 1.1 0.0e+00 0.0e+00 2.6e+02  0  0  0  0 24   0  0  0  0 24 14196
VecCopy                3 1.0 2.3048e-03 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet               523 1.0 2.4471e-01 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY                1 1.0 5.4093e-04 1.3 8.49e+05 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 30024
VecAXPBYCZ           514 1.0 7.2390e-01 1.1 8.73e+08 1.1 0.0e+00 0.0e+00 0.0e+00  1  2  0  0  0   1  2  0  0  0 23064
VecWAXPY             514 1.0 6.3985e-01 1.1 4.37e+08 1.1 0.0e+00 0.0e+00 0.0e+00  1  1  0  0  0   1  1  0  0  0 13047
VecAssemblyBegin       3 1.0 9.6501e-03 1.0 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAssemblyEnd         3 1.0 6.1732e-04 4.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecScatterBegin      516 1.0 3.5405e-01 2.1 0.00e+00 0.0 7.5e+04 4.6e+04 0.0e+00  0  0 98 68  0   0  0 98 68  0     0
VecScatterEnd        516 1.0 4.2311e+0063.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  2  0  0  0  0   2  0  0  0  0     0
SFSetGraph             2 1.0 5.1519e-04 1.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.1646e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  1  0  0   0  0  1  0  0     0
SFBcastOpBegin       516 1.0 3.5289e-01 2.1 0.00e+00 0.0 7.5e+04 4.6e+04 0.0e+00  0  0 98 68  0   0  0 98 68  0     0
SFBcastOpEnd         516 1.0 4.2299e+0064.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  2  0  0  0  0   2  0  0  0  0     0
SFPack               516 1.0 3.4138e-01 2.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack             516 1.0 3.9876e-04 1.8 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               2 1.0 3.1835e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSolve               1 1.0 8.7466e+01 1.0 5.82e+10 1.1 7.5e+04 4.6e+04 1.0e+03 74100 97 68 96  74100 97 68 97 12639
PCSetUp                2 1.0 2.6176e+00 1.1 1.27e+09 1.1 0.0e+00 0.0e+00 0.0e+00  2  2  0  0  0   2  2  0  0  0  9244
PCSetUpOnBlocks        1 1.0 2.6099e+00 1.1 1.27e+09 1.1 0.0e+00 0.0e+00 0.0e+00  2  2  0  0  0   2  2  0  0  0  9271
PCApply              516 1.0 4.1336e+01 1.1 2.70e+10 1.1 0.0e+00 0.0e+00 0.0e+00 33 46  0  0  0  33 46  0  0  0 12342
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     4              4    666933972     0.
           Index Set     7              7      5403804     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    15             15     34604400     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     2              2         3024     0.
      Preconditioner     2              2         1944     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 2.91e-08
Average time for MPI_Barrier(): 4.9116e-06
Average time for zero size MPI_Send(): 3.29025e-06
#PETSc Option Table entries:
-d 3
-ksp_type bcgs
-log_view
-mat_type aij
-n 100
-pc_type bjacobi
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type bcgs -pc_type jacobi -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 17:24:59 2020            |
| OS:             Linux                               |
| HostName:       sdumont6180                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.83432, Active time=2.8717                                        |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.3981      0.000008    0.3981      0.000008    13.86    13.86    |
| Ke                            50792      1.7502      0.000034    1.7502      0.000034    60.95    60.95    |
| elem init                     50792      0.7234      0.000014    0.7234      0.000014    25.19    25.19    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.8717                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

Tempo total: 66.804925
Tempo total: 66.836999
Tempo total: 66.814771
Tempo total: 66.834691
Tempo total: 66.824743
Tempo total: 66.837981
Tempo total: 66.812506
Tempo total: 66.778604
Tempo total: 66.802099
Tempo total: 66.816120
Tempo total: 66.796501
Tempo total: 66.819170
Tempo total: 66.800507
Tempo total: 66.763446
Tempo total: 66.804190
Tempo total: 66.814152
Tempo total: 66.800854
Tempo total: 66.766470
Tempo total: 66.798275
Tempo total: 66.838076
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

/scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6180 with 20 processors, by luciano.siqueira Thu Dec 10 17:25:38 2020
Using 1 OpenMP threads
Using Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500

                         Max       Max/Min     Avg       Total
Time (sec):           6.721e+01     1.000   6.721e+01
Objects:              2.900e+01     1.000   2.900e+01
Flop:                 2.511e+10     1.100   2.397e+10  4.794e+11
Flop/sec:             3.737e+08     1.100   3.567e+08  7.133e+09
MPI Messages:         4.848e+03     2.709   3.233e+03  6.465e+04
MPI Message Lengths:  2.775e+08     1.585   6.938e+04  4.486e+09
MPI Reductions:       9.040e+02     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 6.7213e+01 100.0%  4.7945e+11 100.0%  6.465e+04 100.0%  6.938e+04      100.0%  8.970e+02  99.2%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          7 1.0 4.7634e-0195.3 0.00e+00 0.0 4.4e+02 5.3e+00 7.0e+00  0  0  1  0  1   0  0  1  0  1     0
BuildTwoSidedF         5 1.0 4.7723e-01117.0 0.00e+00 0.0 3.6e+02 5.7e+05 5.0e+00  0  0  1  5  1   0  0  1  5  1     0
MatMult              429 1.0 3.5057e+01 1.1 2.29e+10 1.1 6.3e+04 4.6e+04 0.0e+00 51 91 97 64  0  51 91 97 64  0 12479
MatAssemblyBegin       2 1.0 5.5994e-01 3.3 0.00e+00 0.0 1.5e+02 1.4e+06 2.0e+00  1  0  0  5  0   1  0  0  5  0     0
MatAssemblyEnd         2 1.0 3.4299e-01 1.0 4.38e+05 0.0 2.9e+02 1.1e+04 5.0e+00  1  0  0  0  1   1  0  0  0  1    13
MatZeroEntries         3 1.0 1.2333e-01 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecDot               428 1.0 1.1753e+00 4.2 3.64e+08 1.1 0.0e+00 0.0e+00 4.3e+02  1  1  0  0 47   1  1  0  0 48  5914
VecDotNorm2          214 1.0 1.1884e+00 4.0 3.64e+08 1.1 0.0e+00 0.0e+00 2.1e+02  1  1  0  0 24   1  1  0  0 24  5849
VecNorm              216 1.0 2.0371e-01 1.6 1.83e+08 1.1 0.0e+00 0.0e+00 2.2e+02  0  1  0  0 24   0  1  0  0 24 17221
VecCopy                3 1.0 2.3398e-03 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet                 7 1.0 2.8385e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY                1 1.0 5.7603e-04 1.3 8.49e+05 1.1 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0 28195
VecAXPBYCZ           428 1.0 5.9939e-01 1.1 7.27e+08 1.1 0.0e+00 0.0e+00 0.0e+00  1  3  0  0  0   1  3  0  0  0 23195
VecWAXPY             428 1.0 5.6115e-01 1.1 3.64e+08 1.1 0.0e+00 0.0e+00 0.0e+00  1  1  0  0  0   1  1  0  0  0 12388
VecAssemblyBegin       3 1.0 9.6708e-03 1.0 0.00e+00 0.0 2.2e+02 1.5e+04 3.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAssemblyEnd         3 1.0 5.9258e-04 4.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecPointwiseMult     430 1.0 5.3777e-01 1.1 1.83e+08 1.1 0.0e+00 0.0e+00 0.0e+00  1  1  0  0  0   1  1  0  0  0  6493
VecScatterBegin      430 1.0 2.9290e-01 2.1 0.00e+00 0.0 6.3e+04 4.6e+04 0.0e+00  0  0 97 64  0   0  0 97 64  0     0
VecScatterEnd        430 1.0 3.0114e+0052.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  2  0  0  0  0   2  0  0  0  0     0
SFSetGraph             2 1.0 5.1809e-04 2.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                2 1.0 1.1629e-02 1.2 0.00e+00 0.0 5.8e+02 1.4e+04 2.0e+00  0  0  1  0  0   0  0  1  0  0     0
SFBcastOpBegin       430 1.0 2.9208e-01 2.1 0.00e+00 0.0 6.3e+04 4.6e+04 0.0e+00  0  0 97 64  0   0  0 97 64  0     0
SFBcastOpEnd         430 1.0 3.0107e+0053.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  2  0  0  0  0   2  0  0  0  0     0
SFPack               430 1.0 2.8296e-01 2.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFUnpack             430 1.0 3.1304e-04 1.8 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               1 1.0 3.2266e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSolve               1 1.0 3.7471e+01 1.0 2.51e+10 1.1 6.3e+04 4.6e+04 8.6e+02 56100 97 64 95  56100 97 64 96 12790
PCSetUp                1 1.0 9.8600e-07 4.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
PCApply              430 1.0 6.1070e-01 1.1 1.83e+08 1.1 0.0e+00 0.0e+00 2.0e+00  1  1  0  0  0   1  1  0  0  0  5718
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Matrix     3              3    344047400     0.
           Index Set     4              4       304416     0.
   IS L to G Mapping     1              1      1837212     0.
         Vec Scatter     2              2         1632     0.
              Vector    14             14     38000744     0.
   Star Forest Graph     2              2         2272     0.
       Krylov Solver     1              1         1608     0.
      Preconditioner     1              1          968     0.
              Viewer     1              0            0     0.
========================================================================================================================
Average time to get PetscTime(): 2.78e-08
Average time for MPI_Barrier(): 4.7978e-06
Average time for zero size MPI_Send(): 3.32505e-06
#PETSc Option Table entries:
-d 3
-ksp_type bcgs
-log_view
-mat_type aij
-n 100
-pc_type jacobi
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
-----------------------------------------
Libraries compiled on 2020-07-29 17:59:57 on chimas-cpu 
Machine characteristics: Linux-5.4.0-42-generic-x86_64-with-debian-10.4
Using PETSc directory: /opt/petsc
Using PETSc arch: arch-linux2-c-opt
-----------------------------------------

Using C compiler: /opt/petsc/arch-linux2-c-opt/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -fopenmp   
Using Fortran compiler: /opt/petsc/arch-linux2-c-opt/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -fopenmp    
-----------------------------------------

Using include paths: -I/opt/petsc/include -I/opt/petsc/arch-linux2-c-opt/include
-----------------------------------------

Using C linker: /opt/petsc/arch-linux2-c-opt/bin/mpicc
Using Fortran linker: /opt/petsc/arch-linux2-c-opt/bin/mpif90
Using libraries: -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -lpetsc -Wl,-rpath,/opt/petsc/arch-linux2-c-opt/lib -L/opt/petsc/arch-linux2-c-opt/lib -Wl,-rpath,/usr/lib/gcc/x86_64-linux-gnu/8 -L/usr/lib/gcc/x86_64-linux-gnu/8 -Wl,-rpath,/usr/lib/x86_64-linux-gnu -L/usr/lib/x86_64-linux-gnu -Wl,-rpath,/lib/x86_64-linux-gnu -L/lib/x86_64-linux-gnu -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lsuperlu_dist -lparms -lspai -llapack -lblas -lX11 -lm -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lstdc++ -ldl
-----------------------------------------

Running /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment -d 3 -n 100 -mat_type aij -ksp_type bcgs -pc_type sor -log_view

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0

 EquationSystems
  n_systems()=1
   System #0, "Poisson"
    Type "LinearImplicit"
    Variables="u" 
    Finite Element Types="LAGRANGE" 
    Approximation Orders="SECOND" 
    n_dofs()=8120601
    n_local_dofs()=424723
    n_constrained_dofs()=240002
    n_local_constrained_dofs()=17175
    n_vectors()=1
    n_matrices()=1
    DofMap Sparsity
      Average  On-Processor Bandwidth <= 61.9002
      Average Off-Processor Bandwidth <= 1.91784
      Maximum  On-Processor Bandwidth <= 141
      Maximum Off-Processor Bandwidth <= 121
    DofMap Constraints
      Number of DoF Constraints = 240002
      Number of Heterogenous Constraints= 239202
      Average DoF Constraint Length= 0

 Mesh Information:
  elem_dimensions()={3}
  spatial_dimension()=3
  n_nodes()=8120601
    n_local_nodes()=424723
  n_elem()=1000000
    n_local_elem()=50792
    n_active_elem()=1000000
  n_subdomains()=1
  n_partitions()=20
  n_processors()=20
  n_threads()=1
  processor_id()=0


 -----------------------------------------------------
| Processor id:   0                                   |
| Num Processors: 20                                  |
| Time:           Thu Dec 10 17:26:09 2020            |
| OS:             Linux                               |
| HostName:       sdumont6180                         |
| OS Release:     3.10.0-957.el7.x86_64               |
| OS Version:     #1 SMP Thu Oct 4 20:48:51 UTC 2018  |
| Machine:        x86_64                              |
| Username:       luciano.siqueira                    |
| Configuration:  ../configure  '--prefix=/usr/local' |
|  '--with-vtk-include=/usr/local/include/vtk-8.2'    |
|  '--with-vtk-lib=/usr/local/lib'                    |
|  '--enable-petsc=yes'                               |
|  '--enable-petsc-required'                          |
|  '--enable-slepc'                                   |
|  '--enable-slepc-required'                          |
|  'METHODS=opt'                                      |
|  'PETSC_DIR=/opt/petsc'                             |
|  'PETSC_ARCH=arch-linux2-c-opt'                     |
|  'SLEPC_DIR=/opt/petsc/arch-linux2-c-opt'           |
 -----------------------------------------------------
 ------------------------------------------------------------------------------------------------------------
| Matrix Assembly Performance: Alive time=4.83208, Active time=2.87698                                       |
 ------------------------------------------------------------------------------------------------------------
| Event                         nCalls     Total Time  Avg Time    Total Time  Avg Time    % of Active Time  |
|                                          w/o Sub     w/o Sub     With Sub    With Sub    w/o S    With S   |
|------------------------------------------------------------------------------------------------------------|
|                                                                                                            |
| Fe                            50792      0.3975      0.000008    0.3975      0.000008    13.82    13.82    |
| Ke                            50792      1.7535      0.000035    1.7535      0.000035    60.95    60.95    |
| elem init                     50792      0.7260      0.000014    0.7260      0.000014    25.24    25.24    |
 ------------------------------------------------------------------------------------------------------------
| Totals:                       152376     2.8770                                          100.00            |
 ------------------------------------------------------------------------------------------------------------

slurmstepd: error: *** JOB 801702 ON sdumont6180 CANCELLED AT 2020-12-10T17:27:15 DUE TO TIME LIMIT ***
mpirun: Forwarding signal 18 to job
[0]PETSC ERROR: ------------------------------------------------------------------------
[0]PETSC ERROR: Caught signal number 15 Terminate: Some process (or the batch system) has told this process to end
[0]PETSC ERROR: Try option -start_in_debugger or -on_error_attach_debugger
[0]PETSC ERROR: or see https://www.mcs.anl.gov/petsc/documentation/faq.html#valgrind
[0]PETSC ERROR: or try http://valgrind.org on GNU/linux and Apple Mac OS X to find memory corruption errors
[0]PETSC ERROR: configure using --with-debugging=yes, recompile, link, and run 
[0]PETSC ERROR: to get more information on the crash.
[0]PETSC ERROR: --------------------- Error Message --------------------------------------------------------------
[0]PETSC ERROR: Signal received
[0]PETSC ERROR: See https://www.mcs.anl.gov/petsc/documentation/faq.html for trouble shooting.
[0]PETSC ERROR: Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500
[0]PETSC ERROR: /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6180 by luciano.siqueira Thu Dec 10 17:25:40 2020
[0]PETSC ERROR: Configure options --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
[0]PETSC ERROR: #1 User provided function() line 0 in  unknown file
[1]PETSC ERROR: ------------------------------------------------------------------------
[1]PETSC ERROR: Caught signal number 15 Terminate: Some process (or the batch system) has told this process to end
[1]PETSC ERROR: Try option -start_in_debugger or -on_error_attach_debugger
[1]PETSC ERROR: or see https://www.mcs.anl.gov/petsc/documentation/faq.html#valgrind
[1]PETSC ERROR: or try http://valgrind.org on GNU/linux and Apple Mac OS X to find memory corruption errors
[1]PETSC ERROR: configure using --with-debugging=yes, recompile, link, and run 
[1]PETSC ERROR: to get more information on the crash.
[1]PETSC ERROR: --------------------- Error Message --------------------------------------------------------------
[1]PETSC ERROR: Signal received
[1]PETSC ERROR: See https://www.mcs.anl.gov/petsc/documentation/faq.html for trouble shooting.
[1]PETSC ERROR: Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500
[1]PETSC ERROR: /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6180 by luciano.siqueira Thu Dec 10 17:25:40 2020
[1]PETSC ERROR: Configure options --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
[1]PETSC ERROR: #1 User provided function() line 0 in  unknown file
[2]PETSC ERROR: [3]PETSC ERROR: ------------------------------------------------------------------------
[3]PETSC ERROR: Caught signal number 15 Terminate: Some process (or the batch system) has told this process to end
[3]PETSC ERROR: Try option -start_in_debugger or -on_error_attach_debugger
[3]PETSC ERROR: or see https://www.mcs.anl.gov/petsc/documentation/faq.html#valgrind
[3]PETSC ERROR: or try http://valgrind.org on GNU/linux and Apple Mac OS X to find memory corruption errors
[3]PETSC ERROR: configure using --with-debugging=yes, recompile, link, and run 
[3]PETSC ERROR: to get more information on the crash.
[3]PETSC ERROR: --------------------- Error Message --------------------------------------------------------------
[3]PETSC ERROR: Signal received
[3]PETSC ERROR: See https://www.mcs.anl.gov/petsc/documentation/faq.html for trouble shooting.
[3]PETSC ERROR: Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500
[3]PETSC ERROR: /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6180 by luciano.siqueira Thu Dec 10 17:25:40 2020
[3]PETSC ERROR: Configure options --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
[3]PETSC ERROR: #1 User provided function() line 0 in  unknown file
[4]PETSC ERROR: ------------------------------------------------------------------------
[4]PETSC ERROR: Caught signal number 15 Terminate: Some process (or the batch system) has told this process to end
[4]PETSC ERROR: Try option -start_in_debugger or -on_error_attach_debugger
[4]PETSC ERROR: or see https://www.mcs.anl.gov/petsc/documentation/faq.html#valgrind
[4]PETSC ERROR: or try http://valgrind.org on GNU/linux and Apple Mac OS X to find memory corruption errors
[4]PETSC ERROR: configure using --with-debugging=yes, recompile, link, and run 
[4]PETSC ERROR: to get more information on the crash.
[4]PETSC ERROR: --------------------- Error Message --------------------------------------------------------------
[4]PETSC ERROR: Signal received
[4]PETSC ERROR: See https://www.mcs.anl.gov/petsc/documentation/faq.html for trouble shooting.
[4]PETSC ERROR: Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500
[4]PETSC ERROR: /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6180 by luciano.siqueira Thu Dec 10 17:25:40 2020
[4]PETSC ERROR: Configure options --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
[4]PETSC ERROR: #1 User provided function() line 0 in  unknown file
[5]PETSC ERROR: ------------------------------------------------------------------------
[5]PETSC ERROR: Caught signal number 15 Terminate: Some process (or the batch system) has told this process to end
[5]PETSC ERROR: Try option -start_in_debugger or -on_error_attach_debugger
[5]PETSC ERROR: or see https://www.mcs.anl.gov/petsc/documentation/faq.html#valgrind
[5]PETSC ERROR: or try http://valgrind.org on GNU/linux and Apple Mac OS X to find memory corruption errors
[5]PETSC ERROR: configure using --with-debugging=yes, recompile, link, and run 
[5]PETSC ERROR: to get more information on the crash.
[5]PETSC ERROR: --------------------- Error Message --------------------------------------------------------------
[5]PETSC ERROR: Signal received
[5]PETSC ERROR: See https://www.mcs.anl.gov/petsc/documentation/faq.html for trouble shooting.
[5]PETSC ERROR: Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500
[5]PETSC ERROR: /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6180 by luciano.siqueira Thu Dec 10 17:25:40 2020
[5]PETSC ERROR: Configure options --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
[5]PETSC ERROR: #1 User provided function() line 0 in  unknown file
[6]PETSC ERROR: ------------------------------------------------------------------------
[6]PETSC ERROR: Caught signal number 15 Terminate: Some process (or the batch system) has told this process to end
[6]PETSC ERROR: Try option -start_in_debugger or -on_error_attach_debugger
[6]PETSC ERROR: or see https://www.mcs.anl.gov/petsc/documentation/faq.html#valgrind
[6]PETSC ERROR: or try http://valgrind.org on GNU/linux and Apple Mac OS X to find memory corruption errors
[6]PETSC ERROR: configure using --with-debugging=yes, recompile, link, and run 
[6]PETSC ERROR: to get more information on the crash.
[6]PETSC ERROR: --------------------- Error Message --------------------------------------------------------------
[6]PETSC ERROR: Signal received
[6]PETSC ERROR: See https://www.mcs.anl.gov/petsc/documentation/faq.html for trouble shooting.
[6]PETSC ERROR: Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500
[6]PETSC ERROR: /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6180 by luciano.siqueira Thu Dec 10 17:25:40 2020
[6]PETSC ERROR: Configure options --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
[6]PETSC ERROR: #1 User provided function() line 0 in  unknown file
[7]PETSC ERROR: ------------------------------------------------------------------------
[7]PETSC ERROR: Caught signal number 15 Terminate: Some process (or the batch system) has told this process to end
[7]PETSC ERROR: Try option -start_in_debugger or -on_error_attach_debugger
[7]PETSC ERROR: or see https://www.mcs.anl.gov/petsc/documentation/faq.html#valgrind
[7]PETSC ERROR: or try http://valgrind.org on GNU/linux and Apple Mac OS X to find memory corruption errors
[7]PETSC ERROR: configure using --with-debugging=yes, recompile, link, and run 
[7]PETSC ERROR: to get more information on the crash.
[7]PETSC ERROR: --------------------- Error Message --------------------------------------------------------------
[7]PETSC ERROR: Signal received
[7]PETSC ERROR: See https://www.mcs.anl.gov/petsc/documentation/faq.html for trouble shooting.
[7]PETSC ERROR: Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500
[7]PETSC ERROR: /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6180 by luciano.siqueira Thu Dec 10 17:25:40 2020
[7]PETSC ERROR: Configure options --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
[7]PETSC ERROR: #1 User provided function() line 0 in  unknown file
[8]PETSC ERROR: ------------------------------------------------------------------------
[8]PETSC ERROR: Caught signal number 15 Terminate: Some process (or the batch system) has told this process to end
[8]PETSC ERROR: Try option -start_in_debugger or -on_error_attach_debugger
[8]PETSC ERROR: or see https://www.mcs.anl.gov/petsc/documentation/faq.html#valgrind
[8]PETSC ERROR: or try http://valgrind.org on GNU/linux and Apple Mac OS X to find memory corruption errors
[8]PETSC ERROR: configure using --with-debugging=yes, recompile, link, and run 
[8]PETSC ERROR: to get more information on the crash.
[8]PETSC ERROR: --------------------- Error Message --------------------------------------------------------------
[8]PETSC ERROR: Signal received
[8]PETSC ERROR: See https://www.mcs.anl.gov/petsc/documentation/faq.html for trouble shooting.
[8]PETSC ERROR: Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500
[8]PETSC ERROR: /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6180 by luciano.siqueira Thu Dec 10 17:25:40 2020
[8]PETSC ERROR: Configure options --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
[8]PETSC ERROR: #1 User provided function() line 0 in  unknown file
[9]PETSC ERROR: ------------------------------------------------------------------------
[9]PETSC ERROR: Caught signal number 15 Terminate: Some process (or the batch system) has told this process to end
[9]PETSC ERROR: Try option -start_in_debugger or -on_error_attach_debugger
[9]PETSC ERROR: or see https://www.mcs.anl.gov/petsc/documentation/faq.html#valgrind
[9]PETSC ERROR: or try http://valgrind.org on GNU/linux and Apple Mac OS X to find memory corruption errors
[9]PETSC ERROR: configure using --with-debugging=yes, recompile, link, and run 
[9]PETSC ERROR: to get more information on the crash.
[9]PETSC ERROR: --------------------- Error Message --------------------------------------------------------------
[9]PETSC ERROR: Signal received
[9]PETSC ERROR: See https://www.mcs.anl.gov/petsc/documentation/faq.html for trouble shooting.
[9]PETSC ERROR: Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500
[9]PETSC ERROR: /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6180 by luciano.siqueira Thu Dec 10 17:25:40 2020
[9]PETSC ERROR: Configure options --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
[9]PETSC ERROR: #1 User provided function() line 0 in  unknown file
[10]PETSC ERROR: ------------------------------------------------------------------------
[10]PETSC ERROR: Caught signal number 15 Terminate: Some process (or the batch system) has told this process to end
[10]PETSC ERROR: Try option -start_in_debugger or -on_error_attach_debugger
[10]PETSC ERROR: or see https://www.mcs.anl.gov/petsc/documentation/faq.html#valgrind
[10]PETSC ERROR: or try http://valgrind.org on GNU/linux and Apple Mac OS X to find memory corruption errors
[10]PETSC ERROR: configure using --with-debugging=yes, recompile, link, and run 
[10]PETSC ERROR: to get more information on the crash.
[10]PETSC ERROR: --------------------- Error Message --------------------------------------------------------------
[10]PETSC ERROR: Signal received
[10]PETSC ERROR: See https://www.mcs.anl.gov/petsc/documentation/faq.html for trouble shooting.
[10]PETSC ERROR: Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500
[10]PETSC ERROR: /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6180 by luciano.siqueira Thu Dec 10 17:25:40 2020
[10]PETSC ERROR: Configure options --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
[10]PETSC ERROR: #1 User provided function() line 0 in  unknown file
[12]PETSC ERROR: ------------------------------------------------------------------------
[12]PETSC ERROR: Caught signal number 15 Terminate: Some process (or the batch system) has told this process to end
[12]PETSC ERROR: Try option -start_in_debugger or -on_error_attach_debugger
[12]PETSC ERROR: or see https://www.mcs.anl.gov/petsc/documentation/faq.html#valgrind
[12]PETSC ERROR: or try http://valgrind.org on GNU/linux and Apple Mac OS X to find memory corruption errors
[12]PETSC ERROR: configure using --with-debugging=yes, recompile, link, and run 
[12]PETSC ERROR: to get more information on the crash.
[12]PETSC ERROR: --------------------- Error Message --------------------------------------------------------------
[12]PETSC ERROR: Signal received
[12]PETSC ERROR: See https://www.mcs.anl.gov/petsc/documentation/faq.html for trouble shooting.
[12]PETSC ERROR: Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500
[12]PETSC ERROR: /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6180 by luciano.siqueira Thu Dec 10 17:25:40 2020
[12]PETSC ERROR: Configure options --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
[12]PETSC ERROR: #1 User provided function() line 0 in  unknown file
[13]PETSC ERROR: ------------------------------------------------------------------------
[13]PETSC ERROR: Caught signal number 15 Terminate: Some process (or the batch system) has told this process to end
[13]PETSC ERROR: Try option -start_in_debugger or -on_error_attach_debugger
[13]PETSC ERROR: or see https://www.mcs.anl.gov/petsc/documentation/faq.html#valgrind
[13]PETSC ERROR: or try http://valgrind.org on GNU/linux and Apple Mac OS X to find memory corruption errors
[13]PETSC ERROR: configure using --with-debugging=yes, recompile, link, and run 
[13]PETSC ERROR: to get more information on the crash.
[13]PETSC ERROR: --------------------- Error Message --------------------------------------------------------------
[13]PETSC ERROR: Signal received
[13]PETSC ERROR: See https://www.mcs.anl.gov/petsc/documentation/faq.html for trouble shooting.
[13]PETSC ERROR: Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500
[13]PETSC ERROR: /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6180 by luciano.siqueira Thu Dec 10 17:25:40 2020
[13]PETSC ERROR: Configure options --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
[13]PETSC ERROR: #1 User provided function() line 0 in  unknown file
[19]PETSC ERROR: ------------------------------------------------------------------------
[19]PETSC ERROR: Caught signal number 15 Terminate: Some process (or the batch system) has told this process to end
[19]PETSC ERROR: Try option -start_in_debugger or -on_error_attach_debugger
[19]PETSC ERROR: or see https://www.mcs.anl.gov/petsc/documentation/faq.html#valgrind
[19]PETSC ERROR: or try http://valgrind.org on GNU/linux and Apple Mac OS X to find memory corruption errors
[19]PETSC ERROR: configure using --with-debugging=yes, recompile, link, and run 
[19]PETSC ERROR: to get more information on the crash.
[19]PETSC ERROR: --------------------- Error Message --------------------------------------------------------------
[19]PETSC ERROR: Signal received
[19]PETSC ERROR: See https://www.mcs.anl.gov/petsc/documentation/faq.html for trouble shooting.
[19]PETSC ERROR: Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500
[19]PETSC ERROR: /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6180 by luciano.siqueira Thu Dec 10 17:25:40 2020
[19]PETSC ERROR: Configure options --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
[19]PETSC ERROR: #1 User provided function() line 0 in  unknown file
[11]PETSC ERROR: ------------------------------------------------------------------------
[11]PETSC ERROR: Caught signal number 15 Terminate: Some process (or the batch system) has told this process to end
[11]PETSC ERROR: Try option -start_in_debugger or -on_error_attach_debugger
[11]PETSC ERROR: or see https://www.mcs.anl.gov/petsc/documentation/faq.html#valgrind
[11]PETSC ERROR: or try http://valgrind.org on GNU/linux and Apple Mac OS X to find memory corruption errors
[11]PETSC ERROR: configure using --with-debugging=yes, recompile, link, and run 
[11]PETSC ERROR: to get more information on the crash.
[11]PETSC ERROR: --------------------- Error Message --------------------------------------------------------------
[11]PETSC ERROR: Signal received
[11]PETSC ERROR: See https://www.mcs.anl.gov/petsc/documentation/faq.html for trouble shooting.
[11]PETSC ERROR: Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500
[11]PETSC ERROR: /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6180 by luciano.siqueira Thu Dec 10 17:25:40 2020
[11]PETSC ERROR: Configure options --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
[11]PETSC ERROR: #1 User provided function() line 0 in  unknown file
[14]PETSC ERROR: ------------------------------------------------------------------------
[15]PETSC ERROR: ------------------------------------------------------------------------
[15]PETSC ERROR: Caught signal number 15 Terminate: Some process (or the batch system) has told this process to end
[15]PETSC ERROR: Try option -start_in_debugger or -on_error_attach_debugger
[15]PETSC ERROR: or see https://www.mcs.anl.gov/petsc/documentation/faq.html#valgrind
[15]PETSC ERROR: or try http://valgrind.org on GNU/linux and Apple Mac OS X to find memory corruption errors
[15]PETSC ERROR: configure using --with-debugging=yes, recompile, link, and run 
[15]PETSC ERROR: to get more information on the crash.
[15]PETSC ERROR: --------------------- Error Message --------------------------------------------------------------
[15]PETSC ERROR: Signal received
[15]PETSC ERROR: See https://www.mcs.anl.gov/petsc/documentation/faq.html for trouble shooting.
[15]PETSC ERROR: Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500
[15]PETSC ERROR: /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6180 by luciano.siqueira Thu Dec 10 17:25:40 2020
[15]PETSC ERROR: Configure options --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
[15]PETSC ERROR: #1 User provided function() line 0 in  unknown file
[16]PETSC ERROR: ------------------------------------------------------------------------
[16]PETSC ERROR: Caught signal number 15 Terminate: Some process (or the batch system) has told this process to end
[16]PETSC ERROR: Try option -start_in_debugger or -on_error_attach_debugger
[16]PETSC ERROR: or see https://www.mcs.anl.gov/petsc/documentation/faq.html#valgrind
[16]PETSC ERROR: or try http://valgrind.org on GNU/linux and Apple Mac OS X to find memory corruption errors
[16]PETSC ERROR: configure using --with-debugging=yes, recompile, link, and run 
[16]PETSC ERROR: to get more information on the crash.
[16]PETSC ERROR: --------------------- Error Message --------------------------------------------------------------
[16]PETSC ERROR: Signal received
[16]PETSC ERROR: See https://www.mcs.anl.gov/petsc/documentation/faq.html for trouble shooting.
[16]PETSC ERROR: Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500
[16]PETSC ERROR: /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6180 by luciano.siqueira Thu Dec 10 17:25:40 2020
[16]PETSC ERROR: Configure options --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
[16]PETSC ERROR: #1 User provided function() line 0 in  unknown file
[17]PETSC ERROR: ------------------------------------------------------------------------
[17]PETSC ERROR: Caught signal number 15 Terminate: Some process (or the batch system) has told this process to end
[17]PETSC ERROR: Try option -start_in_debugger or -on_error_attach_debugger
[17]PETSC ERROR: or see https://www.mcs.anl.gov/petsc/documentation/faq.html#valgrind
[17]PETSC ERROR: or try http://valgrind.org on GNU/linux and Apple Mac OS X to find memory corruption errors
[17]PETSC ERROR: configure using --with-debugging=yes, recompile, link, and run 
[17]PETSC ERROR: to get more information on the crash.
[17]PETSC ERROR: --------------------- Error Message --------------------------------------------------------------
[17]PETSC ERROR: Signal received
[17]PETSC ERROR: See https://www.mcs.anl.gov/petsc/documentation/faq.html for trouble shooting.
[17]PETSC ERROR: Petsc Development GIT revision: v3.13.3-587-g573a279584  GIT Date: 2020-07-22 10:05:48 -0500
[17]PETSC ERROR: /scratch/parceirosbr/chimasict/luciano/experiments/202012/libmesh/experiment on a arch-linux2-c-opt named sdumont6180 by luciano.siqueira Thu Dec 10 17:25:40 2020
[17]PETSC ERROR: Configure options --with-debugging=no --with-openmp=1 --download-superlu_dist --download-mumps --download-hypre --download-scalapack --download-spai --download-parms --download-slepc --download-openmpi COPTFLAGS= CXXOPTFLAGS= FOPTFLAGS=
[17]PETSC ERROR: #1 User provided function() line 0 in  unknown file
[18]PETSC ERROR: ------------------------------------------------------------------------
[18]PETSC ERROR: Caught signal number 15 Terminate: Some process (or the batch system) has told this process to end
[18]PETSC ERROR: Try option -start_in_debugger or -on_error_attach_debugger
[18]PETSC ERROR: or see https://www.mcs.anl.gov/petsc/documentation/faq.html#valgrind
[18]PETSC ERROR: 